# A Comprehensive Guide to Go File System Operations

## Table of Contents

1. [Introduction to File Systems](#introduction-to-file-systems)
2. [Basic File Operations](#basic-file-operations)
3. [Reading Files](#reading-files)
4. [Writing Files](#writing-files)
5. [Updating Files](#updating-files)
6. [Deleting Files](#deleting-files)
7. [Line Filtering and Processing](#line-filtering-and-processing)
8. [Directory Operations](#directory-operations)
9. [Temporary Files and Directories](#temporary-files-and-directories)
10. [Embedded File Systems](#embedded-file-systems)
11. [Real-World Examples](#real-world-examples)

---

## Introduction to File Systems

Imagine your computer's storage as a massive library. Files are like books containing information, and directories (folders) are like shelves that organize these books. Just as a librarian needs to know how to add books, find books, update catalog information, and remove old books, a programmer needs to understand how to interact with the file system.

In Go, file system operations are primarily handled through several packages: `os` for basic operations, `io` and `io/ioutil` for reading and writing, `path/filepath` for path manipulation, and `embed` for embedding files into your binary. Go's approach to file operations is explicit and error-conscious, meaning you always know when something goes wrong.

### The File System Hierarchy

Every file system has a tree-like structure:

```
Root Directory (/)
│
├── home/
│   ├── user/
│   │   ├── documents/
│   │   │   ├── report.txt
│   │   │   └── data.csv
│   │   └── downloads/
│   │       └── image.png
│   └── admin/
│
├── tmp/
│   ├── temp_file_001.tmp
│   └── cache/
│
└── etc/
    └── config.conf
```

On Windows, the structure starts with drive letters (C:, D:, etc.) instead of a single root. Go abstracts these differences, allowing your code to work cross-platform.

### File Descriptors and File Objects

When you open a file in Go, you receive a `*os.File` object. This is a handle to the actual file on disk. Think of it like checking out a book from the library—you get a reference to work with, but you need to return it (close the file) when you're done.

```
Program Memory                Operating System              Disk
┌──────────────┐             ┌─────────────────┐         ┌────────┐
│              │             │                 │         │        │
│  *os.File ───┼────────────→│ File Descriptor ├────────→│  File  │
│  (handle)    │   syscall   │   (OS level)    │  I/O    │ (data) │
│              │             │                 │         │        │
└──────────────┘             └─────────────────┘         └────────┘
```

The operating system manages the actual reading and writing, buffering data between your program and the physical disk. Your Go program interacts with this through the `os.File` interface.

### File Permissions and Modes

Every file has permissions that control who can read, write, or execute it. In Go, permissions are represented as octal numbers:

```
Permission Breakdown (Unix/Linux):

0644 means:
  0   6      4      4
  │   │      │      │
  │   │      │      └─ Others: read (4)
  │   │      └─ Group: read (4)
  │   └─ Owner: read(4) + write(2) = 6
  └─ Special flags

Binary representation:
Owner:  r w x  = 4+2+0 = 6 (110)
Group:  r w x  = 4+0+0 = 4 (100)
Others: r w x  = 4+0+0 = 4 (100)

Common permissions:
0644: rw-r--r-- (readable by all, writable by owner)
0755: rwxr-xr-x (executable by all, writable by owner)
0600: rw------- (only owner can read/write)
0777: rwxrwxrwx (everyone can do everything - dangerous!)
```

On Windows, the permission system is different, but Go tries to map these Unix-style permissions to Windows ACLs (Access Control Lists) as best as it can.

---

## Basic File Operations

Let's start with the fundamental operations you'll perform with files. Every file interaction follows a pattern: open the file, perform operations, and close the file. This is crucial because files are limited resources at the operating system level.

### Opening Files

Opening a file creates a connection between your program and the file on disk. Go provides several ways to open files depending on what you want to do:

```go
package main

import (
    "fmt"
    "os"
)

func main() {
    // Method 1: Open for reading (file must exist)
    file, err := os.Open("example.txt")
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    defer file.Close()  // Always close when done
    
    // Method 2: Open with specific flags
    file2, err := os.OpenFile("data.txt", os.O_RDWR|os.O_CREATE, 0644)
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    defer file2.Close()
    
    // Method 3: Create or truncate a file
    file3, err := os.Create("output.txt")
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    defer file3.Close()
}
```

**Understanding File Flags**: When you open a file, you specify flags that tell the operating system what you intend to do:

- `os.O_RDONLY`: Open for reading only
- `os.O_WRONLY`: Open for writing only
- `os.O_RDWR`: Open for reading and writing
- `os.O_APPEND`: Append to the end of file when writing
- `os.O_CREATE`: Create file if it doesn't exist
- `os.O_TRUNC`: Truncate (empty) file when opening
- `os.O_EXCL`: Used with O_CREATE, file must not exist

These flags can be combined using the bitwise OR operator `|`:

```go
// Open for reading and writing, create if doesn't exist, append when writing
flags := os.O_RDWR | os.O_CREATE | os.O_APPEND
file, err := os.OpenFile("log.txt", flags, 0644)
```

### The Importance of defer and Close

Every opened file must be closed. If you forget to close files, you'll eventually run out of file descriptors (the OS limit on how many files a process can have open). The `defer` statement ensures the file is closed even if an error occurs:

```go
func processFile(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()  // Will execute when function returns
    
    // Even if this panics, file.Close() will be called
    // Do processing...
    
    return nil
}
```

### File Information and Metadata

Once you have a file handle, you can query information about it:

```go
func fileInfo(filename string) {
    info, err := os.Stat(filename)
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    
    fmt.Println("Name:", info.Name())
    fmt.Println("Size:", info.Size(), "bytes")
    fmt.Println("Permissions:", info.Mode())
    fmt.Println("Modified:", info.ModTime())
    fmt.Println("Is Directory:", info.IsDir())
}
```

The `os.Stat` function returns a `FileInfo` interface that provides metadata without opening the file. This is efficient when you just need to check if a file exists or get its size.

### Checking File Existence

A common pattern is checking if a file exists before operating on it:

```go
func fileExists(filename string) bool {
    _, err := os.Stat(filename)
    if err == nil {
        return true  // File exists
    }
    if os.IsNotExist(err) {
        return false  // File definitely doesn't exist
    }
    return false  // Some other error (permissions, etc.)
}

// Using it
if fileExists("config.json") {
    // Load configuration
} else {
    // Use defaults or create new config
}
```

### File Paths and Cross-Platform Compatibility

Different operating systems use different path separators (forward slash `/` on Unix/Linux/Mac, backslash `\` on Windows). Go's `path/filepath` package handles this automatically:

```go
import "path/filepath"

func pathExamples() {
    // Join paths correctly for the current OS
    path := filepath.Join("users", "john", "documents", "file.txt")
    // On Unix: users/john/documents/file.txt
    // On Windows: users\john\documents\file.txt
    
    // Get the directory containing a file
    dir := filepath.Dir("/home/user/file.txt")  // /home/user
    
    // Get just the filename
    name := filepath.Base("/home/user/file.txt")  // file.txt
    
    // Get the file extension
    ext := filepath.Ext("document.pdf")  // .pdf
    
    // Split into directory and file
    dir, file := filepath.Split("/home/user/data.csv")
    // dir = /home/user/, file = data.csv
}
```

### Understanding Absolute vs Relative Paths

Paths can be absolute (starting from the root directory) or relative (relative to the current working directory):

```go
// Absolute paths (start from root)
abs1 := "/home/user/file.txt"        // Unix
abs2 := "C:\\Users\\John\\file.txt"  // Windows

// Relative paths
rel1 := "file.txt"           // In current directory
rel2 := "./data/file.txt"    // In data subdirectory
rel3 := "../file.txt"        // In parent directory

// Convert relative to absolute
absPath, err := filepath.Abs("./data/file.txt")
// Returns full path like /home/user/project/data/file.txt

// Get current working directory
cwd, err := os.Getwd()
```

---

## Reading Files

Reading files is one of the most common operations. Go provides multiple approaches, each suited for different scenarios: reading the entire file at once, reading in chunks, reading line by line, or using a buffered reader for efficiency.

### Reading Entire File into Memory

The simplest approach is reading the entire file contents into memory. This is suitable for small to medium-sized files:

```go
package main

import (
    "fmt"
    "os"
)

func readEntireFile() {
    // Method 1: Using os.ReadFile (Go 1.16+)
    data, err := os.ReadFile("example.txt")
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    
    // data is a []byte
    fmt.Println("Content:", string(data))
    fmt.Println("Size:", len(data), "bytes")
}
```

This approach is convenient but has an important limitation: if the file is larger than your available memory, your program will crash. For a 100MB file, this is fine. For a 10GB file, you need a different approach.

### Reading in Chunks

For large files, reading in chunks prevents memory exhaustion:

```go
func readInChunks(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Create a buffer to hold chunks
    buffer := make([]byte, 4096)  // 4KB chunks
    
    for {
        // Read up to len(buffer) bytes
        n, err := file.Read(buffer)
        if err != nil {
            if err.Error() == "EOF" {
                break  // End of file reached
            }
            return err
        }
        
        // Process the chunk (first n bytes of buffer)
        chunk := buffer[:n]
        fmt.Printf("Read %d bytes: %s\n", n, string(chunk))
    }
    
    return nil
}
```

**How Chunked Reading Works**:

```
File on Disk (12 bytes):
┌─────────────────────────────┐
│ Hello, World! │
└─────────────────────────────┘

Buffer (4 bytes):
┌──────────┐
│          │
└──────────┘

Read 1: buffer = "Hell", n = 4
Read 2: buffer = "o, W", n = 4
Read 3: buffer = "orld", n = 4
Read 4: buffer = "orld", n = 0, err = EOF
```

The key insight is that `Read` fills the buffer with as many bytes as available (up to the buffer size), returns how many bytes were actually read, and signals EOF (End Of File) when done.

### Buffered Reading for Efficiency

The `bufio` package provides buffered I/O, which is more efficient than reading byte-by-byte because it minimizes system calls:

```go
import (
    "bufio"
    "fmt"
    "os"
)

func bufferedReading(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Create buffered reader (default 4KB buffer)
    reader := bufio.NewReader(file)
    
    // Read single byte
    b, err := reader.ReadByte()
    
    // Read until delimiter
    line, err := reader.ReadString('\n')
    
    // Read specified number of bytes
    buffer := make([]byte, 100)
    n, err := reader.Read(buffer)
    
    return nil
}
```

**Why Buffering Matters**:

```
Without Buffering (many syscalls):
Program → syscall → OS → Disk (read 1 byte)
Program → syscall → OS → Disk (read 1 byte)
Program → syscall → OS → Disk (read 1 byte)
... (1000 syscalls for 1000 bytes)

With Buffering (fewer syscalls):
Program → syscall → OS → Disk (read 4096 bytes into buffer)
Program ← buffer (get 1 byte)
Program ← buffer (get 1 byte)
Program ← buffer (get 1 byte)
... (only 1 syscall for first 4096 bytes)
```

System calls are expensive because they involve context switching between user space and kernel space. Buffering dramatically reduces the number of syscalls.

### Reading Line by Line

For text files, reading line by line is common and efficient:

```go
func readLines(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    scanner := bufio.NewScanner(file)
    lineNum := 0
    
    // Read line by line
    for scanner.Scan() {
        lineNum++
        line := scanner.Text()
        fmt.Printf("Line %d: %s\n", lineNum, line)
    }
    
    // Check for errors during scanning
    if err := scanner.Err(); err != nil {
        return err
    }
    
    return nil
}
```

The `Scanner` type is specifically designed for reading input split by a delimiter (newlines by default). It handles the complexity of buffering and splitting automatically.

### Reading with Different Delimiters

You can customize how a scanner splits the input:

```go
func readByDelimiter(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    scanner := bufio.NewScanner(file)
    
    // Custom split function for comma-separated values
    scanner.Split(func(data []byte, atEOF bool) (advance int, token []byte, err error) {
        for i := 0; i < len(data); i++ {
            if data[i] == ',' {
                return i + 1, data[:i], nil
            }
        }
        if atEOF && len(data) > 0 {
            return len(data), data, nil
        }
        return 0, nil, nil
    })
    
    for scanner.Scan() {
        value := scanner.Text()
        fmt.Println("Value:", value)
    }
    
    return scanner.Err()
}
```

### Reading Specific Positions (Random Access)

Sometimes you need to read from a specific position in a file:

```go
func readAtPosition(filename string, offset int64) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Move to specific position
    // offset: how many bytes to move
    // whence: 0=from start, 1=from current, 2=from end
    newPos, err := file.Seek(offset, 0)
    if err != nil {
        return err
    }
    
    fmt.Printf("Now at position: %d\n", newPos)
    
    // Read from this position
    buffer := make([]byte, 100)
    n, err := file.Read(buffer)
    if err != nil && err.Error() != "EOF" {
        return err
    }
    
    fmt.Printf("Read %d bytes: %s\n", n, string(buffer[:n]))
    
    return nil
}

// Example: Read last 100 bytes of a file
func readTail(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Seek to 100 bytes before end
    file.Seek(-100, 2)  // 2 = from end
    
    buffer := make([]byte, 100)
    n, _ := file.Read(buffer)
    
    fmt.Println("Last 100 bytes:", string(buffer[:n]))
    
    return nil
}
```

### Reading Binary Files

For binary files (images, executables, etc.), you work with raw bytes:

```go
func readBinary(filename string) error {
    data, err := os.ReadFile(filename)
    if err != nil {
        return err
    }
    
    // For structured binary data, use encoding/binary
    // Example: reading a 32-bit integer from bytes
    if len(data) >= 4 {
        value := binary.LittleEndian.Uint32(data[0:4])
        fmt.Printf("First 4 bytes as uint32: %d\n", value)
    }
    
    return nil
}
```

### Memory-Mapped Files

For very large files that you need to access randomly, memory mapping can be more efficient than traditional I/O:

```go
import "syscall"

func mmapFile(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    info, _ := file.Stat()
    size := info.Size()
    
    // Memory map the file
    data, err := syscall.Mmap(
        int(file.Fd()),
        0,
        int(size),
        syscall.PROT_READ,
        syscall.MAP_SHARED,
    )
    if err != nil {
        return err
    }
    defer syscall.Munmap(data)
    
    // Now 'data' is a []byte that represents the file
    // Accessing data[i] reads directly from disk via OS page cache
    fmt.Printf("First byte: %c\n", data[0])
    
    return nil
}
```

Memory mapping tells the OS to treat the file as if it were in memory. The OS handles loading pages from disk as needed, which can be very efficient for random access patterns.

---

## Writing Files

Writing to files is just as important as reading. Go provides several methods depending on whether you want to create new files, append to existing ones, or completely replace file contents.

### Writing Complete Content at Once

The simplest way to write a file is to write all content in one operation:

```go
func writeEntireFile() error {
    content := []byte("Hello, World!\nThis is a test file.\n")
    
    // Method 1: os.WriteFile (Go 1.16+)
    // Creates file if doesn't exist, truncates if exists
    err := os.WriteFile("output.txt", content, 0644)
    if err != nil {
        return err
    }
    
    return nil
}
```

This is atomic at the write level—either the entire write succeeds or none of it does. However, if your program crashes between multiple `WriteFile` calls, you could end up with partial data.

### Creating and Writing to a New File

When you need more control over the writing process:

```go
func createAndWrite() error {
    // Create file (truncates if exists)
    file, err := os.Create("newfile.txt")
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Write bytes
    data := []byte("First line\n")
    n, err := file.Write(data)
    if err != nil {
        return err
    }
    fmt.Printf("Wrote %d bytes\n", n)
    
    // Write string
    n2, err := file.WriteString("Second line\n")
    if err != nil {
        return err
    }
    fmt.Printf("Wrote %d bytes\n", n2)
    
    return nil
}
```

**Understanding Write Operations**:

```
Before write:
File: (empty)
Buffer: "Hello"

After file.Write([]byte("Hello")):
File: "Hello"
Disk: might still be "Hello" in OS cache

After file.Sync():
File: "Hello"
Disk: "Hello" (forced to physical disk)
```

The `Write` method returns immediately after copying data to the OS buffer. The OS may not write to disk immediately for performance reasons. If you need to ensure data is on physical disk (for crash safety), call `Sync()`:

```go
file.Write(data)
file.Sync()  // Force write to disk
```

### Buffered Writing

For many small writes, buffering improves performance dramatically:

```go
func bufferedWrite() error {
    file, err := os.Create("buffered.txt")
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Create buffered writer
    writer := bufio.NewWriter(file)
    
    // Multiple writes go to buffer first
    for i := 0; i < 1000; i++ {
        fmt.Fprintf(writer, "Line %d\n", i)
    }
    
    // Must flush to ensure all data is written
    writer.Flush()
    
    return nil
}
```

**Buffered vs Unbuffered Writing**:

```
Unbuffered (1000 syscalls):
Write("Line 1") → syscall → OS
Write("Line 2") → syscall → OS
... (very slow)

Buffered (maybe 10 syscalls):
Write("Line 1") → buffer
Write("Line 2") → buffer
... (buffer fills)
Flush → syscall → OS (writes multiple lines)
... (much faster)
```

### Appending to Files

To add content to an existing file without deleting its current contents:

```go
func appendToFile(filename string) error {
    // Open with append flag
    file, err := os.OpenFile(filename, 
        os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Write to end of file
    if _, err := file.WriteString("Appended line\n"); err != nil {
        return err
    }
    
    return nil
}
```

The `O_APPEND` flag ensures that every write happens at the end of the file, even if multiple processes are writing simultaneously. This is important for log files.

### Writing Formatted Output

The `fmt` package provides formatted writing similar to `Printf`:

```go
func formattedWrite() error {
    file, err := os.Create("formatted.txt")
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Write formatted strings
    fmt.Fprintf(file, "Name: %s\n", "John")
    fmt.Fprintf(file, "Age: %d\n", 30)
    fmt.Fprintf(file, "Score: %.2f\n", 95.5)
    
    // Formatted output with bufio
    writer := bufio.NewWriter(file)
    fmt.Fprintf(writer, "Buffered: %v\n", []int{1, 2, 3})
    writer.Flush()
    
    return nil
}
```

### Writing Structured Data

For structured data like JSON or CSV:

```go
import (
    "encoding/json"
    "encoding/csv"
)

// Writing JSON
func writeJSON(filename string) error {
    data := map[string]interface{}{
        "name": "John",
        "age":  30,
        "scores": []int{95, 87, 92},
    }
    
    file, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    encoder := json.NewEncoder(file)
    encoder.SetIndent("", "  ")  // Pretty print
    return encoder.Encode(data)
}

// Writing CSV
func writeCSV(filename string) error {
    file, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    writer := csv.NewWriter(file)
    defer writer.Flush()
    
    // Write header
    writer.Write([]string{"Name", "Age", "City"})
    
    // Write rows
    records := [][]string{
        {"John", "30", "New York"},
        {"Jane", "25", "London"},
        {"Bob", "35", "Tokyo"},
    }
    
    for _, record := range records {
        if err := writer.Write(record); err != nil {
            return err
        }
    }
    
    return nil
}
```

### Atomic File Writes

For critical files, you want atomic writes—either the new content is written completely, or the old content remains unchanged:

```go
func atomicWrite(filename string, data []byte) error {
    // Write to temporary file
    tmpfile, err := os.CreateTemp("", "atomic-")
    if err != nil {
        return err
    }
    tmpname := tmpfile.Name()
    
    defer func() {
        tmpfile.Close()
        os.Remove(tmpname)  // Clean up on error
    }()
    
    // Write data to temp file
    if _, err := tmpfile.Write(data); err != nil {
        return err
    }
    
    // Sync to disk
    if err := tmpfile.Sync(); err != nil {
        return err
    }
    
    tmpfile.Close()
    
    // Atomic rename
    if err := os.Rename(tmpname, filename); err != nil {
        return err
    }
    
    return nil
}
```

The `os.Rename` operation is atomic on most systems—it either completely succeeds or fails, preventing corruption if the process crashes during the write.

### Writing Binary Data

For binary files, you work with raw bytes and often use the `encoding/binary` package:

```go
import "encoding/binary"

func writeBinary(filename string) error {
    file, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Write a 32-bit integer
    var num uint32 = 12345
    err = binary.Write(file, binary.LittleEndian, num)
    if err != nil {
        return err
    }
    
    // Write a slice of integers
    numbers := []uint16{100, 200, 300}
    err = binary.Write(file, binary.LittleEndian, numbers)
    if err != nil {
        return err
    }
    
    return nil
}
```

---

## Updating Files

Updating files is more complex than just reading or writing because you need to modify existing content without necessarily recreating the entire file.

### In-Place Updates (Seek and Write)

For small updates at known positions, you can seek to the position and overwrite:

```go
func updateAtPosition(filename string, position int64, data []byte) error {
    file, err := os.OpenFile(filename, os.O_RDWR, 0644)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Move to position
    _, err = file.Seek(position, 0)
    if err != nil {
        return err
    }
    
    // Write new data
    _, err = file.Write(data)
    return err
}

// Example: Change character at position 10
func changeCharacter(filename string) error {
    return updateAtPosition(filename, 10, []byte("X"))
}
```

**Important**: This overwrites existing bytes. If you write 3 bytes at position 10, bytes 10, 11, and 12 are replaced. The file size doesn't change unless you write past the end.

### Read-Modify-Write Pattern

The safest way to update files is to read the entire content, modify it in memory, then write it back:

```go
func replaceText(filename, old, new string) error {
    // Read entire file
    content, err := os.ReadFile(filename)
    if err != nil {
        return err
    }
    
    // Modify content
    modified := bytes.ReplaceAll(content, []byte(old), []byte(new))
    
    // Write back
    return os.WriteFile(filename, modified, 0644)
}
```

This approach is simple and safe but requires loading the entire file into memory. For large files, you need a different strategy.

### Line-by-Line Updates

For large files, process line by line and write to a temporary file:

```go
func updateLines(inputFile, outputFile string, updateFunc func(string) string) error {
    input, err := os.Open(inputFile)
    if err != nil {
        return err
    }
    defer input.Close()
    
    output, err := os.Create(outputFile)
    if err != nil {
        return err
    }
    defer output.Close()
    
    scanner := bufio.NewScanner(input)
    writer := bufio.NewWriter(output)
    defer writer.Flush()
    
    for scanner.Scan() {
        line := scanner.Text()
        newLine := updateFunc(line)
        fmt.Fprintln(writer, newLine)
    }
    
    return scanner.Err()
}

// Usage
func example() {
    updateLines("input.txt", "output.txt", func(line string) string {
        // Transform each line
        return strings.ToUpper(line)
    })
}
```

### Inserting Content

Inserting content in the middle of a file requires rewriting everything after the insertion point:

```go
func insertAtLine(filename string, lineNum int, content string) error {
    // Read all lines
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    
    var lines []string
    scanner := bufio.NewScanner(file)
    for scanner.Scan() {
        lines = append(lines, scanner.Text())
    }
    file.Close()
    
    if err := scanner.Err(); err != nil {
        return err
    }
    
    // Insert new line
    if lineNum > len(lines) {
        lineNum = len(lines)
    }
    lines = append(lines[:lineNum], append([]string{content}, lines[lineNum:]...)...)
    
    // Write back
    output, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer output.Close()
    
    writer := bufio.NewWriter(output)
    for _, line := range lines {
        fmt.Fprintln(writer, line)
    }
    writer.Flush()
    
    return nil
}
```

### Appending vs Prepending

Appending is efficient because you just write to the end. Prepending requires rewriting the entire file:

```go
// Efficient: Append to end
func appendLine(filename, line string) error {
    file, err := os.OpenFile(filename, os.O_APPEND|os.O_WRONLY|os.O_CREATE, 0644)
    if err != nil {
        return err
    }
    defer file.Close()
    
    _, err = fmt.Fprintln(file, line)
    return err
}

// Inefficient: Prepend to beginning (must rewrite entire file)
func prependLine(filename, line string) error {
    content, err := os.ReadFile(filename)
    if err != nil {
        return err
    }
    
    newContent := []byte(line + "\n")
    newContent = append(newContent, content...)
    
    return os.WriteFile(filename, newContent, 0644)
}
```

### Updating Structured Files (JSON)

For structured files like JSON, you read, parse, modify, and write back:

```go
func updateJSON(filename string) error {
    // Read existing JSON
    data, err := os.ReadFile(filename)
    if err != nil {
        return err
    }
    
    // Parse JSON
    var config map[string]interface{}
    if err := json.Unmarshal(data, &config); err != nil {
        return err
    }
    
    // Modify
    config["updated"] = time.Now().String()
    config["version"] = 2
    
    // Write back
    file, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    encoder := json.NewEncoder(file)
    encoder.SetIndent("", "  ")
    return encoder.Encode(config)
}
```

### Safe Update with Backup

A robust update strategy creates a backup before modifying:

```go
func safeUpdate(filename string, updateFunc func([]byte) []byte) error {
    // Read original
    original, err := os.ReadFile(filename)
    if err != nil {
        return err
    }
    
    // Create backup
    backupName := filename + ".backup"
    if err := os.WriteFile(backupName, original, 0644); err != nil {
        return err
    }
    
    // Modify content
    modified := updateFunc(original)
    
    // Write new content
    if err := os.WriteFile(filename, modified, 0644); err != nil {
        // Restore from backup on error
        os.WriteFile(filename, original, 0644)
        return err
    }
    
    // Remove backup on success (optional)
    // os.Remove(backupName)
    
    return nil
}
```

### Updating with File Locking

For concurrent access, you need file locking to prevent race conditions:

```go
import "syscall"

func updateWithLock(filename string) error {
    file, err := os.OpenFile(filename, os.O_RDWR, 0644)
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Acquire exclusive lock
    err = syscall.Flock(int(file.Fd()), syscall.LOCK_EX)
    if err != nil {
        return err
    }
    defer syscall.Flock(int(file.Fd()), syscall.LOCK_UN)
    
    // Now safely read, modify, and write
    // Other processes will wait for the lock
    
    return nil
}
```

---

## Deleting Files

Deleting files and managing cleanup are important aspects of file system operations. Go provides straightforward methods for deletion, but you need to understand the implications and edge cases.

### Deleting a Single File

The simplest deletion operation:

```go
func deleteFile(filename string) error {
    err := os.Remove(filename)
    if err != nil {
        if os.IsNotExist(err) {
            return fmt.Errorf("file does not exist: %s", filename)
        }
        return err
    }
    
    fmt.Println("File deleted successfully")
    return nil
}
```

**Important**: `os.Remove` fails if the file is a non-empty directory. For directories, use `os.RemoveAll`.

### Safe Deletion (Check Before Delete)

Always verify before deleting:

```go
func safeDelete(filename string) error {
    // Check if file exists
    info, err := os.Stat(filename)
    if err != nil {
        if os.IsNotExist(err) {
            return fmt.Errorf("file does not exist")
        }
        return err
    }
    
    // Check if it's actually a file (not a directory)
    if info.IsDir() {
        return fmt.Errorf("cannot delete: %s is a directory", filename)
    }
    
    // Confirm deletion (in real apps, prompt user)
    fmt.Printf("Delete %s? (size: %d bytes)\n", filename, info.Size())
    
    return os.Remove(filename)
}
```

### Deleting Multiple Files

Using patterns to delete multiple files:

```go
import "path/filepath"

func deleteByPattern(pattern string) error {
    // Find all matching files
    matches, err := filepath.Glob(pattern)
    if err != nil {
        return err
    }
    
    if len(matches) == 0 {
        return fmt.Errorf("no files match pattern: %s", pattern)
    }
    
    // Delete each file
    for _, match := range matches {
        fmt.Printf("Deleting: %s\n", match)
        if err := os.Remove(match); err != nil {
            fmt.Printf("Error deleting %s: %v\n", match, err)
        }
    }
    
    return nil
}

// Examples:
// deleteByPattern("*.tmp")           // Delete all .tmp files
// deleteByPattern("log_*.txt")       // Delete log files
// deleteByPattern("/tmp/cache_*")    // Delete cache files
```

### Deleting Old Files

Delete files older than a certain age:

```go
func deleteOldFiles(dir string, maxAge time.Duration) error {
    entries, err := os.ReadDir(dir)
    if err != nil {
        return err
    }
    
    cutoffTime := time.Now().Add(-maxAge)
    
    for _, entry := range entries {
        if entry.IsDir() {
            continue
        }
        
        info, err := entry.Info()
        if err != nil {
            continue
        }
        
        if info.ModTime().Before(cutoffTime) {
            fullPath := filepath.Join(dir, entry.Name())
            fmt.Printf("Deleting old file: %s (modified: %v)\n", 
                fullPath, info.ModTime())
            os.Remove(fullPath)
        }
    }
    
    return nil
}

// Usage: Delete files older than 7 days
// deleteOldFiles("/tmp/cache", 7*24*time.Hour)
```

### Moving Files to Trash (Soft Delete)

Instead of permanent deletion, move files to a trash directory:

```go
func moveToTrash(filename string) error {
    trashDir := "/tmp/trash"
    
    // Create trash directory if it doesn't exist
    if err := os.MkdirAll(trashDir, 0755); err != nil {
        return err
    }
    
    // Generate unique name in trash
    baseName := filepath.Base(filename)
    timestamp := time.Now().Format("20060102_150405")
    trashPath := filepath.Join(trashDir, 
        fmt.Sprintf("%s_%s", timestamp, baseName))
    
    // Move file
    if err := os.Rename(filename, trashPath); err != nil {
        return err
    }
    
    fmt.Printf("Moved to trash: %s\n", trashPath)
    return nil
}
```

### Secure Deletion (Overwrite Before Delete)

For sensitive files, overwrite content before deletion:

```go
func secureDelete(filename string) error {
    // Get file size
    info, err := os.Stat(filename)
    if err != nil {
        return err
    }
    size := info.Size()
    
    // Open file for writing
    file, err := os.OpenFile(filename, os.O_WRONLY, 0)
    if err != nil {
        return err
    }
    
    // Overwrite with random data (3 passes)
    for pass := 0; pass < 3; pass++ {
        file.Seek(0, 0)
        
        // Write random bytes
        buffer := make([]byte, 4096)
        remaining := size
        
        for remaining > 0 {
            toWrite := int64(len(buffer))
            if remaining < toWrite {
                toWrite = remaining
            }
            
            rand.Read(buffer[:toWrite])
            file.Write(buffer[:toWrite])
            remaining -= toWrite
        }
        
        file.Sync()
    }
    
    file.Close()
    
    // Finally, delete the file
    return os.Remove(filename)
}
```

### Handling Deletion Errors

Different types of errors and how to handle them:

```go
func robustDelete(filename string) error {
    err := os.Remove(filename)
    if err == nil {
        return nil
    }
    
    // File doesn't exist - not necessarily an error
    if os.IsNotExist(err) {
        fmt.Println("File already deleted or doesn't exist")
        return nil
    }
    
    // Permission denied
    if os.IsPermission(err) {
        return fmt.Errorf("permission denied: cannot delete %s", filename)
    }
    
    // File is in use (Windows)
    if strings.Contains(err.Error(), "used by another process") {
        return fmt.Errorf("file is currently in use: %s", filename)
    }
    
    return fmt.Errorf("unexpected error deleting file: %v", err)
}
```

---

## Line Filtering and Processing

Processing files line by line is a common task, especially for log files, CSV files, and configuration files. Go provides excellent tools for this through the `bufio` package.

### Basic Line-by-Line Reading

The fundamental pattern for processing lines:

```go
func processLines(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    scanner := bufio.NewScanner(file)
    lineNum := 0
    
    for scanner.Scan() {
        lineNum++
        line := scanner.Text()
        
        // Process each line
        fmt.Printf("Line %d: %s\n", lineNum, line)
    }
    
    return scanner.Err()
}
```

### Filtering Lines by Content

Filter lines that match certain criteria:

```go
func filterLines(inputFile, outputFile string, predicate func(string) bool) error {
    input, err := os.Open(inputFile)
    if err != nil {
        return err
    }
    defer input.Close()
    
    output, err := os.Create(outputFile)
    if err != nil {
        return err
    }
    defer output.Close()
    
    scanner := bufio.NewScanner(input)
    writer := bufio.NewWriter(output)
    defer writer.Flush()
    
    for scanner.Scan() {
        line := scanner.Text()
        if predicate(line) {
            fmt.Fprintln(writer, line)
        }
    }
    
    return scanner.Err()
}

// Usage examples:
func examples() {
    // Filter lines containing "ERROR"
    filterLines("app.log", "errors.log", func(line string) bool {
        return strings.Contains(line, "ERROR")
    })
    
    // Filter non-empty lines
    filterLines("input.txt", "output.txt", func(line string) bool {
        return strings.TrimSpace(line) != ""
    })
    
    // Filter lines starting with "#"
    filterLines("config.txt", "clean.txt", func(line string) bool {
        return !strings.HasPrefix(strings.TrimSpace(line), "#")
    })
}
```

### Grep-like Functionality

Implement a simple grep (search) tool:

```go
func grep(filename, pattern string, caseSensitive bool) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    scanner := bufio.NewScanner(file)
    lineNum := 0
    
    for scanner.Scan() {
        lineNum++
        line := scanner.Text()
        
        searchLine := line
        searchPattern := pattern
        
        if !caseSensitive {
            searchLine = strings.ToLower(line)
            searchPattern = strings.ToLower(pattern)
        }
        
        if strings.Contains(searchLine, searchPattern) {
            fmt.Printf("%d: %s\n", lineNum, line)
        }
    }
    
    return scanner.Err()
}

// With regular expressions
func grepRegex(filename, pattern string) error {
    regex, err := regexp.Compile(pattern)
    if err != nil {
        return err
    }
    
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    scanner := bufio.NewScanner(file)
    lineNum := 0
    
    for scanner.Scan() {
        lineNum++
        line := scanner.Text()
        
        if regex.MatchString(line) {
            // Highlight matches
            highlighted := regex.ReplaceAllString(line, 
                "\033[1;31m$0\033[0m")  // Red color
            fmt.Printf("%d: %s\n", lineNum, highlighted)
        }
    }
    
    return scanner.Err()
}
```

### Transforming Lines

Apply transformations to each line:

```go
func transformLines(inputFile, outputFile string, 
                   transform func(string) string) error {
    input, err := os.Open(inputFile)
    if err != nil {
        return err
    }
    defer input.Close()
    
    output, err := os.Create(outputFile)
    if err != nil {
        return err
    }
    defer output.Close()
    
    scanner := bufio.NewScanner(input)
    writer := bufio.NewWriter(output)
    defer writer.Flush()
    
    for scanner.Scan() {
        line := scanner.Text()
        transformed := transform(line)
        fmt.Fprintln(writer, transformed)
    }
    
    return scanner.Err()
}

// Usage examples:
func transformExamples() {
    // Convert to uppercase
    transformLines("input.txt", "output.txt", strings.ToUpper)
    
    // Add line numbers
    lineNum := 0
    transformLines("input.txt", "numbered.txt", func(line string) string {
        lineNum++
        return fmt.Sprintf("%4d: %s", lineNum, line)
    })
    
    // Remove leading/trailing whitespace
    transformLines("input.txt", "trimmed.txt", strings.TrimSpace)
}
```

### Aggregating Data from Lines

Collect statistics or aggregate data:

```go
func analyzeFile(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    scanner := bufio.NewScanner(file)
    
    stats := struct {
        TotalLines   int
        TotalWords   int
        TotalChars   int
        EmptyLines   int
        LongestLine  int
    }{}
    
    for scanner.Scan() {
        line := scanner.Text()
        stats.TotalLines++
        stats.TotalChars += len(line)
        
        if strings.TrimSpace(line) == "" {
            stats.EmptyLines++
        } else {
            words := strings.Fields(line)
            stats.TotalWords += len(words)
        }
        
        if len(line) > stats.LongestLine {
            stats.LongestLine = len(line)
        }
    }
    
    fmt.Printf("File Statistics:\n")
    fmt.Printf("Total Lines: %d\n", stats.TotalLines)
    fmt.Printf("Total Words: %d\n", stats.TotalWords)
    fmt.Printf("Total Characters: %d\n", stats.TotalChars)
    fmt.Printf("Empty Lines: %d\n", stats.EmptyLines)
    fmt.Printf("Longest Line: %d characters\n", stats.LongestLine)
    
    return scanner.Err()
}
```

### Processing CSV Files

Handle comma-separated values with filtering:

```go
import "encoding/csv"

func filterCSV(inputFile, outputFile string, 
               filter func([]string) bool) error {
    input, err := os.Open(inputFile)
    if err != nil {
        return err
    }
    defer input.Close()
    
    output, err := os.Create(outputFile)
    if err != nil {
        return err
    }
    defer output.Close()
    
    reader := csv.NewReader(input)
    writer := csv.NewWriter(output)
    defer writer.Flush()
    
    // Read header
    header, err := reader.Read()
    if err != nil {
        return err
    }
    writer.Write(header)
    
    // Process records
    for {
        record, err := reader.Read()
        if err == io.EOF {
            break
        }
        if err != nil {
            return err
        }
        
        if filter(record) {
            writer.Write(record)
        }
    }
    
    return nil
}

// Example: Filter CSV rows where age > 30
func filterCSVExample() {
    filterCSV("people.csv", "adults.csv", func(record []string) bool {
        if len(record) < 2 {
            return false
        }
        age, _ := strconv.Atoi(record[1])
        return age > 30
    })
}
```

### Parallel Line Processing

For CPU-intensive processing, use goroutines:

```go
func parallelProcess(filename string, workers int) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    lines := make(chan string, 100)
    results := make(chan string, 100)
    var wg sync.WaitGroup
    
    // Start workers
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for line := range lines {
                // Process line (CPU-intensive work)
                processed := heavyProcessing(line)
                results <- processed
            }
        }()
    }
    
    // Read lines
    go func() {
        scanner := bufio.NewScanner(file)
        for scanner.Scan() {
            lines <- scanner.Text()
        }
        close(lines)
    }()
    
    // Close results when workers done
    go func() {
        wg.Wait()
        close(results)
    }()
    
    // Collect results
    for result := range results {
        fmt.Println(result)
    }
    
    return nil
}

func heavyProcessing(line string) string {
    // Simulate expensive operation
    time.Sleep(10 * time.Millisecond)
    return strings.ToUpper(line)
}
```

### Streaming Large Files

For files too large to fit in memory, stream and process:

```go
func streamProcess(filename string, 
                  processor func(string) error) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    scanner := bufio.NewScanner(file)
    
    // Increase buffer size for long lines
    buf := make([]byte, 0, 1024*1024)  // 1MB buffer
    scanner.Buffer(buf, 10*1024*1024)  // Max 10MB per line
    
    for scanner.Scan() {
        line := scanner.Text()
        
        if err := processor(line); err != nil {
            return err
        }
        
        // Process and discard, don't accumulate in memory
    }
    
    return scanner.Err()
}
```

---

## Directory Operations

Directories (folders) organize files into a hierarchical structure. Go provides comprehensive tools for creating, reading, traversing, and managing directories.

### Creating Directories

Different ways to create directories:

```go
func createDirectories() error {
    // Create a single directory
    // Fails if parent doesn't exist
    err := os.Mkdir("newdir", 0755)
    if err != nil {
        return err
    }
    
    // Create directory with all parent directories
    // Like "mkdir -p" in Unix
    err = os.MkdirAll("path/to/nested/dir", 0755)
    if err != nil {
        return err
    }
    
    // Check if directory already exists
    err = os.MkdirAll("mydir", 0755)
    if err != nil && !os.IsExist(err) {
        return err
    }
    
    return nil
}
```

**Directory Permissions**: The permission `0755` means:

- Owner: read, write, execute (7 = 111 binary)
- Group: read, execute (5 = 101 binary)
- Others: read, execute (5 = 101 binary)

Execute permission on directories means you can enter the directory and list its contents.

### Listing Directory Contents

Read what's inside a directory:

```go
func listDirectory(dirPath string) error {
    // Method 1: ReadDir (Go 1.16+, more efficient)
    entries, err := os.ReadDir(dirPath)
    if err != nil {
        return err
    }
    
    for _, entry := range entries {
        info, _ := entry.Info()
        
        typeStr := "F"
        if entry.IsDir() {
            typeStr = "D"
        }
        
        fmt.Printf("[%s] %s (%d bytes)\n", 
            typeStr, entry.Name(), info.Size())
    }
    
    return nil
}

// Method 2: With full file info
func listDirectoryDetailed(dirPath string) error {
    files, err := os.ReadDir(dirPath)
    if err != nil {
        return err
    }
    
    for _, file := range files {
        info, _ := file.Info()
        
        fmt.Printf("%-30s %10d bytes  %s\n",
            file.Name(),
            info.Size(),
            info.ModTime().Format("2006-01-02 15:04:05"))
    }
    
    return nil
}
```

### Walking Directory Trees

Recursively traverse directories and subdirectories:

```go
func walkDirectory(root string) error {
    return filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        
        // Calculate depth
        depth := strings.Count(path, string(filepath.Separator)) - 
                 strings.Count(root, string(filepath.Separator))
        indent := strings.Repeat("  ", depth)
        
        if info.IsDir() {
            fmt.Printf("%s[DIR]  %s\n", indent, info.Name())
        } else {
            fmt.Printf("%s[FILE] %s (%d bytes)\n", 
                indent, info.Name(), info.Size())
        }
        
        return nil
    })
}

// Walk with filtering
func walkFiltered(root string, filter func(string) bool) error {
    return filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        
        if !info.IsDir() && filter(path) {
            fmt.Println(path)
        }
        
        return nil
    })
}

// Examples:
func walkExamples() {
    // Find all .txt files
    walkFiltered("/home/user", func(path string) bool {
        return filepath.Ext(path) == ".txt"
    })
    
    // Find all files larger than 1MB
    walkFiltered("/var/log", func(path string) bool {
        info, _ := os.Stat(path)
        return info.Size() > 1024*1024
    })
}
```

### Finding Files

Implement a find command:

```go
func findFiles(root, pattern string) ([]string, error) {
    var matches []string
    
    err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return nil  // Continue on errors
        }
        
        if info.IsDir() {
            return nil
        }
        
        matched, err := filepath.Match(pattern, filepath.Base(path))
        if err != nil {
            return err
        }
        
        if matched {
            matches = append(matches, path)
        }
        
        return nil
    })
    
    return matches, err
}

// Find with multiple criteria
type FindCriteria struct {
    Name      string
    MinSize   int64
    MaxSize   int64
    Extension string
    ModAfter  time.Time
}

func findWithCriteria(root string, criteria FindCriteria) ([]string, error) {
    var matches []string
    
    err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return nil
        }
        
        // Check name pattern
        if criteria.Name != "" {
            matched, _ := filepath.Match(criteria.Name, info.Name())
            if !matched {
                return nil
            }
        }
        
        // Check size
        if criteria.MinSize > 0 && info.Size() < criteria.MinSize {
            return nil
        }
        if criteria.MaxSize > 0 && info.Size() > criteria.MaxSize {
            return nil
        }
        
        // Check extension
        if criteria.Extension != "" && 
           filepath.Ext(path) != criteria.Extension {
            return nil
        }
        
        // Check modification time
        if !criteria.ModAfter.IsZero() && 
           info.ModTime().Before(criteria.ModAfter) {
            return nil
        }
        
        matches = append(matches, path)
        return nil
    })
    
    return matches, err
}
```

### Copying Directories

Recursively copy entire directory trees:

```go
func copyDirectory(src, dst string) error {
    // Get source directory info
    srcInfo, err := os.Stat(src)
    if err != nil {
        return err
    }
    
    // Create destination directory
    err = os.MkdirAll(dst, srcInfo.Mode())
    if err != nil {
        return err
    }
    
    // Read source directory
    entries, err := os.ReadDir(src)
    if err != nil {
        return err
    }
    
    for _, entry := range entries {
        srcPath := filepath.Join(src, entry.Name())
        dstPath := filepath.Join(dst, entry.Name())
        
        if entry.IsDir() {
            // Recursively copy subdirectory
            err = copyDirectory(srcPath, dstPath)
            if err != nil {
                return err
            }
        } else {
            // Copy file
            err = copyFile(srcPath, dstPath)
            if err != nil {
                return err
            }
        }
    }
    
    return nil
}

func copyFile(src, dst string) error {
    sourceFile, err := os.Open(src)
    if err != nil {
        return err
    }
    defer sourceFile.Close()
    
    destFile, err := os.Create(dst)
    if err != nil {
        return err
    }
    defer destFile.Close()
    
    _, err = io.Copy(destFile, sourceFile)
    if err != nil {
        return err
    }
    
    // Copy permissions
    srcInfo, _ := os.Stat(src)
    return os.Chmod(dst, srcInfo.Mode())
}
```

### Deleting Directories

Remove directories and their contents:

```go
func deleteDirectory(path string) error {
    // Check if exists
    info, err := os.Stat(path)
    if err != nil {
        return err
    }
    
    if !info.IsDir() {
        return fmt.Errorf("%s is not a directory", path)
    }
    
    // Remove directory and all contents
    return os.RemoveAll(path)
}

// Safe delete with confirmation
func safeDeleteDirectory(path string) error {
    // Count files to delete
    count := 0
    totalSize := int64(0)
    
    filepath.Walk(path, func(_ string, info os.FileInfo, err error) error {
        if err == nil && !info.IsDir() {
            count++
            totalSize += info.Size()
        }
        return nil
    })
    
    fmt.Printf("About to delete %d files (%d bytes) from %s\n", 
        count, totalSize, path)
    fmt.Print("Continue? (y/n): ")
    
    var response string
    fmt.Scanln(&response)
    
    if strings.ToLower(response) != "y" {
        return fmt.Errorf("deletion cancelled")
    }
    
    return os.RemoveAll(path)
}
```

### Getting Directory Size

Calculate total size of a directory:

```go
func directorySize(path string) (int64, error) {
    var size int64
    
    err := filepath.Walk(path, func(_ string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        if !info.IsDir() {
            size += info.Size()
        }
        return nil
    })
    
    return size, err
}

// With detailed breakdown
func directorySizeDetailed(path string) error {
    sizes := make(map[string]int64)
    fileCount := make(map[string]int)
    
    err := filepath.Walk(path, func(filePath string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        
        ext := filepath.Ext(filePath)
        if ext == "" {
            ext = "[no extension]"
        }
        
        if !info.IsDir() {
            sizes[ext] += info.Size()
            fileCount[ext]++
        }
        
        return nil
    })
    
    if err != nil {
        return err
    }
    
    fmt.Println
if err != nil { return err }

fmt.Println("Directory size breakdown:")
fmt.Println("Extension          Files    Total Size")
fmt.Println("----------------------------------------")

for ext, size := range sizes {
    fmt.Printf("%-15s %5d    %10d bytes\n", ext, fileCount[ext], size)
}

return nil
}
````

### Watching Directories for Changes

Monitor directories for file system events (Note: This example uses a polling approach. For production, consider using `github.com/fsnotify/fsnotify`):

```go
type FileSnapshot struct {
    Path    string
    ModTime time.Time
    Size    int64
}

func watchDirectorySimple(dir string, interval time.Duration, callback func(string, string)) {
    snapshots := make(map[string]FileSnapshot)
    
    // Initial scan
    filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }
        snapshots[path] = FileSnapshot{path, info.ModTime(), info.Size()}
        return nil
    })
    
    ticker := time.NewTicker(interval)
    defer ticker.Stop()
    
    for range ticker.C {
        currentFiles := make(map[string]FileSnapshot)
        
        // Scan current state
        filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
            if err != nil || info.IsDir() {
                return err
            }
            
            snapshot := FileSnapshot{path, info.ModTime(), info.Size()}
            currentFiles[path] = snapshot
            
            // Check for changes
            if old, exists := snapshots[path]; exists {
                if snapshot.ModTime.After(old.ModTime) || snapshot.Size != old.Size {
                    callback(path, "modified")
                }
            } else {
                callback(path, "created")
            }
            
            return nil
        })
        
        // Check for deleted files
        for path := range snapshots {
            if _, exists := currentFiles[path]; !exists {
                callback(path, "deleted")
            }
        }
        
        snapshots = currentFiles
    }
}

// Usage
func main() {
    watchDirectorySimple("/tmp/watched", 2*time.Second, func(path, event string) {
        fmt.Printf("[%s] %s: %s\n", time.Now().Format("15:04:05"), event, path)
    })
}
````

### Creating Directory Structures

Build complex directory hierarchies:

```go
func createProjectStructure(root string) error {
    structure := []string{
        "src/main",
        "src/utils",
        "tests/unit",
        "tests/integration",
        "docs",
        "config",
        "build/output",
        "logs",
    }
    
    for _, dir := range structure {
        path := filepath.Join(root, dir)
        if err := os.MkdirAll(path, 0755); err != nil {
            return err
        }
        fmt.Println("Created:", path)
    }
    
    return nil
}

// With template files
func createProjectWithFiles(root string) error {
    structure := map[string]string{
        "src/main.go":        "package main\n\nfunc main() {\n}\n",
        "README.md":          "# Project\n\nDescription here\n",
        "go.mod":             "module myproject\n\ngo 1.21\n",
        ".gitignore":         "*.log\nbuild/\n",
        "config/app.json":   "{\n  \"port\": 8080\n}\n",
    }
    
    for filePath, content := range structure {
        fullPath := filepath.Join(root, filePath)
        
        // Create parent directory
        dir := filepath.Dir(fullPath)
        if err := os.MkdirAll(dir, 0755); err != nil {
            return err
        }
        
        // Write file
        if err := os.WriteFile(fullPath, []byte(content), 0644); err != nil {
            return err
        }
        
        fmt.Println("Created:", fullPath)
    }
    
    return nil
}
```

---

## Temporary Files and Directories

Temporary files and directories are essential for storing intermediate data, caching, and testing. They're automatically cleaned up by the operating system and should be used when you need short-lived storage.

### Creating Temporary Files

Go provides built-in functions for creating temporary files:

```go
func createTempFile() error {
    // Create temp file in default temp directory
    tmpFile, err := os.CreateTemp("", "prefix-")
    if err != nil {
        return err
    }
    defer os.Remove(tmpFile.Name())  // Clean up
    defer tmpFile.Close()
    
    fmt.Println("Temp file created:", tmpFile.Name())
    // On Unix: /tmp/prefix-123456789
    // On Windows: C:\Users\...\AppData\Local\Temp\prefix-123456789
    
    // Write to temp file
    if _, err := tmpFile.Write([]byte("temporary data")); err != nil {
        return err
    }
    
    return nil
}

// Create temp file in specific directory
func createTempFileInDir(dir string) error {
    tmpFile, err := os.CreateTemp(dir, "myapp-*.txt")
    if err != nil {
        return err
    }
    defer os.Remove(tmpFile.Name())
    defer tmpFile.Close()
    
    // The * in pattern is replaced with random string
    fmt.Println("Created:", tmpFile.Name())
    // Example: myapp-abc123def456.txt
    
    return nil
}
```

**Understanding Temp File Names**: The pattern `"prefix-"` creates files like `prefix-123456789`. The pattern `"prefix-*.txt"` creates files like `prefix-abc123.txt`. The random portion ensures uniqueness.

### Creating Temporary Directories

Similar to files, but for directories:

```go
func createTempDir() error {
    // Create temp directory
    tmpDir, err := os.MkdirTemp("", "myapp-")
    if err != nil {
        return err
    }
    defer os.RemoveAll(tmpDir)  // Clean up
    
    fmt.Println("Temp directory:", tmpDir)
    
    // Use the temp directory
    filePath := filepath.Join(tmpDir, "data.txt")
    if err := os.WriteFile(filePath, []byte("test"), 0644); err != nil {
        return err
    }
    
    return nil
}

// Working directory for batch operations
func processBatch(files []string) error {
    // Create temp workspace
    workDir, err := os.MkdirTemp("", "batch-")
    if err != nil {
        return err
    }
    defer os.RemoveAll(workDir)
    
    // Process files in temp directory
    for i, file := range files {
        // Copy file to workspace
        destPath := filepath.Join(workDir, fmt.Sprintf("file_%d.tmp", i))
        copyFile(file, destPath)
        
        // Process...
    }
    
    return nil
}
```

### Getting System Temp Directory

Find where the OS stores temporary files:

```go
func getTempDir() {
    // Get system temp directory
    tmpDir := os.TempDir()
    fmt.Println("System temp directory:", tmpDir)
    // Unix/Linux: /tmp
    // macOS: /var/folders/...
    // Windows: C:\Users\...\AppData\Local\Temp
    
    // Check if writable
    testFile := filepath.Join(tmpDir, "write-test")
    if err := os.WriteFile(testFile, []byte("test"), 0644); err != nil {
        fmt.Println("Cannot write to temp directory")
    } else {
        os.Remove(testFile)
        fmt.Println("Temp directory is writable")
    }
}
```

### Safe Temporary File Operations

Ensure proper cleanup even on errors:

```go
func safeTempFileOperation() error {
    tmpFile, err := os.CreateTemp("", "safe-")
    if err != nil {
        return err
    }
    
    // Ensure cleanup happens even if function panics
    defer func() {
        tmpFile.Close()
        os.Remove(tmpFile.Name())
    }()
    
    // Do work that might fail
    if err := riskyOperation(tmpFile); err != nil {
        return err
    }
    
    return nil
}

func riskyOperation(f *os.File) error {
    // Operations that might panic or fail
    _, err := f.WriteString("data")
    return err
}
```

### Temp Files for Testing

Temporary files are perfect for unit tests:

```go
import "testing"

func TestFileProcessing(t *testing.T) {
    // Create temp file with test data
    tmpFile, err := os.CreateTemp("", "test-")
    if err != nil {
        t.Fatal(err)
    }
    defer os.Remove(tmpFile.Name())
    
    // Write test data
    testData := "line 1\nline 2\nline 3\n"
    if _, err := tmpFile.WriteString(testData); err != nil {
        t.Fatal(err)
    }
    tmpFile.Close()
    
    // Test your function
    result, err := processFile(tmpFile.Name())
    if err != nil {
        t.Error(err)
    }
    
    // Verify result
    expected := 3
    if result != expected {
        t.Errorf("Expected %d lines, got %d", expected, result)
    }
}
```

### Temp Files with Automatic Cleanup

Use context for automatic cleanup:

```go
import "context"

func withTempFile(ctx context.Context, fn func(*os.File) error) error {
    tmpFile, err := os.CreateTemp("", "ctx-")
    if err != nil {
        return err
    }
    
    // Cleanup when context is done
    go func() {
        <-ctx.Done()
        tmpFile.Close()
        os.Remove(tmpFile.Name())
    }()
    
    return fn(tmpFile)
}

// Usage
func example() {
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    err := withTempFile(ctx, func(f *os.File) error {
        _, err := f.WriteString("data")
        return err
    })
    
    if err != nil {
        fmt.Println("Error:", err)
    }
}
```

### Temporary Cache Directory

Create a cache directory that persists across runs but can be cleaned up:

```go
func getCacheDir(appName string) (string, error) {
    // Get user cache directory
    cacheRoot, err := os.UserCacheDir()
    if err != nil {
        // Fallback to temp directory
        cacheRoot = os.TempDir()
    }
    
    // Create app-specific cache directory
    cacheDir := filepath.Join(cacheRoot, appName)
    if err := os.MkdirAll(cacheDir, 0755); err != nil {
        return "", err
    }
    
    return cacheDir, nil
}

func cleanOldCache(cacheDir string, maxAge time.Duration) error {
    entries, err := os.ReadDir(cacheDir)
    if err != nil {
        return err
    }
    
    cutoff := time.Now().Add(-maxAge)
    
    for _, entry := range entries {
        info, err := entry.Info()
        if err != nil {
            continue
        }
        
        if info.ModTime().Before(cutoff) {
            path := filepath.Join(cacheDir, entry.Name())
            os.RemoveAll(path)
        }
    }
    
    return nil
}
```

### Temp Files for Large Data Processing

When processing data that doesn't fit in memory:

```go
import "sort"

func processSortedData(inputFile string) error {
    // Read data
    data, err := readLargeDataFile(inputFile)
    if err != nil {
        return err
    }
    
    // Sort in chunks and write to temp files
    chunkSize := 10000
    var tempFiles []string
    
    for i := 0; i < len(data); i += chunkSize {
        end := i + chunkSize
        if end > len(data) {
            end = len(data)
        }
        
        chunk := data[i:end]
        sort.Strings(chunk)
        
        // Write sorted chunk to temp file
        tmpFile, err := os.CreateTemp("", "chunk-")
        if err != nil {
            return err
        }
        tempFiles = append(tempFiles, tmpFile.Name())
        
        for _, line := range chunk {
            fmt.Fprintln(tmpFile, line)
        }
        tmpFile.Close()
    }
    
    // Clean up temp files
    defer func() {
        for _, tmpFile := range tempFiles {
            os.Remove(tmpFile)
        }
    }()
    
    // Merge sorted chunks
    return mergeSortedFiles(tempFiles, "output.txt")
}

func readLargeDataFile(filename string) ([]string, error) {
    file, err := os.Open(filename)
    if err != nil {
        return nil, err
    }
    defer file.Close()
    
    var lines []string
    scanner := bufio.NewScanner(file)
    for scanner.Scan() {
        lines = append(lines, scanner.Text())
    }
    
    return lines, scanner.Err()
}

func mergeSortedFiles(tempFiles []string, output string) error {
    // Implementation of k-way merge for sorted files
    // This would merge all sorted chunks into final output
    outFile, err := os.Create(output)
    if err != nil {
        return err
    }
    defer outFile.Close()
    
    // Open all temp files
    var files []*os.File
    var scanners []*bufio.Scanner
    
    for _, tmpFile := range tempFiles {
        f, err := os.Open(tmpFile)
        if err != nil {
            return err
        }
        defer f.Close()
        
        files = append(files, f)
        scanners = append(scanners, bufio.NewScanner(f))
    }
    
    // Simple merge (for demonstration)
    writer := bufio.NewWriter(outFile)
    defer writer.Flush()
    
    for _, scanner := range scanners {
        for scanner.Scan() {
            fmt.Fprintln(writer, scanner.Text())
        }
    }
    
    return nil
}
```

---

## Embedded File Systems

Go 1.16 introduced the `embed` package, allowing you to include files directly in your compiled binary. This is incredibly useful for bundling templates, static assets, configuration files, and more.

### Basic File Embedding

Embed single files into your program:

```go
package main

import (
    _ "embed"
    "fmt"
)

// Embed single file as string
//go:embed templates/hello.txt
var helloTemplate string

// Embed single file as bytes
//go:embed assets/logo.png
var logoBytes []byte

func main() {
    fmt.Println("Template content:")
    fmt.Println(helloTemplate)
    
    fmt.Printf("Logo size: %d bytes\n", len(logoBytes))
}
```

**Important**: The `//go:embed` directive must be placed directly above a variable declaration with no blank line between them.

### Embedding Multiple Files

Embed entire directories or multiple files:

```go
package main

import (
    "embed"
    "fmt"
    "io/fs"
)

// Embed entire directory
//go:embed templates/*
var templates embed.FS

// Embed multiple specific files
//go:embed config.json schema.sql README.md
var configFiles embed.FS

func main() {
    // List embedded files
    fs.WalkDir(templates, ".", func(path string, d fs.DirEntry, err error) error {
        if err != nil {
            return err
        }
        if !d.IsDir() {
            fmt.Println("Embedded:", path)
        }
        return nil
    })
}
```

### Reading Embedded Files

Access embedded file contents:

```go
//go:embed static/*
var staticFiles embed.FS

func readEmbeddedFile() {
    // Read entire file
    data, err := staticFiles.ReadFile("static/index.html")
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    fmt.Println(string(data))
    
    // Open file for reading
    file, err := staticFiles.Open("static/style.css")
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    defer file.Close()
    
    // Read with scanner
    scanner := bufio.NewScanner(file)
    for scanner.Scan() {
        fmt.Println(scanner.Text())
    }
}
```

### Embedding with Directory Structure

Preserve directory structure in embedded files:

```go
package main

import (
    "embed"
    "io/fs"
    "net/http"
)

// Embed entire directory tree
//go:embed static
var staticContent embed.FS

func main() {
    // Serve embedded files via HTTP
    // Strip "static" prefix from URLs
    stripped, _ := fs.Sub(staticContent, "static")
    http.Handle("/", http.FileServer(http.FS(stripped)))
    
    http.ListenAndServe(":8080", nil)
}
```

Directory structure:

```
project/
├── main.go
└── static/
    ├── index.html
    ├── css/
    │   └── style.css
    └── js/
        └── app.js
```

Accessing: `http://localhost:8080/index.html` serves `static/index.html`.

### Embedding Text Files

Common pattern for configuration and templates:

```go
import (
    "encoding/json"
    "html/template"
)

//go:embed config.json
var configJSON string

//go:embed templates/*.tmpl
var templateFiles embed.FS

type Config struct {
    Port     int    `json:"port"`
    Database string `json:"database"`
}

func loadConfig() (*Config, error) {
    var config Config
    if err := json.Unmarshal([]byte(configJSON), &config); err != nil {
        return nil, err
    }
    return &config, nil
}

func renderTemplate(name string, data interface{}) error {
    tmplContent, err := templateFiles.ReadFile("templates/" + name)
    if err != nil {
        return err
    }
    
    tmpl, err := template.New(name).Parse(string(tmplContent))
    if err != nil {
        return err
    }
    
    return tmpl.Execute(os.Stdout, data)
}
```

### Embedding for Distribution

Create self-contained executables with all assets:

```go
package main

import (
    "embed"
    "fmt"
    "html/template"
    "io/fs"
    "net/http"
)

//go:embed templates/* static/*
var content embed.FS

var templates *template.Template

func init() {
    // Parse all embedded templates
    templates = template.Must(
        template.ParseFS(content, "templates/*.html"))
}

func handler(w http.ResponseWriter, r *http.Request) {
    data := map[string]string{
        "Title":   "Embedded App",
        "Message": "This entire app is in one binary!",
    }
    templates.ExecuteTemplate(w, "index.html", data)
}

func main() {
    // Serve static files
    staticFS, _ := fs.Sub(content, "static")
    http.Handle("/static/", http.StripPrefix("/static/", 
        http.FileServer(http.FS(staticFS))))
    
    http.HandleFunc("/", handler)
    
    fmt.Println("Server running on :8080")
    http.ListenAndServe(":8080", nil)
}
```

**Benefits**:

- Single binary deployment (no need to ship asset files separately)
- No runtime file reading errors (assets are guaranteed to be present)
- Faster startup (no disk I/O for reading assets)
- Protection against asset tampering

### Listing Embedded Files

Discover what's embedded at runtime:

```go
//go:embed data/*
var dataFS embed.FS

func listEmbeddedFiles() {
    fmt.Println("Embedded files:")
    
    fs.WalkDir(dataFS, ".", func(path string, d fs.DirEntry, err error) error {
        if err != nil {
            return err
        }
        
        if !d.IsDir() {
            info, _ := d.Info()
            fmt.Printf("  %s (%d bytes)\n", path, info.Size())
        }
        
        return nil
    })
}
```

### Conditional Embedding

Different embeddings for different builds:

```go
// +build embed

package main

import "embed"

//go:embed assets/*
var Assets embed.FS

// Build with: go build -tags embed
```

```go
// +build !embed

package main

import "os"

var Assets = os.DirFS("assets")

// Build with: go build (without tags)
```

This allows development with live file reloading and production builds with embedded files.

### Embedding with SQL Migrations

Common pattern for database migrations:

```go
import (
    "database/sql"
    "path/filepath"
    "sort"
)

//go:embed migrations/*.sql
var migrations embed.FS

func runMigrations(db *sql.DB) error {
    entries, err := fs.ReadDir(migrations, "migrations")
    if err != nil {
        return err
    }
    
    // Sort by filename (001_init.sql, 002_users.sql, etc.)
    sort.Slice(entries, func(i, j int) bool {
        return entries[i].Name() < entries[j].Name()
    })
    
    for _, entry := range entries {
        if entry.IsDir() {
            continue
        }
        
        path := filepath.Join("migrations", entry.Name())
        content, err := migrations.ReadFile(path)
        if err != nil {
            return err
        }
        
        fmt.Println("Running migration:", entry.Name())
        if _, err := db.Exec(string(content)); err != nil {
            return fmt.Errorf("migration %s failed: %v", entry.Name(), err)
        }
    }
    
    return nil
}
```

### Performance Considerations

Embedded files affect binary size and compilation time:

```go
// Good: Embed only what you need
//go:embed static/*.html static/*.css
var essentialFiles embed.FS

// Bad: Embedding large or unnecessary files
//go:embed videos/* datasets/* backups/*
var hugeFiles embed.FS  // Binary will be huge!
```

**Best Practices**:

- Embed small, essential files (HTML, CSS, configs)
- Don't embed large media files, datasets, or binaries
- Use `.embedignore` or build tags to exclude files
- Consider downloading large assets at runtime instead

### Embedding with Compression

For larger embedded files, consider compressing them:

```go
import (
    "bytes"
    "compress/gzip"
    _ "embed"
    "io"
)

//go:embed large-data.json
var compressedData []byte

func getDecompressedData() ([]byte, error) {
    reader, err := gzip.NewReader(bytes.NewReader(compressedData))
    if err != nil {
        return nil, err
    }
    defer reader.Close()
    
    return io.ReadAll(reader)
}
```

---

## Real-World Examples

Let's explore comprehensive, production-ready examples that demonstrate file system operations solving real problems.

### Example 1: Log Rotation System

A system that manages log files by rotating them when they reach a certain size:

```go
package main

import (
    "fmt"
    "os"
    "path/filepath"
    "sort"
    "time"
)

type LogRotator struct {
    logFile     string
    maxSize     int64
    maxBackups  int
    currentFile *os.File
}

func NewLogRotator(logFile string, maxSizeMB int, maxBackups int) (*LogRotator, error) {
    lr := &LogRotator{
        logFile:    logFile,
        maxSize:    int64(maxSizeMB) * 1024 * 1024,
        maxBackups: maxBackups,
    }
    
    if err := lr.openCurrent(); err != nil {
        return nil, err
    }
    
    return lr, nil
}

func (lr *LogRotator) openCurrent() error {
    file, err := os.OpenFile(lr.logFile, 
        os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
    if err != nil {
        return err
    }
    lr.currentFile = file
    return nil
}

func (lr *LogRotator) Write(p []byte) (n int, err error) {
    // Check if rotation needed
    info, err := lr.currentFile.Stat()
    if err != nil {
        return 0, err
    }
    
    if info.Size() >= lr.maxSize {
        if err := lr.rotate(); err != nil {
            return 0, err
        }
    }
    
    return lr.currentFile.Write(p)
}

func (lr *LogRotator) rotate() error {
    // Close current file
    lr.currentFile.Close()
    
    // Rename current log file with timestamp
    timestamp := time.Now().Format("20060102_150405")
    backupName := fmt.Sprintf("%s.%s", lr.logFile, timestamp)
    
    if err := os.Rename(lr.logFile, backupName); err != nil {
        return err
    }
    
    // Clean old backups
    if err := lr.cleanOldBackups(); err != nil {
        return err
    }
    
    // Open new log file
    return lr.openCurrent()
}

func (lr *LogRotator) cleanOldBackups() error {
    dir := filepath.Dir(lr.logFile)
    base := filepath.Base(lr.logFile)
    pattern := filepath.Join(dir, base+".*")
    
    matches, err := filepath.Glob(pattern)
    if err != nil {
        return err
    }
    
    // Sort by modification time
    type fileInfo struct {
        path    string
        modTime time.Time
    }
    
    var files []fileInfo
    for _, match := range matches {
        info, err := os.Stat(match)
        if err != nil {
            continue
        }
        files = append(files, fileInfo{match, info.ModTime()})
    }
    
    sort.Slice(files, func(i, j int) bool {
        return files[i].modTime.After(files[j].modTime)
    })
    
    // Delete old backups beyond maxBackups
    for i := lr.maxBackups; i < len(files); i++ {
        fmt.Println("Deleting old log:", files[i].path)
        os.Remove(files[i].path)
    }
    
    return nil
}

func (lr *LogRotator) Close() error {
    if lr.currentFile != nil {
        return lr.currentFile.Close()
    }
    return nil
}

func main() {
    rotator, err := NewLogRotator("app.log", 10, 5)
    if err != nil {
        panic(err)
    }
    defer rotator.Close()
    
    // Simulate logging
    for i := 0; i < 10000; i++ {
        logLine := fmt.Sprintf("[%s] Log entry %d - %s\n",
            time.Now().Format("2006-01-02 15:04:05"),
            i,
            "This is a sample log message with some content")
        
        rotator.Write([]byte(logLine))
        time.Sleep(10 * time.Millisecond)
    }
}
```

### Example 2: File Synchronization Tool

Synchronize files between two directories:

```go
package main

import (
    "crypto/md5"
    "fmt"
    "io"
    "os"
    "path/filepath"
    "strings"
    "time"
)

type SyncStats struct {
    Copied  int
    Updated int
    Deleted int
    Skipped int
}

func syncDirectories(src, dst string, deleteExtra bool) (*SyncStats, error) {
    stats := &SyncStats{}
    
    // Build map of source files with their hashes
    srcFiles := make(map[string]fileHash)
    err := filepath.Walk(src, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }
        
        relPath, _ := filepath.Rel(src, path)
        hash, _ := hashFile(path)
        srcFiles[relPath] = fileHash{path, hash, info.ModTime()}
        
        return nil
    })
    
    if err != nil {
        return nil, err
    }
    
    // Check destination files
    dstFiles := make(map[string]bool)
    err = filepath.Walk(dst, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }
        
        relPath, _ := filepath.Rel(dst, path)
        dstFiles[relPath] = true
        
        srcInfo, exists := srcFiles[relPath]
        if !exists {
            if deleteExtra {
                fmt.Println("Deleting:", relPath)
                os.Remove(path)
                stats.Deleted++
            }
            return nil
        }
        
        // Check if update needed
        dstHash, _ := hashFile(path)
        if dstHash != srcInfo.hash {
            fmt.Println("Updating:", relPath)
            if err := copyFile(srcInfo.path, path); err != nil {
                return err
            }
            stats.Updated++
        } else {
            stats.Skipped++
        }
        
        return nil
    })
    
    if err != nil {
        return nil, err
    }
    
    // Copy new files
    for relPath, srcInfo := range srcFiles {
        if !dstFiles[relPath] {
            dstPath := filepath.Join(dst, relPath)
            
            // Create parent directories
            os.MkdirAll(filepath.Dir(dstPath), 0755)
            
            fmt.Println("Copying:", relPath)
            if err := copyFile(srcInfo.path, dstPath); err != nil {
                return nil, err
            }
            stats.Copied++
        }
    }
    
    return stats, nil
}

type fileHash struct {
    path    string
    hash    string
    modTime time.Time
}

func hashFile(path string) (string, error) {
    file, err := os.Open(path)
    if err != nil {
        return "", err
    }
    defer file.Close()
    
    hash := md5.New()
    if _, err := io.Copy(hash, file); err != nil {
        return "", err
    }
    
    return fmt.Sprintf("%x", hash.Sum(nil)), nil
}

func copyFile(src, dst string) error {
    sourceFile, err := os.Open(src)
    if err != nil {
        return err
    }
    defer    if err != nil {
        return err
    }
    
    fmt.Println("Directory size breakdown:")
    fmt.Println("Extension          Files    Total Size")
    fmt.Println("----------------------------------------")
    
    for ext, size := range sizes {
        fmt.Printf("%-15s %5d    %10d bytes\n", ext, fileCount[ext], size)
    }
    
    return nil
}
```

### Watching Directories for Changes

Monitor directories for file system events:

```go
import "github.com/fsnotify/fsnotify"

func watchDirectory(path string) error {
    watcher, err := fsnotify.NewWatcher()
    if err != nil {
        return err
    }
    defer watcher.Close()
    
    done := make(chan bool)
    
    go func() {
        for {
            select {
            case event, ok := <-watcher.Events:
                if !ok {
                    return
                }
                
                switch {
                case event.Op&fsnotify.Create == fsnotify.Create:
                    fmt.Println("Created:", event.Name)
                case event.Op&fsnotify.Write == fsnotify.Write:
                    fmt.Println("Modified:", event.Name)
                case event.Op&fsnotify.Remove == fsnotify.Remove:
                    fmt.Println("Deleted:", event.Name)
                case event.Op&fsnotify.Rename == fsnotify.Rename:
                    fmt.Println("Renamed:", event.Name)
                }
                
            case err, ok := <-watcher.Errors:
                if !ok {
                    return
                }
                fmt.Println("Error:", err)
            }
        }
    }()
    
    err = watcher.Add(path)
    if err != nil {
        return err
    }
    
    <-done
    return nil
}
```

### Creating Directory Structures

Build complex directory hierarchies:

```go
func createProjectStructure(root string) error {
    structure := []string{
        "src/main",
        "src/utils",
        "tests/unit",
        "tests/integration",
        "docs",
        "config",
        "build/output",
        "logs",
    }
    
    for _, dir := range structure {
        path := filepath.Join(root, dir)
        if err := os.MkdirAll(path, 0755); err != nil {
            return err
        }
        fmt.Println("Created:", path)
    }
    
    return nil
}

// With template files
func createProjectWithFiles(root string) error {
    structure := map[string]string{
        "src/main.go":        "package main\n\nfunc main() {\n}\n",
        "README.md":          "# Project\n\nDescription here\n",
        "go.mod":             "module myproject\n\ngo 1.21\n",
        ".gitignore":         "*.log\nbuild/\n",
        "config/app.json":   "{\n  \"port\": 8080\n}\n",
    }
    
    for filePath, content := range structure {
        fullPath := filepath.Join(root, filePath)
        
        // Create parent directory
        dir := filepath.Dir(fullPath)
        if err := os.MkdirAll(dir, 0755); err != nil {
            return err
        }
        
        // Write file
        if err := os.WriteFile(fullPath, []byte(content), 0644); err != nil {
            return err
        }
        
        fmt.Println("Created:", fullPath)
    }
    
    return nil
}
```

---

## Temporary Files and Directories

Temporary files and directories are essential for storing intermediate data, caching, and testing. They're automatically cleaned up by the operating system and should be used when you need short-lived storage.

### Creating Temporary Files

Go provides built-in functions for creating temporary files:

```go
func createTempFile() error {
    // Create temp file in default temp directory
    tmpFile, err := os.CreateTemp("", "prefix-")
    if err != nil {
        return err
    }
    defer os.Remove(tmpFile.Name())  // Clean up
    defer tmpFile.Close()
    
    fmt.Println("Temp file created:", tmpFile.Name())
    // On Unix: /tmp/prefix-123456789
    // On Windows: C:\Users\...\AppData\Local\Temp\prefix-123456789
    
    // Write to temp file
    if _, err := tmpFile.Write([]byte("temporary data")); err != nil {
        return err
    }
    
    return nil
}

// Create temp file in specific directory
func createTempFileInDir(dir string) error {
    tmpFile, err := os.CreateTemp(dir, "myapp-*.txt")
    if err != nil {
        return err
    }
    defer os.Remove(tmpFile.Name())
    defer tmpFile.Close()
    
    // The * in pattern is replaced with random string
    fmt.Println("Created:", tmpFile.Name())
    // Example: myapp-abc123def456.txt
    
    return nil
}
```

**Understanding Temp File Names**: The pattern `"prefix-"` creates files like `prefix-123456789`. The pattern `"prefix-*.txt"` creates files like `prefix-abc123.txt`. The random portion ensures uniqueness.

### Creating Temporary Directories

Similar to files, but for directories:

```go
func createTempDir() error {
    // Create temp directory
    tmpDir, err := os.MkdirTemp("", "myapp-")
    if err != nil {
        return err
    }
    defer os.RemoveAll(tmpDir)  // Clean up
    
    fmt.Println("Temp directory:", tmpDir)
    
    // Use the temp directory
    filePath := filepath.Join(tmpDir, "data.txt")
    if err := os.WriteFile(filePath, []byte("test"), 0644); err != nil {
        return err
    }
    
    return nil
}

// Working directory for batch operations
func processBatch(files []string) error {
    // Create temp workspace
    workDir, err := os.MkdirTemp("", "batch-")
    if err != nil {
        return err
    }
    defer os.RemoveAll(workDir)
    
    // Process files in temp directory
    for i, file := range files {
        // Copy file to workspace
        destPath := filepath.Join(workDir, fmt.Sprintf("file_%d.tmp", i))
        copyFile(file, destPath)
        
        // Process...
    }
    
    return nil
}
```

### Getting System Temp Directory

Find where the OS stores temporary files:

```go
func getTempDir() {
    // Get system temp directory
    tmpDir := os.TempDir()
    fmt.Println("System temp directory:", tmpDir)
    // Unix/Linux: /tmp
    // macOS: /var/folders/...
    // Windows: C:\Users\...\AppData\Local\Temp
    
    // Check if writable
    testFile := filepath.Join(tmpDir, "write-test")
    if err := os.WriteFile(testFile, []byte("test"), 0644); err != nil {
        fmt.Println("Cannot write to temp directory")
    } else {
        os.Remove(testFile)
        fmt.Println("Temp directory is writable")
    }
}
```

### Safe Temporary File Operations

Ensure proper cleanup even on errors:

```go
func safeTempFileOperation() error {
    tmpFile, err := os.CreateTemp("", "safe-")
    if err != nil {
        return err
    }
    
    // Ensure cleanup happens even if function panics
    defer func() {
        tmpFile.Close()
        os.Remove(tmpFile.Name())
    }()
    
    // Do work that might fail
    if err := riskyOperation(tmpFile); err != nil {
        return err
    }
    
    return nil
}

func riskyOperation(f *os.File) error {
    // Operations that might panic or fail
    _, err := f.WriteString("data")
    return err
}
```

### Temp Files for Testing

Temporary files are perfect for unit tests:

```go
import "testing"

func TestFileProcessing(t *testing.T) {
    // Create temp file with test data
    tmpFile, err := os.CreateTemp("", "test-")
    if err != nil {
        t.Fatal(err)
    }
    defer os.Remove(tmpFile.Name())
    
    // Write test data
    testData := "line 1\nline 2\nline 3\n"
    if _, err := tmpFile.WriteString(testData); err != nil {
        t.Fatal(err)
    }
    tmpFile.Close()
    
    // Test your function
    result, err := processFile(tmpFile.Name())
    if err != nil {
        t.Error(err)
    }
    
    // Verify result
    expected := 3
    if result != expected {
        t.Errorf("Expected %d lines, got %d", expected, result)
    }
}
```

### Temp Files with Automatic Cleanup

Use context for automatic cleanup:

```go
func withTempFile(ctx context.Context, fn func(*os.File) error) error {
    tmpFile, err := os.CreateTemp("", "ctx-")
    if err != nil {
        return err
    }
    
    // Cleanup when context is done
    go func() {
        <-ctx.Done()
        tmpFile.Close()
        os.Remove(tmpFile.Name())
    }()
    
    return fn(tmpFile)
}

// Usage
func example() {
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    err := withTempFile(ctx, func(f *os.File) error {
        _, err := f.WriteString("data")
        return err
    })
    
    if err != nil {
        fmt.Println("Error:", err)
    }
}
```

### Temporary Cache Directory

Create a cache directory that persists across runs but can be cleaned up:

```go
func getCacheDir(appName string) (string, error) {
    // Get user cache directory
    cacheRoot, err := os.UserCacheDir()
    if err != nil {
        // Fallback to temp directory
        cacheRoot = os.TempDir()
    }
    
    // Create app-specific cache directory
    cacheDir := filepath.Join(cacheRoot, appName)
    if err := os.MkdirAll(cacheDir, 0755); err != nil {
        return "", err
    }
    
    return cacheDir, nil
}

func cleanOldCache(cacheDir string, maxAge time.Duration) error {
    entries, err := os.ReadDir(cacheDir)
    if err != nil {
        return err
    }
    
    cutoff := time.Now().Add(-maxAge)
    
    for _, entry := range entries {
        info, err := entry.Info()
        if err != nil {
            continue
        }
        
        if info.ModTime().Before(cutoff) {
            path := filepath.Join(cacheDir, entry.Name())
            os.RemoveAll(path)
        }
    }
    
    return nil
}
```

### Temp Files for Large Data Processing

When processing data that doesn't fit in memory:

```go
func processSortedData(inputFile string) error {
    // Read data
    data, err := readDataFromFile(inputFile)
    if err != nil {
        return err
    }
    
    // Sort in chunks and write to temp files
    chunkSize := 10000
    var tempFiles []string
    
    for i := 0; i < len(data); i += chunkSize {
        end := i + chunkSize
        if end > len(data) {
            end = len(data)
        }
        
        chunk := data[i:end]
        sort.Strings(chunk)
        
        // Write sorted chunk to temp file
        tmpFile, err := os.CreateTemp("", "chunk-")
        if err != nil {
            return err
        }
        tempFiles = append(tempFiles, tmpFile.Name())
        
        for _, line := range chunk {
            fmt.Fprintln(tmpFile, line)
        }
        tmpFile.Close()
    }
    
    // Clean up temp files
    defer func() {
        for _, tmpFile := range tempFiles {
            os.Remove(tmpFile)
        }
    }()
    
    // Merge sorted chunks
    return mergeSortedFiles(tempFiles, "output.txt")
}
```

---

## Embedded File Systems

Go 1.16 introduced the `embed` package, allowing you to include files directly in your compiled binary. This is incredibly useful for bundling templates, static assets, configuration files, and more.

### Basic File Embedding

Embed single files into your program:

```go
package main

import (
    _ "embed"
    "fmt"
)

// Embed single file as string
//go:embed templates/hello.txt
var helloTemplate string

// Embed single file as bytes
//go:embed assets/logo.png
var logoBytes []byte

func main() {
    fmt.Println("Template content:")
    fmt.Println(helloTemplate)
    
    fmt.Printf("Logo size: %d bytes\n", len(logoBytes))
}
```

**Important**: The `//go:embed` directive must be placed directly above a variable declaration with no blank line between them.

### Embedding Multiple Files

Embed entire directories or multiple files:

```go
package main

import (
    "embed"
    "fmt"
    "io/fs"
)

// Embed entire directory
//go:embed templates/*
var templates embed.FS

// Embed multiple specific files
//go:embed config.json schema.sql README.md
var configFiles embed.FS

func main() {
    // List embedded files
    fs.WalkDir(templates, ".", func(path string, d fs.DirEntry, err error) error {
        if err != nil {
            return err
        }
        if !d.IsDir() {
            fmt.Println("Embedded:", path)
        }
        return nil
    })
}
```

### Reading Embedded Files

Access embedded file contents:

```go
//go:embed static/*
var staticFiles embed.FS

func readEmbeddedFile() {
    // Read entire file
    data, err := staticFiles.ReadFile("static/index.html")
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    fmt.Println(string(data))
    
    // Open file for reading
    file, err := staticFiles.Open("static/style.css")
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    defer file.Close()
    
    // Read with scanner
    scanner := bufio.NewScanner(file)
    for scanner.Scan() {
        fmt.Println(scanner.Text())
    }
}
```

### Embedding with Directory Structure

Preserve directory structure in embedded files:

```go
package main

import (
    "embed"
    "io/fs"
    "net/http"
)

// Embed entire directory tree
//go:embed static
var staticContent embed.FS

func main() {
    // Serve embedded files via HTTP
    // Strip "static" prefix from URLs
    stripped, _ := fs.Sub(staticContent, "static")
    http.Handle("/", http.FileServer(http.FS(stripped)))
    
    http.ListenAndServe(":8080", nil)
}
```

Directory structure:

```
project/
├── main.go
└── static/
    ├── index.html
    ├── css/
    │   └── style.css
    └── js/
        └── app.js
```

Accessing: `http://localhost:8080/index.html` serves `static/index.html`.

### Embedding Text Files

Common pattern for configuration and templates:

```go
//go:embed config.json
var configJSON string

//go:embed templates/*.tmpl
var templateFiles embed.FS

func loadConfig() error {
    var config Config
    if err := json.Unmarshal([]byte(configJSON), &config); err != nil {
        return err
    }
    // Use config...
    return nil
}

func renderTemplate(name string, data interface{}) error {
    tmplContent, err := templateFiles.ReadFile("templates/" + name)
    if err != nil {
        return err
    }
    
    tmpl, err := template.New(name).Parse(string(tmplContent))
    if err != nil {
        return err
    }
    
    return tmpl.Execute(os.Stdout, data)
}
```

### Embedding for Distribution

Create self-contained executables with all assets:

```go
package main

import (
    "embed"
    "fmt"
    "html/template"
    "net/http"
)

//go:embed templates/* static/*
var content embed.FS

var templates *template.Template

func init() {
    // Parse all embedded templates
    templates = template.Must(
        template.ParseFS(content, "templates/*.html"))
}

func handler(w http.ResponseWriter, r *http.Request) {
    data := map[string]string{
        "Title": "Embedded App",
        "Message": "This entire app is in one binary!",
    }
    templates.ExecuteTemplate(w, "index.html", data)
}

func main() {
    // Serve static files
    staticFS, _ := fs.Sub(content, "static")
    http.Handle("/static/", http.StripPrefix("/static/", 
        http.FileServer(http.FS(staticFS))))
    
    http.HandleFunc("/", handler)
    
    fmt.Println("Server running on :8080")
    http.ListenAndServe(":8080", nil)
}
```

**Benefits**:

- Single binary deployment (no need to ship asset files separately)
- No runtime file reading errors (assets are guaranteed to be present)
- Faster startup (no disk I/O for reading assets)
- Protection against asset tampering

### Listing Embedded Files

Discover what's embedded at runtime:

```go
//go:embed data/*
var dataFS embed.FS

func listEmbeddedFiles() {
    fmt.Println("Embedded files:")
    
    fs.WalkDir(dataFS, ".", func(path string, d fs.DirEntry, err error) error {
        if err != nil {
            return err
        }
        
        if !d.IsDir() {
            info, _ := d.Info()
            fmt.Printf("  %s (%d bytes)\n", path, info.Size())
        }
        
        return nil
    })
}
```

### Conditional Embedding

Different embeddings for different builds:

```go
// +build embed

package main

import "embed"

//go:embed assets/*
var Assets embed.FS

// Build with: go build -tags embed
```

```go
// +build !embed

package main

import "os"

var Assets = os.DirFS("assets")

// Build with: go build (without tags)
```

This allows development with live file reloading and production builds with embedded files.

### Embedding with SQL Migrations

Common pattern for database migrations:

```go
//go:embed migrations/*.sql
var migrations embed.FS

func runMigrations(db *sql.DB) error {
    entries, err := fs.ReadDir(migrations, "migrations")
    if err != nil {
        return err
    }
    
    // Sort by filename (001_init.sql, 002_users.sql, etc.)
    sort.Slice(entries, func(i, j int) bool {
        return entries[i].Name() < entries[j].Name()
    })
    
    for _, entry := range entries {
        if entry.IsDir() {
            continue
        }
        
        path := filepath.Join("migrations", entry.Name())
        content, err := migrations.ReadFile(path)
        if err != nil {
            return err
        }
        
        fmt.Println("Running migration:", entry.Name())
        if _, err := db.Exec(string(content)); err != nil {
            return fmt.Errorf("migration %s failed: %v", entry.Name(), err)
        }
    }
    
    return nil
}
```

### Performance Considerations

Embedded files affect binary size and compilation time:

```go
// Good: Embed only what you need
//go:embed static/*.html static/*.css
var essentialFiles embed.FS

// Bad: Embedding large or unnecessary files
//go:embed videos/* datasets/* backups/*
var hugeFiles embed.FS  // Binary will be huge!
```

**Best Practices**:

- Embed small, essential files (HTML, CSS, configs)
- Don't embed large media files, datasets, or binaries
- Use `.embedignore` or build tags to exclude files
- Consider downloading large assets at runtime instead

---

## Real-World Examples

Let's explore comprehensive, production-ready examples that demonstrate file system operations solving real problems.

### Example 1: Log Rotation System

A system that manages log files by rotating them when they reach a certain size:

```go
package main

import (
    "fmt"
    "os"
    "path/filepath"
    "sort"
    "time"
)

type LogRotator struct {
    logFile     string
    maxSize     int64
    maxBackups  int
    currentFile *os.File
}

func NewLogRotator(logFile string, maxSizeMB int, maxBackups int) (*LogRotator, error) {
    lr := &LogRotator{
        logFile:    logFile,
        maxSize:    int64(maxSizeMB) * 1024 * 1024,
        maxBackups: maxBackups,
    }
    
    if err := lr.openCurrent(); err != nil {
        return nil, err
    }
    
    return lr, nil
}

func (lr *LogRotator) openCurrent() error {
    file, err := os.OpenFile(lr.logFile, 
        os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
    if err != nil {
        return err
    }
    lr.currentFile = file
    return nil
}

func (lr *LogRotator) Write(p []byte) (n int, err error) {
    // Check if rotation needed
    info, err := lr.currentFile.Stat()
    if err != nil {
        return 0, err
    }
    
    if info.Size() >= lr.maxSize {
        if err := lr.rotate(); err != nil {
            return 0, err
        }
    }
    
    return lr.currentFile.Write(p)
}

func (lr *LogRotator) rotate() error {
    // Close current file
    lr.currentFile.Close()
    
    // Rename current log file with timestamp
    timestamp := time.Now().Format("20060102_150405")
    backupName := fmt.Sprintf("%s.%s", lr.logFile, timestamp)
    
    if err := os.Rename(lr.logFile, backupName); err != nil {
        return err
    }
    
    // Clean old backups
    if err := lr.cleanOldBackups(); err != nil {
        return err
    }
    
    // Open new log file
    return lr.openCurrent()
}

func (lr *LogRotator) cleanOldBackups() error {
    dir := filepath.Dir(lr.logFile)
    base := filepath.Base(lr.logFile)
    pattern := filepath.Join(dir, base+".*")
    
    matches, err := filepath.Glob(pattern)
    if err != nil {
        return err
    }
    
    // Sort by modification time
    type fileInfo struct {
        path    string
        modTime time.Time
    }
    
    var files []fileInfo
    for _, match := range matches {
        info, err := os.Stat(match)
        if err != nil {
            continue
        }
        files = append(files, fileInfo{match, info.ModTime()})
    }
    
    sort.Slice(files, func(i, j int) bool {
        return files[i].modTime.After(files[j].modTime)
    })
    
    // Delete old backups beyond maxBackups
    for i := lr.maxBackups; i < len(files); i++ {
        fmt.Println("Deleting old log:", files[i].path)
        os.Remove(files[i].path)
    }
    
    return nil
}

func (lr *LogRotator) Close() error {
    if lr.currentFile != nil {
        return lr.currentFile.Close()
    }
    return nil
}

func main() {
    rotator, err := NewLogRotator("app.log", 10, 5)
    if err != nil {
        panic(err)
    }
    defer rotator.Close()
    
    // Simulate logging
    for i := 0; i < 10000; i++ {
        logLine := fmt.Sprintf("[%s] Log entry %d - %s\n",
            time.Now().Format("2006-01-02 15:04:05"),
            i,
            "This is a sample log message with some content")
        
        rotator.Write([]byte(logLine))
        time.Sleep(10 * time.Millisecond)
    }
}
```

### Example 2: File Synchronization Tool

Synchronize files between two directories:

```go
package main

import (
    "crypto/md5"
    "fmt"
    "io"
    "os"
    "path/filepath"
    "time"
)

type SyncStats struct {
    Copied  int
    Updated int
    Deleted int
    Skipped int
}

func syncDirectories(src, dst string, deleteExtra bool) (*SyncStats, error) {
    stats := &SyncStats{}
    
    // Build map of source files with their hashes
    srcFiles := make(map[string]fileHash)
    err := filepath.Walk(src, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }
        
        relPath, _ := filepath.Rel(src, path)
        hash, _ := hashFile(path)
        srcFiles[relPath] = fileHash{path, hash, info.ModTime()}
        
        return nil
    })
    
    if err != nil {
        return nil, err
    }
    
    // Check destination files
    dstFiles := make(map[string]bool)
    err = filepath.Walk(dst, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }
        
        relPath, _ := filepath.Rel(dst, path)
        dstFiles[relPath] = true
        
        srcInfo, exists := srcFiles[relPath]
        if !exists {
            if deleteExtra {
                fmt.Println("Deleting:", relPath)
                os.Remove(path)
                stats.Deleted++
            }
            return nil
        }
        
        // Check if update needed
        dstHash, _ := hashFile(path)
        if dstHash != srcInfo.hash {
            fmt.Println("Updating:", relPath)
            if err := copyFile(srcInfo.path, path); err != nil {
                return err
            }
            stats.Updated++
        } else {
            stats.Skipped++
        }
        
        return nil
    })
    
    if err != nil {
        return nil, err
    }
    
    // Copy new files
    for relPath, srcInfo := range srcFiles {
        if !dstFiles[relPath] {
            dstPath := filepath.Join(dst, relPath)
            
            // Create parent directories
            os.MkdirAll(filepath.Dir(dstPath), 0755)
            
            fmt.Println("Copying:", relPath)
            if err := copyFile(srcInfo.path, dstPath); err != nil {
                return nil, err
            }
            stats.Copied++
        }
    }
    
    return stats, nil
}

type fileHash struct {
    path    string
    hash    string
    modTime time.Time
}

func hashFile(path string) (string, error) {
    file, err := os.Open(path)
    if err != nil {
        return "", err
    }
    defer file.Close()
    
    hash := md5.New()
    if _, err := io.Copy(hash, file); err != nil {
        return "", err
    }
    
    return fmt.Sprintf("%x", hash.Sum(nil)), nil
}

func copyFile(src, dst string) error {
    sourceFile, err := os.Open(src)
    if err != nil {
        return err
    }
    defer sourceFile.Close()
    
    destFile, err := os.Create(dst)
    if err != nil {
        return err
    }
    defer destFile.Close()
    
    if _, err := io.Copy(destFile, sourceFile); err != nil {
        return err
    }
    
    // Copy permissions and timestamps
    srcInfo, _ := os.Stat(src)
    os.Chmod(dst, srcInfo.Mode())
    os.Chtimes(dst, time.Now(), srcInfo.ModTime())
    
    return nil
}

func main() {
    stats, err := syncDirectories("source", "destination", true)
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    
    fmt.Printf("\nSync complete:\n")
    fmt.Printf("  Copied: %d\n", stats.Copied)
    fmt.Printf("  Updated: %d\n", stats.Updated)
    fmt.Printf("  Deleted: %d\n", stats.Deleted)
    fmt.Printf("  Skipped: %d\n", stats.Skipped)
}
```

### Example 3: Configuration File Manager

Manage application configuration with validation and migrations:

```go
package main

import (
    "encoding/json"
    "fmt"
    "os"
    "path/filepath"
)

type Config struct {
    Version  int                    `json:"version"`
    Database DatabaseConfig         `json:"database"`
    Server   ServerConfig           `json:"server"`
    Features map[string]interface{} `json:"features"`
}

type DatabaseConfig struct {
    Host     string `json:"host"`
    Port     int    `json:"port"`
    Name     string `json:"name"`
    User     string `json:"user"`
    Password string `json:"password"`
}

type ServerConfig struct {
    Port    int    `json:"port"`
    Host    string `json:"host"`
    Timeout int    `json:"timeout"`
}

type ConfigManager struct {
    configPath string
    config     *Config
}

func NewConfigManager(path string) (*ConfigManager, error) {
    cm := &ConfigManager{configPath: path}
    
    if err := cm.load(); err != nil {
        // Create default config if doesn't exist
        if os.IsNotExist(err) {
            cm.config = cm.defaultConfig()
            return cm, cm.Save()
        }
        return nil, err
    }
    
    // Migrate if needed
    if err := cm.migrate(); err != nil {
        return nil, err
    }
    
    return cm, nil
}

func (cm *ConfigManager) defaultConfig() *Config {
    return &Config{
        Version: 1,
        Database: DatabaseConfig{
            Host: "localhost",
            Port: 5432,
            Name: "myapp",
        },
        Server: ServerConfig{
            Port:    8080,
            Host:    "0.0.0.0",
            Timeout: 30,
        },
        Features: make(map[string]interface{}),
    }
}

func (cm *ConfigManager) load() error {
    data, err := os.ReadFile(cm.configPath)
    if err != nil {
        return err
    }
    
    return json.Unmarshal(data, &cm.config)
}

func (cm *ConfigManager) Save() error {
    // Create backup before saving
    if _, err := os.Stat(cm.configPath); err == nil {
        backupPath := cm.configPath + ".backup"
        data, _ := os.ReadFile(cm.configPath)
        os.WriteFile(backupPath, data, 0644)
    }
    
    // Marshal config
    data, err := json.MarshalIndent(cm.config, "", "  ")
    if err != nil {
        return err
    }
    
    // Atomic write
    tmpFile := cm.configPath + ".tmp"
    if err := os.WriteFile(tmpFile, data, 0644); err != nil {
        return err
    }
    
    return os.Rename(tmpFile, cm.configPath)
}

func (cm *ConfigManager) migrate() error {
    currentVersion := cm.config.Version
    targetVersion := 2
    
    if currentVersion >= targetVersion {
        return nil
    }
    
    fmt.Printf("Migrating config from v%d to v%d\n", currentVersion, targetVersion)
    
    // Migration logic
    switch currentVersion {
    case 1:
        // Add new fields introduced in v2
        if cm.config.Features == nil {
            cm.config.Features = make(map[string]interface{})
        }
        cm.config.Features["newFeature"] = true
        cm.config.Version = 2
        fallthrough
    case 2:
        // Future migrations go here
    }
    
    return cm.Save()
}

func (cm *ConfigManager) Validate() error {
    if cm.config.Database.Port < 1 || cm.config.Database.Port > 65535 {
        return fmt.Errorf("invalid database port: %d", cm.config.Database.Port)
    }
    
    if cm.config.Server.Port < 1 || cm.config.Server.Port > 65535 {
        return fmt.Errorf("invalid server port: %d", cm.config.Server.Port)
    }
    
    if cm.config.Database.Host == "" {
        return fmt.Errorf("database host cannot be empty")
    }
    
    return nil
}

func (cm *ConfigManager) Get() *Config {
    return cm.config
}

func (cm *ConfigManager) Set(key string, value interface{}) error {
    cm.config.Features[key] = value
    return cm.Save()
}

func main() {
    configPath := filepath.Join(os.Getenv("HOME"), ".myapp", "config.json")
    
    // Ensure config directory exists
    os.MkdirAll(filepath.Dir(configPath), 0755)
    
    cm, err := NewConfigManager(configPath)
    if err != nil {
        fmt.Println("Error loading config:", err)
        return
    }
    
    if err := cm.Validate(); err != nil {
        fmt.Println("Config validation failed:", err)
        return
    }
    
    config := cm.Get()
    fmt.Printf("Database: %s:%d\n", config.Database.Host, config.Database.Port)
    fmt.Printf("Server: %s:%d\n", config.Server.Host, config.Server.Port)
    
    // Modify config
    cm.Set("darkMode", true)
    cm.Set("language", "en")
}
```

### Example 4: File Deduplication Tool

Find and remove duplicate files based on content:

```go
package main

import (
    "crypto/sha256"
    "fmt"
    "io"
    "os"
    "path/filepath"
)

type FileInfo struct {
    Path string
    Size int64
    Hash string
}

type DuplicateFinder struct {
    root      string
    filesByHash map[string][]FileInfo
    filesBySize map[int64][]FileInfo
}

func NewDuplicateFinder(root string) *DuplicateFinder {
    return &DuplicateFinder{
        root:        root,
        filesByHash: make(map[string][]FileInfo),
        filesBySize: make(map[int64][]FileInfo),
    }
}

func (df *DuplicateFinder) Scan() error {
    fmt.Println("Scanning directory...")
    
    return filepath.Walk(df.root, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        
        if info.IsDir() {
            return nil
        }
        
        // Skip very small files
        if info.Size() < 100 {
            return nil
        }
        
        fileInfo := FileInfo{
            Path: path,
            Size: info.Size(),
        }
        
        // Group by size first (faster than hashing)
        df.filesBySize[info.Size()] = append(df.filesBySize[info.Size()], fileInfo)
        
        return nil
    })
}

func (df *DuplicateFinder) FindDuplicates() error {
    fmt.Println("Finding duplicates...")
    
    // Only hash files that have size duplicates
    for size, files := range df.filesBySize {
        if len(files) < 2 {
            continue
        }
        
        fmt.Printf("Checking %d files of size %d bytes\n", len(files), size)
        
        for _, file := range files {
            hash, err := df.hashFile(file.Path)
            if err != nil {
                fmt.Printf("Error hashing %s: %v\n", file.Path, err)
                continue
            }
            
            file.Hash = hash
            df.filesByHash[hash] = append(df.filesByHash[hash], file)
        }
    }
    
    return nil
}

func (df *DuplicateFinder) hashFile(path string) (string, error) {
    file, err := os.Open(path)
    if err != nil {
        return "", err
    }
    defer file.Close()
    
    hash := sha256.New()
    if _, err := io.Copy(hash, file); err != nil {
        return "", err
    }
    
    return fmt.Sprintf("%x", hash.Sum(nil)), nil
}

func (df *DuplicateFinder) PrintDuplicates() {
    duplicateCount := 0
    wastedSpace := int64(0)
    
    fmt.Println("\nDuplicate files found:")
    fmt.Println(strings.Repeat("=", 60))
    
    for hash, files := range df.filesByHash {
        if len(files) < 2 {
            continue
        }
        
        duplicateCount++
        fmt.Printf("\nDuplicate set %d (hash: %s...)\n", duplicateCount, hash[:16])
        fmt.Printf("Size: %d bytes\n", files[0].Size)
        
        for i, file := range files {
            marker := " "
            if i > 0 {
                marker = "→"
                wastedSpace += file.Size
            }
            fmt.Printf("  %s %s\n", marker, file.Path)
        }
    }
    
    fmt.Println(strings.Repeat("=", 60))
    fmt.Printf("\nTotal duplicate sets: %d\n", duplicateCount)
    fmt.Printf("Wasted space: %.2f MB\n", float64(wastedSpace)/(1024*1024))
}

func (df *DuplicateFinder) RemoveDuplicates(keepFirst bool) error {
    for _, files := range df.filesByHash {
        if len(files) < 2 {
            continue
        }
        
        // Keep first or last file
        startIdx := 1
        if !keepFirst {
            startIdx = 0
            files = files[:len(files)-1]
        }
        
        for i := startIdx; i < len(files); i++ {
            fmt.Printf("Deleting: %s\n", files[i].Path)
            if err := os.Remove(files[i].Path); err != nil {
                fmt.Printf("  Error: %v\n", err)
            }
        }
    }
    
    return nil
}

func main() {
    if len(os.Args) < 2 {
        fmt.Println("Usage: dedup <directory>")
        return
    }
    
    finder := NewDuplicateFinder(os.Args[1])
    
    if err := finder.Scan(); err != nil {
        fmt.Println("Scan error:", err)
        return
    }
    
    if err := finder.FindDuplicates(); err != nil {
        fmt.Println("Find error:", err)
        return
    }
    
    finder.PrintDuplicates()
    
    // Uncomment to actually remove duplicates
    // fmt.Print("\nRemove duplicates? (y/n): ")
    // var response string
    // fmt.Scanln(&response)
    // if response == "y" {
    //     finder.RemoveDuplicates(true)
    // }
}
```

### Example 5: Backup System with Compression

Create incremental backups with compression:

```go
package main

import (
    "archive/tar"
    "compress/gzip"
    "fmt"
    "io"
    "os"
    "path/filepath"
    "time"
)

type BackupManager struct {
    sourceDir string
    backupDir string
}

func NewBackupManager(source, backup string) *BackupManager {
    return &BackupManager{
        sourceDir: source,
        backupDir: backup,
    }
}

func (bm *BackupManager) CreateBackup(incremental bool) error {
    // Create backup directory if doesn't exist
    if err := os.MkdirAll(bm.backupDir, 0755); err != nil {
        return err
    }
    
    // Generate backup filename
    timestamp := time.Now().Format("20060102_150405")
    backupName := fmt.Sprintf("backup_%s.tar.gz", timestamp)
    backupPath := filepath.Join(bm.backupDir, backupName)
    
    fmt.Printf("Creating backup: %s\n", backupName)
    
    // Create tar.gz file
    file, err := os.Create(backupPath)
    if err != nil {
        return err
    }
    defer file.Close()
    
    gzipWriter := gzip.NewWriter(file)
    defer gzipWriter.Close()
    
    tarWriter := tar.NewWriter(gzipWriter)
    defer tarWriter.Close()
    
    // Get last backup time for incremental backup
    var lastBackupTime time.Time
    if incremental {
        lastBackupTime = bm.getLastBackupTime()
    }
    
    // Walk source directory
    fileCount := 0
    totalSize := int64(0)
    
    err = filepath.Walk(bm.sourceDir, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }
        
        // Skip if incremental and file hasn't changed
        if incremental && info.ModTime().Before(lastBackupTime) {
            return nil
        }
        
        // Create tar header
        header, err := tar.FileInfoHeader(info, "")
        if err != nil {
            return err
        }
        
        // Set relative path
        relPath, _ := filepath.Rel(bm.sourceDir, path)
        header.Name = relPath
        
        // Write header
        if err := tarWriter.WriteHeader(header); err != nil {
            return err
        }
        
        // Write file content
        if !info.IsDir() {
            file, err := os.Open(path)
            if err != nil {
                return err
            }
            defer file.Close()
            
            written, err := io.Copy(tarWriter, file)
            if err != nil {
                return err
            }
            
            fileCount++
            totalSize += written
            
            if fileCount%100 == 0 {
                fmt.Printf("  Backed up %d files...\n", fileCount)
            }
        }
        
        return nil
    })
    
    if err != nil {
        return err
    }
    
    // Get final backup size
    backupInfo, _ := os.Stat(backupPath)
    compressionRatio := float64(totalSize) / float64(backupInfo.Size())
    
    fmt.Printf("\nBackup complete:\n")
    fmt.Printf("  Files: %d\n", fileCount)
    fmt.Printf("  Original size: %.2f MB\n", float64(totalSize)/(1024*1024))
    fmt.Printf("  Compressed size: %.2f MB\n", float64(backupInfo.Size())/(1024*1024))
    fmt.Printf("  Compression ratio: %.2fx\n", compressionRatio)
    
    return nil
}

func (bm *BackupManager) getLastBackupTime() time.Time {
    entries, err := os.ReadDir(bm.backupDir)
    if err != nil {
        return time.Time{}
    }
    
    var latestTime time.Time
    for _, entry := range entries {
        if entry.IsDir() {
            continue
        }
        
        info, err := entry.Info()
        if err != nil {
            continue
        }
        
        if info.ModTime().After(latestTime) {
            latestTime = info.ModTime()
        }
    }
    
    return latestTime
}

func (bm *BackupManager) RestoreBackup(backupFile, destination string) error {
    fmt.Printf("Restoring backup: %s\n", backupFile)
    
    // Open backup file
    file, err := os.Open(filepath.Join(bm.backupDir, backupFile))
    if err != nil {
        return err
    }
    defer file.Close()
    
    // Create gzip reader
    gzipReader, err := gzip.NewReader(file)
    if err != nil {
        return err
    }
    defer gzipReader.Close()
    
    // Create tar reader
    tarReader := tar.NewReader(gzipReader)
    
    // Extract files
    fileCount := 0
    for {
        header, err := tarReader.Next()
        if err == io.EOF {
            break
        }
        if err != nil {
            return err
        }
        
        targetPath := filepath.Join(destination, header.Name)
        
        switch header.Typeflag {
        case tar.TypeDir:
            if err := os.MkdirAll(targetPath, os.FileMode(header.Mode)); err != nil {
                return err
            }
            
        case tar.TypeReg:
            // Create parent directories
            os.MkdirAll(filepath.Dir(targetPath), 0755)
            
            // Create file
            outFile, err := os.Create(targetPath)
            if err != nil {
                return err
            }
            
            if _, err := io.Copy(outFile, tarReader); err != nil {
                outFile.Close()
                return err
            }
            
            outFile.Close()
            os.Chmod(targetPath, os.FileMode(header.Mode))
            
            fileCount++
            if fileCount%100 == 0 {
                fmt.Printf("  Restored %d files...\n", fileCount)
            }
        }
    }
    
    fmt.Printf("\nRestore complete: %d files\n", fileCount)
    return nil
}

func (bm *BackupManager) ListBackups() {
    entries, err := os.ReadDir(bm.backupDir)
    if err != nil {
        fmt.Println("Error:", err)
        return
    }
    
    fmt.Println("Available backups:")
    for _, entry := range entries {
        if entry.IsDir() {
            continue
        }
        
        info, _ := entry.Info()
        fmt.Printf("  %s (%d bytes) - %s\n",
            entry.Name(),
            info.Size(),
            info.ModTime().Format("2006-01-02 15:04:05"))
    }
}

func main() {
    bm := NewBackupManager("/home/user/documents", "/home/user/backups")
    
    // Create full backup
    if err := bm.CreateBackup(false); err != nil {
        fmt.Println("Backup failed:", err)
        return
    }
    
    // List backups
    bm.ListBackups()
    
    // Restore example
    // bm.RestoreBackup("backup_20240101_120000.tar.gz", "/tmp/restored")
}
```

### Example 6: File Watcher with Action Triggers

Watch directories and trigger actions on file changes:

```go
package main

import (
    "fmt"
    "log"
    "os"
    "path/filepath"
    "strings"
    "time"
)

type FileEvent struct {
    Path      string
    EventType string
    Timestamp time.Time
}

type ActionHandler func(FileEvent)

type FileWatcher struct {
    watchDir string
    patterns []string
    handlers map[string]ActionHandler
    files    map[string]time.Time
    interval time.Duration
}

func NewFileWatcher(dir string, interval time.Duration) *FileWatcher {
    return &FileWatcher{
        watchDir: dir,
        patterns: []string{"*"},
        handlers: make(map[string]ActionHandler),
        files:    make(map[string]time.Time),
        interval: interval,
    }
}

func (fw *FileWatcher) AddPattern(pattern string) {
    fw.patterns = append(fw.patterns, pattern)
}

func (fw *FileWatcher) OnCreate(handler ActionHandler) {
    fw.handlers["create"] = handler
}

func (fw *FileWatcher) OnModify(handler ActionHandler) {
    fw.handlers["modify"] = handler
}

func (fw *FileWatcher) OnDelete(handler ActionHandler) {
    fw.handlers["delete"] = handler
}

func (fw *FileWatcher) Start() error {
    // Initial scan
    if err := fw.scan(); err != nil {
        return err
    }
    
    fmt.Printf("Watching %s for changes...\n", fw.watchDir)
    
    ticker := time.NewTicker(fw.interval)
    defer ticker.Stop()
    
    for range ticker.C {
        if err := fw.checkChanges(); err != nil {
            log.Println("Error checking changes:", err)
        }
    }
    
    return nil
}

func (fw *FileWatcher) scan() error {
    newFiles := make(map[string]time.Time)
    
    err := filepath.Walk(fw.watchDir, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }
        
        if fw.matchesPattern(path) {
            newFiles[path] = info.ModTime()
        }
        
        return nil
    })
    
    fw.files = newFiles
    return err
}

func (fw *FileWatcher) checkChanges() error {
    currentFiles := make(map[string]time.Time)
    
    // Scan current state
    err := filepath.Walk(fw.watchDir, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }
        
        if fw.matchesPattern(path) {
            currentFiles[path] = info.ModTime()
            
            // Check for new or modified files
            if oldTime, exists := fw.files[path]; exists {
                if info.ModTime().After(oldTime) {
                    fw.trigger("modify", path)
                }
            } else {
                fw.trigger("create", path)
            }
        }
        
        return nil
    })
    
    // Check for deleted files
    for path := range fw.files {
        if _, exists := currentFiles[path]; !exists {
            fw.trigger("delete", path)
        }
    }
    
    fw.files = currentFiles
    return err
}

func (fw *FileWatcher) matchesPattern(path string) bool {
    for _, pattern := range fw.patterns {
        matched, _ := filepath.Match(pattern, filepath.Base(path))
        if matched {
            return true
        }
    }
    return false
}

func (fw *FileWatcher) trigger(eventType, path string) {
    event := FileEvent{
        Path:      path,
        EventType: eventType,
        Timestamp: time.Now(),
    }
    
    if handler, exists := fw.handlers[eventType]; exists {
        handler(event)
    }
}

func main() {
    watcher := NewFileWatcher("/tmp/watched", 2*time.Second)
    
    // Watch only text files
    watcher.AddPattern("*.txt")
    watcher.AddPattern("*.log")
    
    // Register handlers
    watcher.OnCreate(func(e FileEvent) {
        fmt.Printf("[%s] File created: %s\n", 
            e.Timestamp.Format("15:04:05"), e.Path)
        
        // Example action: log file content
        if strings.HasSuffix(e.Path, ".log") {
            data, _ := os.ReadFile(e.Path)
            fmt.Printf("  Content: %s\n", string(data))
        }
    })
    
    watcher.OnModify(func(e FileEvent) {
        fmt.Printf("[%s] File modified: %s\n", 
            e.Timestamp.Format("15:04:05"), e.Path)
    })
    
    watcher.OnDelete(func(e FileEvent) {
        fmt.Printf("[%s] File deleted: %s\n", 
            e.Timestamp.Format("15:04:05"), e.Path)
    })
    
    if err := watcher.Start(); err != nil {
        log.Fatal(err)
    }
}
```

---

## Best Practices and Common Pitfalls

### Best Practices

**Always Close Files**

```go
// Good
func readFile(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()  // Always use defer
    
    // Process file...
    return nil
}
```

**Use Buffered I/O for Performance**

```go
// Good: Buffered reading
func efficientRead(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()
    
    reader := bufio.NewReader(file)
    // Much faster than reading byte by byte
    return nil
}
```

**Check Errors Explicitly**

```go
// Good
data, err := os.ReadFile("config.json")
if err != nil {
    if os.IsNotExist(err) {
        // Handle missing file
    } else if os.IsPermission(err) {
        // Handle permission denied
    } else {
        // Handle other errors
    }
}
```

**Use filepath Package for Cross-Platform Paths**

```go
// Good: Works on all platforms
path := filepath.Join("users", "john", "documents")

// Bad: Only works on Unix
path := "users/john/documents"
```

**Atomic File Writes for Critical Data**

```go
// Good: Atomic write
func atomicWrite(filename string, data []byte) error {
    tmp := filename + ".tmp"
    if err := os.WriteFile(tmp, data, 0644); err != nil {
        return err
    }
    return os.Rename(tmp, filename)  // Atomic on most systems
}
```

### Common Pitfalls

**Pitfall 1: Forgetting to Close Files**

```go
// Bad: File descriptor leak
func leak() {
    file, _ := os.Open("data.txt")
    // Forgot to close - file descriptor leaked
}
```

**Pitfall 2: Not Checking if File Exists Before Opening**

```go
// Bad: Panic if file doesn't exist
file, _ := os.Open("config.json")  // Ignoring error

// Good: Check error
file, err := os.Open("config.json")
if err != nil {
    log.Fatal(err)
}
```

**Pitfall 3: Race Conditions with File Existence**

```go
// Bad: TOCTOU (Time Of Check, Time Of Use) bug
if _, err := os.Stat(filename); err == nil {
    // File exists
    // But it could be deleted here by another process
    os.Remove(filename)  // Might fail
}

// Good: Handle errors directly
if err := os.Remove(filename); err != nil && !os.IsNotExist(err) {
    return err
}
```

**Pitfall 4: Not Using Absolute Paths**

```go
// Bad: Relative paths depend on working directory
os.Open("config.json")  // Where is this file?

// Good: Use absolute paths or resolve relative ones
absPath, _ := filepath.Abs("config.json")
os.Open(absPath)
```

**Pitfall 5: Ignoring Sync for Critical Data**

```go
// Bad: Data might not be on disk
file.Write(data)
file.Close()

// Good: Ensure data is written to disk
file.Write(data)
file.Sync()  // Force write to physical disk
file.Close()
```

---

## Conclusion

Go's file system operations provide a comprehensive and cross-platform way to work with files and directories. Through this guide, we've explored:

- **Basic Operations**: Opening, closing, and managing file handles
- **Reading Files**: Various methods from simple to memory-efficient streaming
- **Writing Files**: From simple writes to atomic operations
- **Updating Files**: In-place modifications and safe update patterns
- **Deleting Files**: Safe deletion with validation and soft delete options
- **Line Processing**: Filtering, transforming, and analyzing text files
- **Directory Operations**: Creating, traversing, copying, and managing directory trees
- **Temporary Files**: Working with ephemeral storage for intermediate data
- **Embedded Files**: Bundling assets directly into your executable

The key takeaway is that Go makes file operations explicit and error-conscious, which leads to more robust and maintainable code. By following best practices and understanding the underlying mechanisms, you can build reliable file-handling systems for any application.# A Comprehensive Guide to Go File System Operations

