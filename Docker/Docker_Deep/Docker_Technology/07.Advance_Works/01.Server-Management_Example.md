# Complete Guide: Nginx + SSL + Docker for Multiple Domains on Single Server

## Table of Contents

1. [Understanding the Architecture](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#architecture)
2. [Prerequisites and Server Preparation](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#prerequisites)
3. [Project Structure Setup](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#project-structure)
4. [Project 1: React + Node.js + PostgreSQL + Redis](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#project1)
5. [Project 2: Next.js + Golang + PostgreSQL](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#project2)
6. [Nginx Reverse Proxy Setup](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#nginx-setup)
7. [SSL Certificate Configuration with Let's Encrypt](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#ssl-setup)
8. [DNS Configuration](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#dns-config)
9. [Deployment Steps](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#deployment)
10. [Testing and Verification](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#testing)
11. [Maintenance and Troubleshooting](https://claude.ai/chat/aefcc9c9-f1e1-41de-9883-ed6b27dff2da#maintenance)

---

## 1. Understanding the Architecture {#architecture}

Before diving into configuration, let's understand how all pieces work together. When you have multiple projects with different domains on a single server, the traffic flow looks like this:

```
                                    INTERNET
                                       │
                                       │
                    ┌──────────────────┼──────────────────┐
                    │                  │                  │
                    │                  │                  │
          project01.com        api.project01.com   project02.com
          project02.com        api.project02.com
                    │                  │                  │
                    └──────────────────┼──────────────────┘
                                       │
                                       ▼
                            ┌──────────────────────┐
                            │   Firewall/Router    │
                            │   Port 80 (HTTP)     │
                            │   Port 443 (HTTPS)   │
                            └──────────┬───────────┘
                                       │
┌──────────────────────────────────────┼─────────────────────────────────────┐
│                          DOCKER HOST SERVER                                 │
│                                      │                                      │
│                                      ▼                                      │
│                     ┌────────────────────────────────┐                     │
│                     │   Nginx Reverse Proxy          │                     │
│                     │   (Container: nginx_proxy)     │                     │
│                     │                                │                     │
│                     │  ┌──────────────────────────┐  │                     │
│                     │  │  SSL Certificates:       │  │                     │
│                     │  │  - project01.com         │  │                     │
│                     │  │  - api.project01.com     │  │                     │
│                     │  │  - project02.com         │  │                     │
│                     │  │  - api.project02.com     │  │                     │
│                     │  └──────────────────────────┘  │                     │
│                     │                                │                     │
│                     │  Routes based on domain name   │                     │
│                     └────────┬───────────────────────┘                     │
│                              │                                              │
│         ┌────────────────────┼────────────────────┐                        │
│         │                    │                    │                        │
│         ▼                    ▼                    ▼                        │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐                │
│  │   Project 1  │    │   Project 1  │    │   Project 2  │                │
│  │   Frontend   │    │   Backend    │    │   Frontend   │                │
│  │   (React)    │    │   (Node.js)  │    │   (Next.js)  │                │
│  │              │    │              │    │              │                │
│  │ Container:   │    │ Container:   │    │ Container:   │                │
│  │ project1_fe  │    │ project1_be  │    │ project2_fe  │                │
│  │ Port: 3000   │    │ Port: 5000   │    │ Port: 3000   │                │
│  └──────┬───────┘    └──────┬───────┘    └──────┬───────┘                │
│         │                   │                    │                         │
│         │                   │                    │                         │
│         │            ┌──────┴──────┐             │                         │
│         │            │             │             │                         │
│         │            ▼             ▼             │                         │
│         │     ┌────────────┐ ┌─────────┐        │                         │
│         │     │PostgreSQL  │ │  Redis  │        │                         │
│         │     │(project1)  │ │(project1│        │                         │
│         │     │Port: 5432  │ │Port:6379│        │                         │
│         │     └────────────┘ └─────────┘        │                         │
│         │                                        │                         │
│         │                    ┌──────────────────┴───┐                     │
│         │                    │   Project 2          │                     │
│         │                    │   Backend            │                     │
│         │                    │   (Golang)           │                     │
│         │                    │                      │                     │
│         │                    │ Container:           │                     │
│         │                    │ project2_be          │                     │
│         │                    │ Port: 8080           │                     │
│         │                    └──────┬───────────────┘                     │
│         │                           │                                      │
│         │                           ▼                                      │
│         │                    ┌────────────┐                               │
│         │                    │PostgreSQL  │                               │
│         │                    │(project2)  │                               │
│         │                    │Port: 5432  │                               │
│         │                    └────────────┘                               │
│         │                                                                  │
│         └──────────────── proxy_network ────────────────────┘            │
│                                                                             │
│         ┌─────────────── project1_network ───────────┐                    │
│         ┌─────────────── project2_network ───────────┐                    │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Key Concepts Explained

**1. Single Entry Point**: All traffic enters through one Nginx container listening on ports 80 (HTTP) and 443 (HTTPS).

**2. Domain-Based Routing**: Nginx examines the domain name in each request and routes it to the correct backend container:

- `project01.com` → React frontend container
- `api.project01.com` → Node.js backend container
- `project02.com` → Next.js frontend container
- `api.project02.com` → Golang backend container

**3. SSL Termination**: Nginx handles all SSL/TLS encryption and decryption. When a browser connects via HTTPS, Nginx decrypts the traffic, then forwards plain HTTP to the backend containers. This simplifies your application code—your apps don't need to handle SSL.

**4. Network Isolation**: Each project has its own internal Docker network where its containers communicate. Only the frontend/backend containers that need external access are also connected to the `proxy_network`, which Nginx uses to reach them.

**5. Internal Communication**: Within each project, containers use Docker's internal DNS to communicate. For example, in Project 1, the Node.js backend connects to PostgreSQL using `postgres:5432` as the hostname—Docker resolves `postgres` to the correct container's IP address automatically.

---

## 2. Prerequisites and Server Preparation {#prerequisites}

### Server Requirements

You'll need a server (VPS or dedicated) with:

- **Operating System**: Ubuntu 22.04 LTS or later (this guide uses Ubuntu)
- **RAM**: Minimum 4GB (8GB recommended for production)
- **CPU**: 2+ cores recommended
- **Storage**: 50GB+ SSD
- **Root/sudo access**: Required for installation

### Software Installation

First, update your server and install Docker:

```bash
# Update system packages
sudo apt-get update
sudo apt-get upgrade -y

# Install required dependencies
sudo apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release \
    git

# Add Docker's official GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Set up Docker repository
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Install Docker Engine
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io

# Install Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Add your user to docker group (to run docker without sudo)
sudo usermod -aG docker $USER

# Verify installation
docker --version
docker-compose --version

# Log out and back in for group changes to take effect
# Or run: newgrp docker
```

### Firewall Configuration

Configure the firewall to allow HTTP and HTTPS traffic:

```bash
# If using UFW (Ubuntu's default firewall)
sudo ufw allow 22/tcp    # SSH (don't lock yourself out!)
sudo ufw allow 80/tcp    # HTTP
sudo ufw allow 443/tcp   # HTTPS
sudo ufw enable
sudo ufw status

# If using iptables directly
sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT
sudo iptables -A INPUT -p tcp --dport 80 -j ACCEPT
sudo iptables -A INPUT -p tcp --dport 443 -j ACCEPT
sudo iptables-save | sudo tee /etc/iptables/rules.v4
```

### Create Working Directory Structure

Set up organized directories for all projects:

```bash
# Create main projects directory
sudo mkdir -p /opt/docker-projects
sudo chown $USER:$USER /opt/docker-projects
cd /opt/docker-projects

# Create directories for each project and nginx
mkdir -p nginx-proxy/{conf.d,ssl,certbot}
mkdir -p project1/{frontend,backend}
mkdir -p project2/{frontend,backend}

# Create directories for scripts and backups
mkdir -p /opt/scripts
mkdir -p /opt/backups/{project1,project2}
```

Your directory structure should now look like this:

```
/opt/docker-projects/
├── nginx-proxy/
│   ├── conf.d/          # Nginx site configurations
│   ├── ssl/             # SSL certificates (if self-signed)
│   └── certbot/         # Let's Encrypt challenge files
├── project1/
│   ├── frontend/        # React app
│   └── backend/         # Node.js API
└── project2/
    ├── frontend/        # Next.js app
    └── backend/         # Golang API
```

---

## 3. Project Structure Setup {#project-structure}

Before creating Docker configurations, let's establish the complete folder structure with all necessary files.

### Complete Directory Tree

```
/opt/docker-projects/
│
├── nginx-proxy/
│   ├── docker-compose.yml
│   ├── nginx.conf
│   ├── conf.d/
│   │   ├── project01-frontend.conf
│   │   ├── project01-backend.conf
│   │   ├── project02-frontend.conf
│   │   └── project02-backend.conf
│   ├── ssl/
│   │   └── (Let's Encrypt certificates will be here)
│   └── certbot/
│       └── (ACME challenge files)
│
├── project1/
│   ├── docker-compose.yml
│   ├── .env
│   ├── frontend/
│   │   ├── Dockerfile
│   │   ├── nginx.conf          # Nginx config for serving React build
│   │   ├── package.json
│   │   ├── src/
│   │   ├── public/
│   │   └── build/              # Created after build
│   └── backend/
│       ├── Dockerfile
│       ├── package.json
│       ├── src/
│       │   ├── server.js
│       │   └── ...
│       └── node_modules/
│
└── project2/
    ├── docker-compose.yml
    ├── .env
    ├── frontend/
    │   ├── Dockerfile
    │   ├── package.json
    │   ├── next.config.js
    │   ├── pages/
    │   ├── public/
    │   └── .next/              # Created after build
    └── backend/
        ├── Dockerfile
        ├── go.mod
        ├── go.sum
        ├── main.go
        └── ...
```

### Create Shared Docker Network

Before setting up projects, create the shared network that Nginx will use to communicate with all projects:

```bash
docker network create proxy_network
```

Verify the network was created:

```bash
docker network ls
# Should show proxy_network in the list
```

This network is critical—it's the bridge that allows Nginx to reach all your project containers while keeping projects isolated from each other.

---

## 4. Project 1: React + Node.js + PostgreSQL + Redis {#project1}

Project 1 consists of four services: React frontend, Node.js backend, PostgreSQL database, and Redis cache. The frontend serves at `project01.com` and the backend API at `api.project01.com`.

### Project 1 Docker Compose Configuration

Create the main orchestration file:

```yaml
# /opt/docker-projects/project1/docker-compose.yml
version: '3.8'

services:
  # React Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: project1_frontend
    restart: unless-stopped
    networks:
      - project1_internal
      - proxy_network
    environment:
      - NODE_ENV=production
      - REACT_APP_API_URL=https://api.project01.com
    labels:
      - "traefik.enable=false"  # We're using Nginx, not Traefik

  # Node.js Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: project1_backend
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - project1_internal
      - proxy_network
    environment:
      - NODE_ENV=production
      - PORT=5000
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=${JWT_SECRET}
      - CORS_ORIGIN=https://project01.com
    env_file:
      - .env

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: project1_postgres
    restart: unless-stopped
    networks:
      - project1_internal
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: project1_redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD}
    networks:
      - project1_internal
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

volumes:
  postgres_data:
    name: project1_postgres_data
  redis_data:
    name: project1_redis_data

networks:
  project1_internal:
    name: project1_network
    driver: bridge
  proxy_network:
    external: true
```

### Understanding the Docker Compose File

Let's break down the important parts:

**Services Section**: Defines four containers that work together.

**Frontend Service**:

- `build: ./frontend` tells Docker to build an image from the Dockerfile in the frontend directory
- `container_name: project1_frontend` gives a predictable name (useful for debugging)
- `networks` connects to both the internal network (for potential backend communication) and `proxy_network` (so Nginx can reach it)
- `REACT_APP_API_URL` environment variable tells React where the backend API is

**Backend Service**:

- `depends_on` with `condition: service_healthy` ensures the database and Redis are fully ready before starting
- Connects to both networks: internal (to reach database/Redis) and proxy (so Nginx can reach it)
- `DATABASE_URL` uses `postgres:5432` as the hostname—Docker DNS resolves this to the postgres container's IP
- `env_file: .env` loads additional environment variables from the .env file

**Postgres Service**:

- Uses official PostgreSQL image (no need to build)
- Only on `project1_internal` network—not accessible from Nginx or other projects
- `volumes` persist data and run initialization SQL on first startup
- `healthcheck` allows other services to wait until the database is actually ready to accept connections

**Redis Service**:

- Also only on internal network
- `command` sets a password for security
- Healthcheck ensures it's ready before the backend starts

**Networks**:

- `project1_internal`: Created by this compose file, used for secure internal communication
- `proxy_network`: External network (created earlier), shared with Nginx

### Project 1 Environment Variables

Create the environment file with all sensitive credentials:

```bash
# /opt/docker-projects/project1/.env
COMPOSE_PROJECT_NAME=project1

# PostgreSQL Configuration
POSTGRES_USER=project1_user
POSTGRES_PASSWORD=super_secure_postgres_password_change_me
POSTGRES_DB=project1_database

# Redis Configuration
REDIS_PASSWORD=super_secure_redis_password_change_me

# Backend Configuration
JWT_SECRET=super_secret_jwt_key_min_32_characters_long_change_me
NODE_ENV=production
```

**Security Note**: These are example values. Generate strong, unique passwords for production:

```bash
# Generate secure random passwords
openssl rand -base64 32
```

### Project 1 Frontend Dockerfile (React)

```dockerfile
# /opt/docker-projects/project1/frontend/Dockerfile

# Stage 1: Build React application
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files
COPY package.json package-lock.json ./

# Install dependencies
RUN npm ci --only=production

# Copy source code
COPY . .

# Build the React app
RUN npm run build

# Stage 2: Serve with Nginx
FROM nginx:alpine

# Remove default Nginx configuration
RUN rm /etc/nginx/conf.d/default.conf

# Copy custom Nginx configuration
COPY nginx.conf /etc/nginx/conf.d/

# Copy built React app from builder stage
COPY --from=builder /app/build /usr/share/nginx/html

# Expose port 80 (internal to Docker)
EXPOSE 80

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD wget --quiet --tries=1 --spider http://localhost/ || exit 1

CMD ["nginx", "-g", "daemon off;"]
```

**Multi-stage Build Explained**:

This Dockerfile uses a two-stage build process, which is a best practice for production:

**Stage 1 (Builder)**:

- Uses Node.js image to build the React application
- Installs dependencies and runs `npm run build`
- Creates optimized production files in `/app/build`

**Stage 2 (Final Image)**:

- Uses lightweight Nginx Alpine image (much smaller than Node.js)
- Copies only the built files from Stage 1
- Final image doesn't contain Node.js, npm, or source code—just static files and Nginx
- This reduces image size from ~1GB to ~50MB

### Project 1 Frontend Nginx Configuration

```nginx
# /opt/docker-projects/project1/frontend/nginx.conf

server {
    listen 80;
    server_name localhost;
    root /usr/share/nginx/html;
    index index.html;

    # Gzip compression for better performance
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/javascript
        application/json
        application/xml+rss;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # Serve static files with caching
    location ~* \.(jpg|jpeg|png|gif|ico|css|js|svg|woff|woff2|ttf|eot)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # React Router support - all routes go to index.html
    location / {
        try_files $uri $uri/ /index.html;
    }

    # Health check endpoint
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
```

This Nginx configuration serves the React app and handles client-side routing. The key line is `try_files $uri $uri/ /index.html` which ensures that React Router works correctly—any URL that doesn't match a file gets served `index.html`, letting React handle routing.

### Project 1 Backend Dockerfile (Node.js)

```dockerfile
# /opt/docker-projects/project1/backend/Dockerfile

FROM node:18-alpine

# Install dumb-init for proper signal handling
RUN apk add --no-cache dumb-init

# Create app directory
WORKDIR /app

# Create non-root user
RUN addgroup -g 1001 -S nodejs && adduser -S nodejs -u 1001

# Copy package files
COPY package.json package-lock.json ./

# Install dependencies
RUN npm ci --only=production && npm cache clean --force

# Copy application code
COPY --chown=nodejs:nodejs . .

# Switch to non-root user
USER nodejs

# Expose port
EXPOSE 5000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
  CMD node -e "require('http').get('http://localhost:5000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"

# Use dumb-init to handle signals properly
ENTRYPOINT ["dumb-init", "--"]

CMD ["node", "src/server.js"]
```

**Key Security Features**:

- Creates and runs as a non-root user (`nodejs`)
- Uses `dumb-init` to properly handle system signals (important for graceful shutdowns)
- Includes healthcheck so Docker can verify the service is actually working
- Cleans npm cache to reduce image size

### Project 1 Backend Sample Code

```javascript
// /opt/docker-projects/project1/backend/src/server.js

const express = require('express');
const cors = require('cors');
const { Pool } = require('pg');
const redis = require('redis');

const app = express();
const PORT = process.env.PORT || 5000;

// Middleware
app.use(cors({
  origin: process.env.CORS_ORIGIN || 'http://localhost:3000'
}));
app.use(express.json());

// PostgreSQL connection
const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  max: 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});

// Redis connection
const redisClient = redis.createClient({
  url: process.env.REDIS_URL,
  password: process.env.REDIS_PASSWORD
});

redisClient.connect().catch(console.error);

redisClient.on('error', (err) => {
  console.error('Redis error:', err);
});

// Health check endpoint (required for Docker healthcheck)
app.get('/health', async (req, res) => {
  try {
    // Check database connection
    await pool.query('SELECT 1');
    
    // Check Redis connection
    await redisClient.ping();
    
    res.status(200).json({ 
      status: 'healthy',
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(503).json({ 
      status: 'unhealthy',
      error: error.message 
    });
  }
});

// Sample API endpoint
app.get('/api/users', async (req, res) => {
  try {
    // Try to get from cache first
    const cached = await redisClient.get('users');
    if (cached) {
      return res.json(JSON.parse(cached));
    }

    // If not in cache, get from database
    const result = await pool.query('SELECT id, username, email FROM users LIMIT 10');
    
    // Cache the result for 5 minutes
    await redisClient.setEx('users', 300, JSON.stringify(result.rows));
    
    res.json(result.rows);
  } catch (error) {
    console.error('Error fetching users:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});

// Graceful shutdown
process.on('SIGTERM', async () => {
  console.log('SIGTERM signal received: closing HTTP server');
  await pool.end();
  await redisClient.quit();
  process.exit(0);
});

app.listen(PORT, '0.0.0.0', () => {
  console.log(`Server running on port ${PORT}`);
  console.log(`Environment: ${process.env.NODE_ENV}`);
});
```

### Project 1 Database Initialization

```sql
-- /opt/docker-projects/project1/backend/init-db.sql

-- Create users table
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create index on email for faster lookups
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);

-- Insert sample data (for testing)
INSERT INTO users (username, email, password_hash) VALUES
    ('testuser1', 'test1@example.com', '$2b$10$dummy_hash_replace_in_production'),
    ('testuser2', 'test2@example.com', '$2b$10$dummy_hash_replace_in_production')
ON CONFLICT (email) DO NOTHING;
```

This SQL file runs automatically when the PostgreSQL container starts for the first time (via the volume mount in docker-compose.yml).

---

## 5. Project 2: Next.js + Golang + PostgreSQL {#project2}

Project 2 uses Next.js for the frontend and Golang for the backend. The frontend serves at `project02.com` and the backend API at `api.project02.com`.

### Project 2 Docker Compose Configuration

```yaml
# /opt/docker-projects/project2/docker-compose.yml
version: '3.8'

services:
  # Next.js Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=https://api.project02.com
    container_name: project2_frontend
    restart: unless-stopped
    networks:
      - project2_internal
      - proxy_network
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=https://api.project02.com

  # Golang Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: project2_backend
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - project2_internal
      - proxy_network
    environment:
      - ENV=production
      - PORT=8080
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable
      - JWT_SECRET=${JWT_SECRET}
      - CORS_ORIGINS=https://project02.com
    env_file:
      - .env

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: project2_postgres
    restart: unless-stopped
    networks:
      - project2_internal
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/migrations:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
    name: project2_postgres_data

networks:
  project2_internal:
    name: project2_network
    driver: bridge
  proxy_network:
    external: true
```

### Project 2 Environment Variables

```bash
# /opt/docker-projects/project2/.env
COMPOSE_PROJECT_NAME=project2

# PostgreSQL Configuration
POSTGRES_USER=project2_user
POSTGRES_PASSWORD=another_super_secure_password_change_me
POSTGRES_DB=project2_database

# Backend Configuration
JWT_SECRET=another_super_secret_jwt_key_min_32_chars_change_me
ENV=production
```

### Project 2 Frontend Dockerfile (Next.js)

```dockerfile
# /opt/docker-projects/project2/frontend/Dockerfile

# Stage 1: Dependencies
FROM node:18-alpine AS deps
WORKDIR /app

# Copy package files
COPY package.json package-lock.json ./

# Install dependencies
RUN npm ci

# Stage 2: Builder
FROM node:18-alpine AS builder
WORKDIR /app

# Copy dependencies from deps stage
COPY --from=deps /app/node_modules ./node_modules

# Copy source code
COPY . .

# Build argument for API URL
ARG NEXT_PUBLIC_API_URL
ENV NEXT_PUBLIC_API_URL=$NEXT_PUBLIC_API_URL

# Build Next.js application
RUN npm run build

# Stage 3: Runner
FROM node:18-alpine AS runner
WORKDIR /app

ENV NODE_ENV=production

# Create non-root user
RUN addgroup -g 1001 -S nodejs && adduser -S nextjs -u 1001

# Copy necessary files
COPY --from=builder /app/public ./public
COPY --from=builder /app/package.json ./package.json

# Copy built application
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs

EXPOSE 3000

ENV PORT=3000
ENV HOSTNAME="0.0.0.0"

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
  CMD node -e "require('http').get('http://localhost:3000/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"

CMD ["node", "server.js"]
```

**Next.js Dockerfile Explanation**:

This is a three-stage build optimized for Next.js:

**Stage 1 (deps)**: Installs dependencies separately so they can be cached

**Stage 2 (builder)**: Builds the Next.js application. The `ARG NEXT_PUBLIC_API_URL` allows passing the API URL at build time—Next.js bakes environment variables starting with `NEXT_PUBLIC_` into the frontend code.

**Stage 3 (runner)**: Creates a minimal runtime image with only what's needed to run Next.js in production mode. Uses Next.js's standalone output for the smallest possible image.

### Project 2 Next.js Configuration

```javascript
// /opt/docker-projects/project2/frontend/next.config.js

/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  
  // Enable standalone output for Docker
  output: 'standalone',
  
  // API rewrites (optional - if you want to proxy API calls)
  async rewrites() {
    return [
      {
        source: '/api/:path*',
        destination: `${process.env.NEXT_PUBLIC_API_URL}/api/:path*`,
      },
    ];
  },

  // Security headers
  async headers() {
    return [
      {
        source: '/:path*',
        headers: [
          {
            key: 'X-DNS-Prefetch-Control',
            value: 'on'
          },
          {
            key: 'Strict-Transport-Security',
            value: 'max-age=63072000; includeSubDomains; preload'
          },
          {
            key: 'X-Frame-Options',
            value: 'SAMEORIGIN'
          },
          {
            key: 'X-Content-Type-Options',
            value: 'nosniff'
          },
          {
            key: 'X-XSS-Protection',
            value: '1; mode=block'
          },
        ],
      },
    ];
  },
};

module.exports = nextConfig;
```

### Project 2 Backend Dockerfile (Golang)

```dockerfile
# /opt/docker-projects/project2/backend/Dockerfile

# Stage 1: Build
FROM golang:1.21-alpine AS builder

WORKDIR /app

# Install build dependencies
RUN apk add --no-cache git

# Copy go mod files
COPY go.mod go.sum ./

# Download dependencies
RUN go mod download

# Copy source code
COPY . .

# Build the application
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .

# Stage 2: Runtime
FROM alpine:latest

# Install ca-certificates for HTTPS requests
RUN apk --no-cache add ca-certificates

WORKDIR /root/

# Copy binary from builder
COPY --from=builder /app/main .

# Expose port
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD wget --quiet --tries=1 --spider http://localhost:8080/health || exit 1

CMD ["./main"]
```

**Golang Dockerfile Explanation**:

**Stage 1 (builder)**: Uses full Golang image to compile the application. `CGO_ENABLED=0` creates a fully static binary that doesn't depend on system libraries.

**Stage 2 (runtime)**: Uses minimal Alpine Linux image (only ~5MB). The compiled binary from Stage 1 is copied over. Final image is extremely small (~15MB vs ~800MB if using the full Golang image).

### Project 2 Backend Sample Code (Golang)

```go
// /opt/docker-projects/project2/backend/main.go

package main

import (
    "database/sql"
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "os"
    "time"

    _ "github.com/lib/pq"
    "github.com/gorilla/mux"
    "github.com/rs/cors"
)

var db *sql.DB

type User struct {
    ID        int       `json:"id"`
    Username  string    `json:"username"`
    Email     string    `json:"email"`
    CreatedAt time.Time `json:"created_at"`
}

func main() {
    // Initialize database
    var err error
    db, err = sql.Open("postgres", os.Getenv("DATABASE_URL"))
    if err != nil {
        log.Fatal("Failed to connect to database:", err)
    }
    defer db.Close()

    // Test database connection
    if err = db.Ping(); err != nil {
        log.Fatal("Failed to ping database:", err)
    }
    log.Println("Database connected successfully")

    // Set up router
    router := mux.NewRouter()

    // Health check endpoint
    router.HandleFunc("/health", healthCheckHandler).Methods("GET")
    
    // API endpoints
    router.HandleFunc("/api/users", getUsersHandler).Methods("GET")
    router.HandleFunc("/api/users/{id}", getUserHandler).Methods("GET")

    // CORS configuration
    corsOrigins := os.Getenv("CORS_ORIGINS")
    if corsOrigins == "" {
        corsOrigins = "http://localhost:3000"
    }

    c := cors.New(cors.Options{
        AllowedOrigins:   []string{corsOrigins},
        AllowedMethods:   []string{"GET", "POST", "PUT", "DELETE", "OPTIONS"},
        AllowedHeaders:   []string{"Accept", "Authorization", "Content-Type"},
        AllowCredentials: true,
    })

    handler := c.Handler(router)

    // Start server
    port := os.Getenv("PORT")
    if port == "" {
        port = "8080"
    }

    log.Printf("Server starting on port %s", port)
    log.Fatal(http.ListenAndServe(":"+port, handler))
}

func healthCheckHandler(w http.ResponseWriter, r *http.Request) {
    // Check database connection
    if err := db.Ping(); err != nil {
        w.WriteHeader(http.StatusServiceUnavailable)
        json.NewEncoder(w).Encode(map[string]string{
            "status": "unhealthy",
            "error":  err.Error(),
        })
        return
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(map[string]string{
        "status":    "healthy",
        "timestamp": time.Now().Format(time.RFC3339),
    })
}

func getUsersHandler(w http.ResponseWriter, r *http.Request) {
    rows, err := db.Query(`
        SELECT id, username, email, created_at 
        FROM users 
        ORDER BY created_at DESC 
        LIMIT 10
    `)
    if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }
    defer rows.Close()

    var users []User
    for rows.Next() {
        var user User
        if err := rows.Scan(&user.ID, &user.Username, &user.Email, &user.CreatedAt); err != nil {
            http.Error(w, err.Error(), http.StatusInternalServerError)
            return
        }
        users = append(users, user)
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(users)
}

func getUserHandler(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    id := vars["id"]

    var user User
    err := db.QueryRow(`
        SELECT id, username, email, created_at 
        FROM users 
        WHERE id = $1
    `, id).Scan(&user.ID, &user.Username, &user.Email, &user.CreatedAt)

    if err == sql.ErrNoRows {
        http.Error(w, "User not found", http.StatusNotFound)
        return
    } else if err != nil {
        http.Error(w, err.Error(), http.StatusInternalServerError)
        return
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(user)
}
```

### Project 2 Database Migration

```sql
-- /opt/docker-projects/project2/backend/migrations/001_init.sql

-- Create users table
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create posts table
CREATE TABLE IF NOT EXISTS posts (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    published BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes
CREATE INDEX IF NOT EXISTS idx_posts_user_id ON posts(user_id);
CREATE INDEX IF NOT EXISTS idx_posts_published ON posts(published);

-- Insert sample data
INSERT INTO users (username, email, password_hash) VALUES
    ('john_doe', 'john@example.com', '$2a$10$dummy_hash_for_testing'),
    ('jane_smith', 'jane@example.com', '$2a$10$dummy_hash_for_testing')
ON CONFLICT (email) DO NOTHING;
```

---

## 6. Nginx Reverse Proxy Setup {#nginx-setup}

Now we create the central Nginx reverse proxy that routes traffic to both projects based on domain names.

### Nginx Proxy Docker Compose

```yaml
# /opt/docker-projects/nginx-proxy/docker-compose.yml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    container_name: nginx_proxy
    restart: unless-stopped
    ports:
      - "80:80"      # HTTP
      - "443:443"    # HTTPS
    volumes:
      # Main nginx configuration
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      
      # Site-specific configurations
      - ./conf.d:/etc/nginx/conf.d:ro
      
      # SSL certificates (will be created by certbot)
      - /etc/letsencrypt:/etc/letsencrypt:ro
      
      # Let's Encrypt webroot for ACME challenge
      - ./certbot:/var/www/certbot:ro
      
      # Logs
      - nginx_logs:/var/log/nginx
    networks:
      - proxy_network
    depends_on:
      - certbot

  # Certbot for SSL certificate management
  certbot:
    image: certbot/certbot:latest
    container_name: certbot
    volumes:
      - /etc/letsencrypt:/etc/letsencrypt
      - /var/lib/letsencrypt:/var/lib/letsencrypt
      - ./certbot:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"

volumes:
  nginx_logs:

networks:
  proxy_network:
    external: true
```

### Main Nginx Configuration

```nginx
# /opt/docker-projects/nginx-proxy/nginx.conf

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 2048;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 50M;

    # Buffer settings
    client_body_buffer_size 128k;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 16k;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # Security headers (global)
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # Hide nginx version
    server_tokens off;

    # SSL session cache (shared across all virtual hosts)
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;

    # Modern SSL configuration
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384';
    ssl_prefer_server_ciphers off;

    # OCSP stapling
    ssl_stapling on;
    ssl_stapling_verify on;
    resolver 8.8.8.8 8.8.4.4 valid=300s;
    resolver_timeout 5s;

    # Include site-specific configurations
    include /etc/nginx/conf.d/*.conf;
}
```

### Project 1 Frontend Nginx Configuration

```nginx
# /opt/docker-projects/nginx-proxy/conf.d/project01-frontend.conf

# Upstream for Project 1 Frontend
upstream project1_frontend {
    server project1_frontend:80;
    keepalive 32;
}

# HTTP server - redirect to HTTPS
server {
    listen 80;
    server_name project01.com www.project01.com;

    # Let's Encrypt ACME challenge
    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    # Redirect all other traffic to HTTPS
    location / {
        return 301 https://$host$request_uri;
    }
}

# HTTPS server
server {
    listen 443 ssl http2;
    server_name project01.com www.project01.com;

    # SSL certificate paths
    ssl_certificate /etc/letsencrypt/live/project01.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/project01.com/privkey.pem;

    # SSL configuration
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_prefer_server_ciphers off;
    ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';

    # HSTS (optional but recommended)
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # Logging
    access_log /var/log/nginx/project01-frontend-access.log;
    error_log /var/log/nginx/project01-frontend-error.log;

    # Proxy to React frontend
    location / {
        proxy_pass http://project1_frontend;
        proxy_http_version 1.1;

        # Headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Port $server_port;

        # WebSocket support (if needed for React hot reload in dev)
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";

        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;

        # Buffering
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
    }
}
```

### Project 1 Backend Nginx Configuration

```nginx
# /opt/docker-projects/nginx-proxy/conf.d/project01-backend.conf

# Upstream for Project 1 Backend
upstream project1_backend {
    server project1_backend:5000;
    keepalive 32;
}

# HTTP server - redirect to HTTPS
server {
    listen 80;
    server_name api.project01.com;

    # Let's Encrypt ACME challenge
    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 301 https://$host$request_uri;
    }
}

# HTTPS server
server {
    listen 443 ssl http2;
    server_name api.project01.com;

    # SSL certificate
    ssl_certificate /etc/letsencrypt/live/api.project01.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/api.project01.com/privkey.pem;

    # HSTS
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # Logging
    access_log /var/log/nginx/project01-backend-access.log;
    error_log /var/log/nginx/project01-backend-error.log;

    # Rate limiting (protect against abuse)
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req zone=api_limit burst=20 nodelay;

    # Proxy to Node.js backend
    location / {
        proxy_pass http://project1_backend;
        proxy_http_version 1.1;

        # Headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Increase timeout for long-running requests
        proxy_connect_timeout 75s;
        proxy_send_timeout 75s;
        proxy_read_timeout 75s;

        # Don't buffer uploads
        proxy_request_buffering off;
    }

    # Health check endpoint (don't log)
    location /health {
        proxy_pass http://project1_backend/health;
        access_log off;
    }
}
```

### Project 2 Frontend Nginx Configuration

```nginx
# /opt/docker-projects/nginx-proxy/conf.d/project02-frontend.conf

# Upstream for Project 2 Frontend
upstream project2_frontend {
    server project2_frontend:3000;
    keepalive 32;
}

# HTTP server - redirect to HTTPS
server {
    listen 80;
    server_name project02.com www.project02.com;

    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 301 https://$host$request_uri;
    }
}

# HTTPS server
server {
    listen 443 ssl http2;
    server_name project02.com www.project02.com;

    # SSL certificate
    ssl_certificate /etc/letsencrypt/live/project02.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/project02.com/privkey.pem;

    # HSTS
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # Logging
    access_log /var/log/nginx/project02-frontend-access.log;
    error_log /var/log/nginx/project02-frontend-error.log;

    # Proxy to Next.js frontend
    location / {
        proxy_pass http://project2_frontend;
        proxy_http_version 1.1;

        # Headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # WebSocket support for Next.js hot reload
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";

        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # Next.js specific - static assets
    location /_next/static/ {
        proxy_pass http://project2_frontend;
        proxy_cache_valid 60m;
        add_header Cache-Control "public, immutable";
    }
}
```

### Project 2 Backend Nginx Configuration

```nginx
# /opt/docker-projects/nginx-proxy/conf.d/project02-backend.conf

# Upstream for Project 2 Backend
upstream project2_backend {
    server project2_backend:8080;
    keepalive 32;
}

# HTTP server - redirect to HTTPS
server {
    listen 80;
    server_name api.project02.com;

    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 301 https://$host$request_uri;
    }
}

# HTTPS server
server {
    listen 443 ssl http2;
    server_name api.project02.com;

    # SSL certificate
    ssl_certificate /etc/letsencrypt/live/api.project02.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/api.project02.com/privkey.pem;

    # HSTS
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # Logging
    access_log /var/log/nginx/project02-backend-access.log;
    error_log /var/log/nginx/project02-backend-error.log;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api2_limit:10m rate=10r/s;
    limit_req zone=api2_limit burst=20 nodelay;

    # Proxy to Golang backend
    location / {
        proxy_pass http://project2_backend;
        proxy_http_version 1.1;

        # Headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # Health check endpoint
    location /health {
        proxy_pass http://project2_backend/health;
        access_log off;
    }
}
```

---

## 7. SSL Certificate Configuration with Let's Encrypt {#ssl-setup}

Let's Encrypt provides free SSL certificates. We'll obtain certificates for all four domains.

### Understanding the SSL Process

Here's how Let's Encrypt verification works:

```
┌─────────────────────────────────────────────────────────────────┐
│                    Let's Encrypt Process                        │
└─────────────────────────────────────────────────────────────────┘

1. You request certificate for project01.com
   ↓
2. Let's Encrypt says: "Prove you control project01.com by creating
   a specific file at http://project01.com/.well-known/acme-challenge/xyz"
   ↓
3. Certbot creates the challenge file in /var/www/certbot/
   ↓
4. Nginx serves this file when Let's Encrypt checks
   ↓
5. Let's Encrypt verifies: "Yes, you control this domain"
   ↓
6. Certificate is issued and saved to /etc/letsencrypt/
   ↓
7. Nginx loads the certificate and starts serving HTTPS
```

### Initial Certificate Acquisition (Before HTTPS)

Since we need HTTP to be working first (for ACME challenges), we'll obtain certificates in stages.

**Step 1: Start Nginx without SSL (temporary config)**

Create temporary HTTP-only configurations:

```nginx
# Temporary: /opt/docker-projects/nginx-proxy/conf.d/temp-project01.conf

server {
    listen 80;
    server_name project01.com www.project01.com;

    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 200 "Temporary - setting up SSL\n";
        add_header Content-Type text/plain;
    }
}
```

Create similar files for all domains:

- `temp-project01.conf` (project01.com, www.project01.com)
- `temp-api-project01.conf` (api.project01.com)
- `temp-project02.conf` (project02.com, www.project02.com)
- `temp-api-project02.conf` (api.project02.com)

**Step 2: Start Nginx proxy (HTTP only)**

```bash
cd /opt/docker-projects/nginx-proxy
docker-compose up -d nginx
```

**Step 3: Obtain SSL certificates**

```bash
# Certificate for project01.com (frontend)
docker-compose run --rm certbot certonly \
  --webroot \
  --webroot-path=/var/www/certbot \
  --email your-email@example.com \
  --agree-tos \
  --no-eff-email \
  -d project01.com \
  -d www.project01.com

# Certificate for api.project01.com (backend)
docker-compose run --rm certbot certonly \
  --webroot \
  --webroot-path=/var/www/certbot \
  --email your-email@example.com \
  --agree-tos \
  --no-eff-email \
  -d api.project01.com

# Certificate for project02.com (frontend)
docker-compose run --rm certbot certonly \
  --webroot \
  --webroot-path=/var/www/certbot \
  --email your-email@example.com \
  --agree-tos \
  --no-eff-email \
  -d project02.com \
  -d www.project02.com

# Certificate for api.project02.com (backend)
docker-compose run --rm certbot certonly \
  --webroot \
  --webroot-path=/var/www/certbot \
  --email your-email@example.com \
  --agree-tos \
  --no-eff-email \
  -d api.project02.com
```

**Important**: Replace `your-email@example.com` with your actual email. Let's Encrypt uses this for expiration notices.

**Step 4: Verify certificates were created**

```bash
sudo ls -la /etc/letsencrypt/live/

# You should see directories:
# project01.com/
# api.project01.com/
# project02.com/
# api.project02.com/
```

**Step 5: Replace temporary configs with real HTTPS configs**

Delete the temporary configs:

```bash
cd /opt/docker-projects/nginx-proxy/conf.d
rm temp-*.conf
```

Create the permanent HTTPS configurations (use the configs from section 6 above).

**Step 6: Reload Nginx**

```bash
cd /opt/docker-projects/nginx-proxy
docker-compose restart nginx
```

### Testing SSL Configuration

```bash
# Test SSL certificate
curl -vI https://project01.com
curl -vI https://api.project01.com
curl -vI https://project02.com
curl -vI https://api.project02.com

# Check SSL grade (optional, using external service)
# Visit: https://www.ssllabs.com/ssltest/analyze.html?d=project01.com
```

### Automatic Certificate Renewal

Let's Encrypt certificates expire every 90 days. The certbot container automatically renews them.

**Verify auto-renewal is working:**

```bash
# Check certbot container is running
docker ps | grep certbot

# Manually test renewal (dry run)
docker-compose run --rm certbot renew --dry-run
```

**Set up renewal hook to reload Nginx:**

Create a renewal hook script:

```bash
#!/bin/bash
# /opt/scripts/reload-nginx-after-renewal.sh

docker exec nginx_proxy nginx -s reload
echo "Nginx reloaded at $(date)" >> /var/log/certbot-renewal.log
```

Make it executable:

```bash
chmod +x /opt/scripts/reload-nginx-after-renewal.sh
```

Update certbot to use the hook:

```yaml
# Update nginx-proxy/docker-compose.yml certbot service:
certbot:
  image: certbot/certbot:latest
  container_name: certbot
  volumes:
    - /etc/letsencrypt:/etc/letsencrypt
    - /var/lib/letsencrypt:/var/lib/letsencrypt
    - ./certbot:/var/www/certbot
  entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew --deploy-hook \"/opt/scripts/reload-nginx-after-renewal.sh\"; sleep 12h & wait $${!}; done;'"
```

---

## 8. DNS Configuration {#dns-config}

For your domains to work, you need to configure DNS records pointing to your server's IP address.

### Required DNS Records

Log into your domain registrar's DNS management panel (GoDaddy, Namecheap, Cloudflare, etc.) and create these records:

**For Project 1:**

```
Type    Name              Value                   TTL
----    ----              -----                   ---
A       project01.com     YOUR_SERVER_IP          3600
A       www.project01     YOUR_SERVER_IP          3600
A       api.project01     YOUR_SERVER_IP          3600
```

**For Project 2:**

```
Type    Name              Value                   TTL
----    ----              -----                   ---
A       project02.com     YOUR_SERVER_IP          3600
A       www.project02     YOUR_SERVER_IP          3600
A       api.project02     YOUR_SERVER_IP          3600
```

Replace `YOUR_SERVER_IP` with your server's public IP address.

### DNS Propagation

After adding DNS records, wait for propagation (usually 5-60 minutes, sometimes up to 24 hours).

**Check DNS propagation:**

```bash
# Check if DNS is resolving
dig project01.com
dig api.project01.com
dig project02.com
dig api.project02.com

# Or using nslookup
nslookup project01.com
nslookup api.project01.com
```

The output should show your server's IP address.

**Online DNS propagation checker:**

- https://dnschecker.org
- https://www.whatsmydns.net

Enter your domain names to see if they're resolving correctly globally.

---

## 9. Deployment Steps {#deployment}

Now let's deploy everything in the correct order.

### Complete Deployment Procedure

```bash
# Step 1: Ensure you're in the projects directory
cd /opt/docker-projects

# Step 2: Create the shared network (if not already created)
docker network create proxy_network

# Step 3: Start Project 1
cd /opt/docker-projects/project1
docker-compose up -d --build

# Wait for services to be healthy
docker-compose ps

# Check logs if there are issues
docker-compose logs -f

# Step 4: Start Project 2
cd /opt/docker-projects/project2
docker-compose up -d --build

# Check status
docker-compose ps
docker-compose logs -f

# Step 5: Start Nginx Proxy
cd /opt/docker-projects/nginx-proxy

# If this is initial setup and you haven't gotten SSL certificates yet:
# Use temporary configs, start nginx, get certificates (see Section 7)

# If you already have certificates:
docker-compose up -d

# Step 6: Verify all containers are running
docker ps

# You should see:
# - nginx_proxy
# - certbot
# - project1_frontend
# - project1_backend
# - project1_postgres
# - project1_redis
# - project2_frontend
# - project2_backend
# - project2_postgres
```

### Verification Checklist

```bash
# 1. Check container health
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# 2. Check networks
docker network inspect proxy_network

# 3. Test internal connectivity
docker exec project1_backend ping -c 2 postgres
docker exec project1_backend ping -c 2 redis

# 4. Check Nginx configuration syntax
docker exec nginx_proxy nginx -t

# 5. View Nginx logs
docker logs nginx_proxy --tail 50

# 6. Test HTTP to HTTPS redirect
curl -I http://project01.com
# Should return 301 redirect to https://

# 7. Test HTTPS endpoints
curl https://project01.com
curl https://api.project01.com/health
curl https://project02.com
curl https://api.project02.com/health

# 8. Check database connectivity
docker exec -it project1_postgres psql -U project1_user -d project1_database -c "SELECT version();"
```

### Deployment Script

Create an automated deployment script:

```bash
#!/bin/bash
# /opt/scripts/deploy-all.sh

set -e  # Exit on error

echo "=== Starting deployment ==="

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Function to print colored messages
print_success() {
    echo -e "${GREEN}✓ $1${NC}"
}

print_error() {
    echo -e "${RED}✗ $1${NC}"
}

print_info() {
    echo -e "${YELLOW}→ $1${NC}"
}

# Check if running as root
if [[ $EUID -eq 0 ]]; then
   print_error "Don't run this script as root"
   exit 1
fi

# Ensure proxy network exists
print_info "Checking proxy network..."
if ! docker network inspect proxy_network >/dev/null 2>&1; then
    docker network create proxy_network
    print_success "Created proxy_network"
else
    print_success "proxy_network exists"
fi

# Deploy Project 1
print_info "Deploying Project 1..."
cd /opt/docker-projects/project1
docker-compose pull
docker-compose up -d --build
if [ $? -eq 0 ]; then
    print_success "Project 1 deployed"
else
    print_error "Project 1 deployment failed"
    exit 1
fi

# Deploy Project 2
print_info "Deploying Project 2..."
cd /opt/docker-projects/project2
docker-compose pull
docker-compose up -d --build
if [ $? -eq 0 ]; then
    print_success "Project 2 deployed"
else
    print_error "Project 2 deployment failed"
    exit 1
fi

# Deploy Nginx Proxy
print_info "Deploying Nginx Proxy..."
cd /opt/docker-projects/nginx-proxy
docker-compose up -d
if [ $? -eq 0 ]; then
    print_success "Nginx Proxy deployed"
else
    print_error "Nginx Proxy deployment failed"
    exit 1
fi

# Wait for services to be healthy
print_info "Waiting for services to be healthy..."
sleep 10

# Check all containers
print_info "Checking container status..."
docker ps --format "table {{.Names}}\t{{.Status}}"

print_success "Deployment complete!"
print_info "Access your projects at:"
echo "  - https://project01.com"
echo "  - https://api.project01.com"
echo "  - https://project02.com"
echo "  - https://api.project02.com"
```

Make it executable:

```bash
chmod +x /opt/scripts/deploy-all.sh
```

---

## 10. Testing and Verification {#testing}

### Testing Each Component

**Test 1: Nginx Proxy**

```bash
# Check Nginx is running
docker ps | grep nginx_proxy

# Test configuration
docker exec nginx_proxy nginx -t

# Check which domains Nginx is serving
docker exec nginx_proxy nginx -T | grep server_name
```

**Test 2: SSL Certificates**

```bash
# Check certificate details
openssl s_client -connect project01.com:443 -servername project01.com < /dev/null | openssl x509 -noout -dates

# Should show:
# notBefore: [issue date]
# notAfter: [expiry date, ~90 days from issue]
```

**Test 3: Project 1 Frontend**

```bash
# Test HTTP to HTTPS redirect
curl -I http://project01.com
# Should return: HTTP/1.1 301 Moved Permanently

# Test HTTPS works
curl -I https://project01.com
# Should return: HTTP/2 200

# Test actual page content
curl https://project01.com
```

**Test 4: Project 1 Backend**

```bash
# Test health endpoint
curl https://api.project01.com/health

# Should return JSON:
# {"status":"healthy","timestamp":"2024-..."}

# Test API endpoint
curl https://api.project01.com/api/users
```

**Test 5: Project 2 Frontend**

```bash
curl -I https://project02.com
# Should return HTTP/2 200

# View page
curl https://project02.com
```

**Test 6: Project 2 Backend**

```bash
# Test health
curl https://api.project02.com/health

# Test API
curl https://api.project02.com/api/users
```

**Test 7: Database Connectivity**

```bash
# Project 1 - Check PostgreSQL
docker exec -it project1_postgres psql -U project1_user -d project1_database -c "\dt"

# Project 1 - Check Redis
docker exec -it project1_redis redis-cli -a $(grep REDIS_PASSWORD /opt/docker-projects/project1/.env | cut -d '=' -f2) PING

# Project 2 - Check PostgreSQL
docker exec -it project2_postgres psql -U project2_user -d project2_database -c "\dt"
```

**Test 8: Cross-Origin Requests (CORS)**

```bash
# Test CORS from frontend to backend
curl -I -X OPTIONS https://api.project01.com/api/users \
  -H "Origin: https://project01.com" \
  -H "Access-Control-Request-Method: GET"

# Should return:
# Access-Control-Allow-Origin: https://project01.com
```

### Browser Testing

Open your browser and test:

1. Visit `https://project01.com` - should load React app without SSL warnings
2. Open browser console (F12) - check for any errors
3. Visit `https://api.project01.com/health` - should return JSON health status
4. Visit `https://project02.com` - should load Next.js app
5. Visit `https://api.project02.com/health` - should return JSON health status

### Performance Testing

```bash
# Test response times
time curl -so /dev/null -w "HTTP: %{http_code}\nTime: %{time_total}s\n" https://project01.com

# Load testing with Apache Bench (install if needed: apt install apache2-utils)
ab -n 1000 -c 10 https://project01.com/

# Or using wrk (install: apt install wrk)
wrk -t4 -c100 -d30s https://project01.com/
```

---

## 11. Maintenance and Troubleshooting {#maintenance}

### Common Issues and Solutions

**Issue 1: "502 Bad Gateway"**

This means Nginx can't reach the backend container.

```bash
# Check if backend container is running
docker ps | grep project1_backend

# Check if backend is on proxy_network
docker network inspect proxy_network | grep project1_backend

# Check backend logs
docker logs project1_backend --tail 50

# Test if backend responds internally
docker exec nginx_proxy wget -O- http://project1_backend:5000/health
```

**Solution**: Usually means the backend isn't healthy or isn't on the proxy network. Restart the backend:

```bash
cd /opt/docker-projects/project1
docker-compose restart backend
```

**Issue 2: "SSL Certificate Error"**

Browser shows SSL warnings.

```bash
# Check if certificate exists
ls -la /etc/letsencrypt/live/project01.com/

# Check certificate expiry
openssl x509 -in /etc/letsencrypt/live/project01.com/fullchain.pem -noout -enddate

# Check Nginx SSL configuration
docker exec nginx_proxy nginx -T | grep ssl_certificate
```

**Solution**: Certificate might have expired or paths in Nginx config are wrong. Renew certificate:

```bash
cd /opt/docker-projects/nginx-proxy
docker-compose run --rm certbot renew --force-renewal
docker-compose restart nginx
```

**Issue 3: "Cannot connect to database"**

Backend can't reach the database.

```bash
# Check if database is running
docker ps | grep postgres

# Check database health
docker exec project1_postgres pg_isready -U project1_user

# Test connection from backend
docker exec project1_backend ping -c 2 postgres

# Check if on same network
docker network inspect project1_network | grep -E "project1_backend|project1_postgres"
```

**Solution**: Ensure both are on the same internal network:

```bash
cd /opt/docker-projects/project1
docker-compose down
docker-compose up -d
```

**Issue 4: "Let's Encrypt rate limit exceeded"**

You've requested too many certificates (5 per week per domain).

```bash
# Check when you can request again
# Visit: https://crt.sh/?q=project01.com
```

**Solution**: Wait for rate limit to reset, or use DNS challenge instead of HTTP challenge.

### Monitoring Scripts

**Check all services status:**

```bash
#!/bin/bash
# /opt/scripts/check-status.sh

echo "=== Docker Containers ==="
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

echo -e "\n=== Disk Usage ==="
df -h | grep -E "Filesystem|/opt|/var/lib/docker"

echo -e "\n=== Docker Disk Usage ==="
docker system df

echo -e "\n=== Network Status ==="
docker network ls

echo -e "\n=== SSL Certificate Expiry ==="
for domain in project01.com api.project01.com project02.com api.project02.com; do
    expiry=$(openssl x509 -in /etc/letsencrypt/live/$domain/fullchain.pem -noout -enddate 2>/dev/null | cut -d= -f2)
    echo "$domain: $expiry"
done

echo -e "\n=== Recent Nginx Errors ==="
docker exec nginx_proxy tail -n 20 /var/log/nginx/error.log
```

### Backup Script

```bash
#!/bin/bash
# /opt/scripts/backup.sh

BACKUP_DIR="/opt/backups"
DATE=$(date +%Y%m%d_%H%M%S)

# Backup Project 1 database
echo "Backing up Project 1 database..."
docker exec project1_postgres pg_dump -U project1_user project1_database | gzip > ${BACKUP_DIR}/project1/db_${DATE}.sql.gz

# Backup Project 2 database
echo "Backing up Project 2 database..."
docker exec project2_postgres pg_dump -U project2_user project2_database | gzip > ${BACKUP_DIR}/project2/db_${DATE}.sql.gz

# Backup Redis data (Project 1)
echo "Backing up Project 1 Redis..."
docker exec project1_redis redis-cli -a $(grep REDIS_PASSWORD /opt/docker-projects/project1/.env | cut -d '=' -f2) SAVE
docker cp project1_redis:/data/dump.rdb ${BACKUP_DIR}/project1/redis_${DATE}.rdb

# Backup SSL certificates
echo "Backing up SSL certificates..."
tar -czf ${BACKUP_DIR}/ssl_${DATE}.tar.gz /etc/letsencrypt

# Clean old backups (older than 30 days)
find ${BACKUP_DIR} -type f -mtime +30 -delete

echo "Backup completed: $DATE"
```

**Automate backups with cron:**

```bash
sudo crontab -e

# Add this line (runs daily at 2 AM):
0 2 * * * /opt/scripts/backup.sh >> /var/log/backup.log 2>&1
```

### Update Strategy

**Update Docker images:**

```bash
#!/bin/bash
# /opt/scripts/update.sh

cd /opt/docker-projects/project1
docker-compose pull
docker-compose up -d --build

cd /opt/docker-projects/project2
docker-compose pull
docker-compose up -d --build

cd /opt/docker-projects/nginx-proxy
docker-compose pull
docker-compose up -d

# Clean up old images
docker image prune -af
```

### Log Management

**View logs:**

```bash
# All logs from a project
docker-compose -f /opt/docker-projects/project1/docker-compose.yml logs -f

# Specific service logs
docker logs project1_backend -f --tail 100

# Nginx access logs
docker exec nginx_proxy tail -f /var/log/nginx/access.log

# Nginx error logs
docker exec nginx_proxy tail -f /var/log/nginx/error.log
```

**Log rotation (prevent logs from filling disk):**

```json
// /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  }
}
```

Restart Docker after changing:

```bash
sudo systemctl restart docker
```

---

## Summary

You now have a complete, production-ready setup with:

✅ Two separate projects running on one server ✅ Four domains with automatic SSL certificates ✅ Nginx reverse proxy handling all traffic ✅ Isolated networks for security ✅ Health checks and proper error handling ✅ Automated certificate renewal ✅ Backup and monitoring scripts

### Architecture Overview

```
Internet → Nginx Proxy (SSL) → Routes by domain:
    ├─ project01.com     → React Frontend (Project 1)
    ├─ api.project01.com → Node.js Backend (Project 1) → PostgreSQL + Redis
    ├─ project02.com     → Next.js Frontend (Project 2)
    └─ api.project02.com → Golang Backend (Project 2) → PostgreSQL
```

All services are containerized, isolated, and can be updated independently without affecting each other.