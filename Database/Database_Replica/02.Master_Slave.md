# Chapter: Understanding Primary–Replica (Master–Slave) Replication

Imagine you’re running a busy restaurant.

* The **head chef** is the only one allowed to cook new dishes (the *primary*).
* The **assistant chefs** don’t cook on their own, but they keep watching the head chef carefully, taking notes, and repeating every move so their copies of the dishes match exactly (the *replicas*).
* Customers who just want to *look at the food* (read queries) can walk over to the assistants.
* But if someone wants to *add new orders* (write queries), it always goes to the head chef.

That’s **primary–replica replication** in databases.

---

## Step 1: Why do we even need this?

Databases get stressed under heavy traffic. If everyone sends both **reads** (e.g., “show me product details”) and **writes** (e.g., “add this to my cart”) to a single database, it slows down.

Replication solves this by:

1. **Sharing the load**: Primary handles writes; replicas handle reads.
2. **Safety**: If the primary fails, a replica can be promoted as the new primary.
3. **Backups**: Replicas can safely be used for backups without disturbing the main system.

---

## Step 2: How does replication actually work?

Let’s go back to our chef analogy.

* When the head chef finishes cooking a dish, they write the recipe in a notebook.
* The assistants grab this notebook and replay each step in their own kitchens.

In database terms:

* **Primary writes everything into a log** (like a recipe book).

  * In PostgreSQL, this is called the **WAL** (Write-Ahead Log).
  * In MySQL, it’s called the **binlog**.
* **Replicas read the log and apply the same changes**.

So if you run this SQL on the primary:

```sql
INSERT INTO orders (id, product) VALUES (1, 'Laptop');
```

The primary first writes this event into its log. The replica then reads:
“An order was added with id=1, product=Laptop” → and applies the same change.

---

## Step 3: The timing problem (Replication Lag)

Here’s the catch:
The replica doesn’t instantly apply the change. There’s always a small delay (milliseconds, sometimes seconds under load).

That means if you:

1. Add an order on the primary.
2. Immediately check the replica for that order.
3. You might not see it yet → because the assistant chef hasn’t finished copying the notebook.

This is called **replication lag**.

---

## Step 4: Types of replication timing

There are three common ways databases handle timing between the primary and replicas:

1. **Asynchronous (most common)**

   * Primary doesn’t wait for replicas.
   * Fastest, but you might lose the last few transactions if the primary crashes.

2. **Semi-synchronous**

   * Primary waits until at least one replica confirms it *received* the log (not applied yet).
   * Slightly safer, small delay.

3. **Synchronous**

   * Primary waits until replicas confirm they’ve *applied* the change.
   * Safest, but slowest.

---

## Step 5: Failover (What if the head chef disappears?)

If the primary crashes:

* One of the replicas is promoted to primary.
* All other replicas are told to follow the new primary.

This way the kitchen keeps running.

Tools like **Patroni** (Postgres) or **Orchestrator** (MySQL) help automate this failover.

---

## Step 6: How apps actually use this

In real systems, you set up two different “doors” to your database:

* **Write Door** → always goes to the primary.
* **Read Door** → usually goes to replicas.

But there’s one important rule:
If you just wrote some data and need to see it immediately, you **must read from the primary** (otherwise replication lag might trick you).

Example:

* A user updates their profile picture.
* If you show their profile immediately after, you should fetch from the primary.
* But if another random user checks that profile later, you can safely show it from a replica.

---

## Step 7: Putting it all together (Mental Picture)

```
Clients
   |
   |  Writes (INSERT/UPDATE/DELETE)
   v
Primary --------------> Replicas
   |                       ^
   |  Log of changes       |  Reads (SELECT queries)
   |                       |
   ------------------------- 
```

---

## Step 8: Quick summary

* Primary handles **all writes**.
* Replicas handle **reads**.
* Replicas copy changes by replaying the primary’s log.
* There’s always some **lag**.
* If the primary dies, a replica can be promoted.
* Applications must be smart about when to read from replicas and when to stick to the primary.

---

# Chapter: Building Master–Replica PostgreSQL with Docker

So far, you’ve read the story. Now, let’s set up a playground where you can *see replication in action*. We’ll use Docker, because it lets us spin up databases like little Lego blocks — no risk of messing with your actual system.

---

## Step 1: The Plan

We want:

* **One master (primary) PostgreSQL** → handles writes.
* **One replica (slave)** → copies data from master, serves reads.
* **Your app (Node.js)** → decides who gets the query.

Both databases will run in containers and talk over a shared Docker network.

---

## Step 2: The Docker Compose File

Here’s the full `docker-compose.yml` that sets up the cluster:

```yaml
version: "3.9"

services:
  # Master database
  postgres-master:
    image: postgres:16
    container_name: postgres-master
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5432:5432"
    volumes:
      - master-data:/var/lib/postgresql/data
      - ./master/init:/docker-entrypoint-initdb.d
    networks:
      - dbnet

  # Replica database
  postgres-replica:
    image: postgres:16
    container_name: postgres-replica
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5433:5432"
    depends_on:
      - postgres-master
    command:
      - "postgres"
      - "-c"
      - "primary_conninfo=host=postgres-master port=5432 user=myuser password=mypassword"
      - "-c"
      - "hot_standby=on"
    volumes:
      - replica-data:/var/lib/postgresql/data
    networks:
      - dbnet

networks:
  dbnet:

volumes:
  master-data:
  replica-data:
```

---

## Step 3: What’s Happening Here?

* **`postgres-master`**
  Runs a normal PostgreSQL instance, exposed on port `5432`.

* **`postgres-replica`**
  Also runs PostgreSQL but with `primary_conninfo` telling it:

  > “Follow the master at `postgres-master:5432` using this username and password.”

* **Volumes**
  Persist data locally, so even if containers restart, data isn’t lost.

* **Ports**

  * Master: `localhost:5432`
  * Replica: `localhost:5433`

---

## Step 4: Boot It Up

Run:

```bash
docker-compose up -d
```

You’ll now have two databases running.

---

## Step 5: Test Replication

1. Connect to the master:

```bash
docker exec -it postgres-master psql -U myuser -d mydb
```

Insert a row:

```sql
CREATE TABLE users (id SERIAL PRIMARY KEY, name TEXT);
INSERT INTO users (name) VALUES ('Alice');
```

2. Connect to the replica:

```bash
docker exec -it postgres-replica psql -U myuser -d mydb
```

Query:

```sql
SELECT * FROM users;
```

✅ You should see `Alice` appear, even though you never wrote to the replica.

That’s replication in action.

---

## Step 6: Node.js Router for Reads/Writes

Now we add the application logic. Create `db.js`:

```js
// db.js
const { Pool } = require("pg");

// Write connection (master)
const writePool = new Pool({
  host: "localhost",
  port: 5432,
  user: "myuser",
  password: "mypassword",
  database: "mydb",
});

// Read connection (replica)
const readPool = new Pool({
  host: "localhost",
  port: 5433,
  user: "myuser",
  password: "mypassword",
  database: "mydb",
});

// Query router
async function query(sql, params = [], { readOnly = false } = {}) {
  const pool = readOnly ? readPool : writePool;
  const client = await pool.connect();
  try {
    const result = await client.query(sql, params);
    return result.rows;
  } finally {
    client.release();
  }
}

module.exports = { query };
```

---

## Step 7: Example Usage

```js
// app.js
const express = require("express");
const { query } = require("./db");

const app = express();
app.use(express.json());

// Write: insert user into master
app.post("/users", async (req, res) => {
  const { name } = req.body;
  await query("INSERT INTO users (name) VALUES ($1)", [name]);
  res.send("User created");
});

// Read: fetch users from replica
app.get("/users", async (req, res) => {
  const users = await query("SELECT * FROM users", [], { readOnly: true });
  res.json(users);
});

app.listen(3000, () => console.log("App running on http://localhost:3000"));
```

Run with:

```bash
node app.js
```

* POST `/users` → goes to master.
* GET `/users` → goes to replica.

---

## Step 8: See It in Action

1. `POST /users {"name":"Bob"}`
   → Master inserts Bob.

2. `GET /users`
   → Replica returns `[Alice, Bob]`.

Your app is now truly **splitting reads and writes** across master and replica.

---

📖 *And that’s how the story turns real: one master writing the truth, many replicas serving it to readers, and your Node.js app acting as the wise librarian, deciding where each request belongs.*

---

Excellent question, Riyad 👏 — this goes to the **heart of replication**.
Let’s step back and tell the story like a dev author teaching a junior developer:

---

# Chapter: How PostgreSQL Shares Knowledge Between Master and Replica

Imagine our master database as the **scribe** of a kingdom. Every time a citizen (the user) brings new information — say, "Alice has joined" — the scribe writes it down in the royal scroll.

Now, the kingdom has many libraries (replicas) that must also know this news. But the master doesn’t let every library rewrite the scroll themselves. Instead, it sends them **copies of the scroll updates** so they stay in sync.

In PostgreSQL, that "scroll" is called the **Write-Ahead Log (WAL)**.

---

## Step 1: The Write-Ahead Log (WAL)

* When you **insert, update, or delete** something, PostgreSQL **doesn’t directly change the data on disk first**.
* Instead, it writes a record into the **WAL** — a log file that says:

  > “At 10:05 AM, row X was inserted into table users.”

This guarantees durability. If the database crashes, the WAL can be replayed to recover.

Think of WAL as the **black box flight recorder** of the database.

---

## Step 2: Streaming Replication

When replication is enabled, the master not only writes WAL for itself, but also **streams** these WAL records over TCP to the replicas.

* The replica runs in a special mode called **standby**.
* It continuously receives WAL entries from the master.
* The replica then **replays those WAL changes** on its own data files, applying inserts, updates, and deletes exactly as they happened.

So replicas don’t re-run SQL queries. They simply **replay the changes** at the storage level.

---

## Step 3: How Does It Happen in Real Time?

1. **User writes on Master** → `INSERT INTO users (name) VALUES ('Alice');`
2. Master logs this to WAL.
3. WAL is **sent over the network** to replicas.
4. Replica applies the WAL and now its copy of `users` also has Alice.

To the outside world, it looks like replication is “instant.” In reality, it’s just **WAL shipping + replaying**.

---

## Step 4: Synchronous vs Asynchronous

PostgreSQL gives you a choice:

* **Asynchronous replication (default)**

  * Master writes WAL and sends it off.
  * It doesn’t wait for replicas to confirm.
  * Faster, but if the master crashes, the replica might be slightly behind.

* **Synchronous replication**

  * Master waits until at least one replica confirms it has received WAL.
  * Slower, but safer (zero data loss in a crash).

Think of it like this:

* Asynchronous = “I sent the letter, they’ll get it eventually.”
* Synchronous = “I won’t leave the post office until the receiver signs for it.”

---

## Step 5: Why Replicas Are Read-Only

Because WAL contains *exactly how the master wrote data*, if a replica started accepting writes of its own, it would create conflicts.
That’s why replicas are **read-only**: they just follow orders from WAL, like a mirror.

---

## Step 6: Visual Flow

```
User → Master (writes)
          ↓
       WAL log
          ↓
   Stream WAL over network
          ↓
     Replica (replay WAL, read-only)
```

---

💡 So in short:
PostgreSQL keeps master and replica in sync by **streaming WAL records** — little “change notes” — from the master to the replicas, which then **replay them** to stay identical.

---