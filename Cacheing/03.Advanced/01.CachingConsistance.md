# **Cache Consistency – How to Avoid Stale Data**

In modern backend systems, especially **microservices** or distributed architectures, caching is not just a performance booster—it is a double-edged sword. While caching accelerates responses, improper caching can lead to **stale data**, **race conditions**, and even **critical business errors**.

Cache **consistency** is the discipline of ensuring that the cached data reflects the true source of truth (usually a database) as accurately as needed by your application.

---

## **1. Why Cache Consistency Matters**

Imagine you have an e-commerce system:

1. A customer adds an item to the cart.
2. The cart service caches the user’s cart in memory or Redis.
3. Another service, like checkout, reads from the cache to show cart totals.

If the cache is **stale**, the customer might see:

* Incorrect pricing.
* Items already sold out.
* Invalid promotions.

Consequences:

* Loss of revenue.
* Customer trust issues.
* Bugs that are extremely hard to reproduce.

> In distributed systems, “stale cache” is not just a bug—it’s a **system-level hazard**.

---

## **2. Core Principles of Cache Consistency**

Consistency is about **how up-to-date your cached data is**, relative to the authoritative source. There are **three main dimensions**:

1. **Time** – How long before cached data expires? (TTL)
2. **Propagation** – How quickly updates reach all caches?
3. **Atomicity** – Are cache updates synchronized with database writes?

---

### **2.1 Time-Based Consistency (TTL)**

**How it works:**

* Each cache entry has a **time-to-live (TTL)**.
* After TTL expires, the data is automatically considered stale and removed.

**Why it works:**

* Simple and automatic.
* Prevents cache from living forever with outdated data.

**Limitations:**

* Data can be stale for the TTL duration.
* Not ideal for critical or high-velocity data.

**Example:**

```text
# Cache product price with TTL 5 minutes
SET product:123:price 19.99 EX 300
```

Even if the price changes in the DB immediately, users may see the old price until TTL expires.

---

### **2.2 Manual / Explicit Invalidation**

**How it works:**

* Whenever the underlying data changes, the cache is **explicitly cleared** or updated.
* Usually triggered inside the application logic or via hooks in the database.

**Why it works:**

* Ensures freshness immediately after the update.
* Ideal for known-change events.

**Pitfalls:**

* Easy to forget an invalidation → stale cache.
* Harder in distributed systems with multiple nodes.

**Example:**

```text
UPDATE product SET price=20 WHERE id=123;
DEL product:123:price;
```

---

### **2.3 Event-Driven Invalidation**

**How it works:**

* Each microservice keeps a **local cache**.
* When a service updates data, it **publishes an event** (e.g., Kafka, Redis Pub/Sub).
* Other services **subscribe** to these events and invalidate their local caches.

**Why it works:**

* Maintains cache consistency across distributed services.
* Scales well in microservice architecture.

**Example flow:**

1. Inventory service updates stock for `product:123`.
2. Publishes: `invalidate:product:123`.
3. Cart service receives the event → deletes local cache key.
4. Next read fetches fresh data from DB.

---

### **2.4 Versioned Keys / Monotonic Bumping**

**How it works:**

* Cache keys include a **version number**: `product:123:v1`.
* On update, increment version → `v2`.
* Old versions automatically expire.

**Why it works:**

* Avoids **race conditions** where a cache is updated while reads are ongoing.
* No need to delete old keys immediately; TTL handles cleanup.

**Example:**

```text
# Old key
GET product:123:v1   → returns stale

# After update
SET product:123:v2  → new reads use v2
```

---

### **2.5 Combining TTL + Invalidation (Hybrid Approach)**

For **critical data**, we rarely rely on TTL alone. We use **hybrid strategies**:

* Event-driven invalidation for **immediate freshness**.
* Short TTL as a **safety net** in case the invalidation message is lost.

**Benefits:**

* Minimized stale data window.
* Resilient to network failures or broker downtime.

---

## **3. Patterns to Remember**

| Strategy                  | Freshness | Pros                                 | Cons                              | Best For                        |
| ------------------------- | --------- | ------------------------------------ | --------------------------------- | ------------------------------- |
| Static TTL                | Low       | Simple, automatic                    | Stale until TTL expires           | Rarely-changing data            |
| Manual Invalidation       | High      | Immediate consistency                | Easy to forget                    | Known-change events             |
| Event-Driven Invalidation | High      | Distributed consistency across nodes | Requires messaging infrastructure | Microservices / real-time data  |
| Versioned Keys            | High      | Avoids race conditions               | Extra key management              | Critical data updates           |
| TTL + Event               | Very High | Safety + immediate freshness         | Complex                           | High-stakes, multi-service data |

---

## **4. Key Takeaways**

1. Cache is **not a database**—it is an optimization. Treat it with care.
2. Always define your **consistency requirements** per data type:

   * User session: must be fresh → high consistency.
   * Product catalog: can tolerate some staleness → low consistency.
3. **Hybrid strategies** usually work best in production.
4. Instrument metrics:

   * Cache hit/miss rate.
   * Invalidation lag.
   * TTL expirations.

> **Golden rule:** “Never assume cache is always fresh. Always design for eventual or immediate invalidation depending on business criticality.”

---