# **Chapter: TTL and Invalidation Strategies in Backend Caching (with Propagation Considerations)**

Caching is like keeping a **shortcut** to your data. Done right, it speeds up your application dramatically; done wrong, it leads to stale data, weird bugs, or angry users asking, *“Why am I still seeing the old value?”*.

To make caching **safe** and **reliable**, two major topics come into play:

1. **TTL (Time-to-Live)** – Deciding *how long* cached data stays valid.
2. **Invalidation Strategies** – Deciding *when* and *how* cached data should be removed or updated.

In distributed systems, **cache propagation** becomes critical — meaning you must ensure that changes in one place are quickly reflected everywhere else that relies on cached data.

---

## **Step 1: Understanding TTL (Time-to-Live)**

### 1.1 What is TTL?

TTL is the **lifespan** of a cache entry, measured from the moment it is stored until it expires. After the TTL elapses, the cache automatically removes the data or marks it stale.

**Example:**
If you store a product price in Redis with a TTL of `300 seconds`, it will disappear after 5 minutes unless refreshed.

```plaintext
SET product:123:price 19.99 EX 300
```

### 1.2 Why Use TTL?

* **Automatic freshness control** — old data doesn’t live forever.
* **Memory management** — expired items free up space.
* **Fail-safe** — even if you forget to invalidate, data won’t stay stale forever.

---

## **Step 2: Explore TTL Strategies in Backend Systems**

TTL is not one-size-fits-all. The **right TTL** depends on the data type and the cost of fetching fresh data.

### 2.1 **Static TTL**

* Fixed expiry for all items in a category.
* Good for data that changes rarely.
* Example: Country codes (TTL = 1 day).

### 2.2 **Dynamic TTL**

* TTL depends on the data’s volatility.
* Example: Stock prices (TTL = 5 seconds), blog posts (TTL = 1 hour).

### 2.3 **Sliding TTL (Refresh-on-Access)**

* TTL resets every time the item is accessed.
* Keeps frequently used data fresh longer.
* Example: User session tokens.

```plaintext
GET user:session:abc
-> refresh TTL to 30 minutes
```

### 2.4 **Randomized TTL (Jitter)**

* Adds randomness to TTL to avoid **cache stampedes** (thundering herd problem).
* Example: Instead of 60 minutes, store as `60 ± random(0-10)` minutes.

---

## **Step 3: Understand the Challenge of Cache Invalidation**

**Why is invalidation hard?** Because you must ensure no request uses stale data after an update.
Even **Jeff Dean** from Google famously said:

> “There are only two hard things in computer science: cache invalidation and naming things.”

---

## **Step 4: Learn the Main Invalidation Strategies**

### 4.1 **Time-Based Invalidation**

* Relies purely on TTL.
* No explicit invalidation call.
* **Pros:** Simple, automatic.
* **Cons:** Can serve stale data until expiry.

### 4.2 **Write-Through Invalidation**

* Every time you write to the DB, you *also* update the cache immediately.
* Example: Updating a product price:

  * Update DB → Update cache with new value.
* **Pros:** Cache always up-to-date.
* **Cons:** Slightly higher write latency.

### 4.3 **Write-Behind (Asynchronous)**

* Write to cache first, then queue an async write to DB.
* Example: Real-time analytics counters.
* **Pros:** Very fast writes.
* **Cons:** Risk of data loss if cache fails before DB write.

### 4.4 **Explicit/Manual Invalidation**

* You explicitly remove an item from cache when you *know* it changed.
* Example:

```plaintext
DEL product:123
```

* **Pros:** Complete control.
* **Cons:** Easy to forget; may leave stale cache.

### 4.5 **Event-Driven Invalidation**

* Subscribe cache to a message/event bus (Kafka, RabbitMQ, Redis Pub/Sub).
* When data changes, publish an **invalidate event**.
* **Pros:** Real-time propagation across distributed systems.
* **Cons:** More moving parts; requires a message broker.

---

## **Step 5: Propagation Challenges in Distributed Caches**

In small apps, you may have a **single cache node**. In production, you often have **multiple nodes** or **multiple services** each with their own local caches.

### 5.1 **The Staleness Problem**

Imagine Service A updates the DB, clears its local cache, but Service B still has stale data. Without propagation, B serves wrong data.

---

### 5.2 Solutions for Propagation

#### Centralized Cache

* All services read/write to one cache (e.g., Redis cluster).
* Invalidation is instant because there’s only one source.
* **Trade-off:** Single point of failure (unless replicated).

#### Pub/Sub Invalidation

* Services with local caches subscribe to invalidation events.
* Example:

  1. Service A updates product 123.
  2. Service A publishes `invalidate:product:123`.
  3. All other services delete their local cache entry.

#### Versioning Keys

* Instead of deleting cache, use a version number in the key.
* Example:

  * Key: `product:123:v1`
  * After update → Increment to `v2`
* All new requests use the new version key.

#### Hybrid: TTL + Event

* Use short TTL as a backup in case event propagation fails.
* Prevents stale cache lasting forever.

---

## **Step 6: Real-World Best Practices**

1. **Never rely solely on TTL for critical data** — combine TTL with explicit invalidation.
2. **Use consistent key naming** — e.g., `entityType:entityId:field`.
3. **Add jitter to TTL** — avoids stampedes.
4. **Instrument cache hit/miss metrics** — Prometheus, Grafana.
5. **Avoid over-invalidation** — deleting too much can cause cache storms.
6. **Test under load** — ensure propagation works at scale.

---

## **Step 7: Code Example — Event-Driven Invalidation with Redis Pub/Sub**

```typescript
// publisher.ts
import { createClient } from "redis";
const redis = createClient();

async function updateProductPrice(productId: string, price: number) {
    // Update DB (pseudo-code)
    await db.products.update({ id: productId, price });

    // Publish invalidation event
    await redis.publish("cache:invalidate", `product:${productId}`);
}
```

```typescript
// subscriber.ts
import { createClient } from "redis";
const redis = createClient();
const localCache = new Map();

redis.subscribe("cache:invalidate", (message) => {
    console.log(`Invalidating local cache for ${message}`);
    localCache.delete(message);
});
```

---

## **Step 8: Deep Dive — Caching Strategies Table Explained**

This table compares common cache expiration and invalidation strategies by four key factors:

| **Factor**         | Meaning                                                                                                                                                        |
| ------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Freshness**      | How up-to-date the cached data stays — high means near real-time accuracy, low means more stale data can appear.                                               |
| **Complexity**     | How difficult the strategy is to implement and maintain — higher complexity usually means more code, infrastructure, or coordination.                          |
| **Latency Impact** | How much the caching strategy affects request latency — "None" means it doesn't add extra delay, "Low" means some additional time due to invalidation/refresh. |
| **Best For**       | The types of data or scenarios where this strategy works best.                                                                                                 |

---

### Strategy Breakdown & Examples

#### 8.1 Static TTL

* **How it works:** Data is cached with a fixed expiration time. After TTL expires, data is considered stale and refreshed on the next request.
* **Freshness:** Low — cached data can be stale until TTL expires.
* **Complexity:** Low — easy to implement with most caching systems.
* **Latency Impact:** None — no extra delay, reads are fast, writes do not require cache updates.
* **Example:** Product catalog descriptions that change only once a day. Even if a description changes right after caching, users might see the old description for some time until the TTL expires.

#### 8.2 Dynamic TTL

* **How it works:** TTL is adjusted dynamically based on data volatility or usage patterns — more volatile data gets shorter TTLs.
* **Freshness:** Medium — fresher than static TTL because hot/changing data expires faster.
* **Complexity:** Medium — requires monitoring data change rates and applying TTL logic.
* **Latency Impact:** None — similar to static TTL, reads remain fast.
* **Example:** News headlines might have TTL of 1 minute during breaking news and 10 minutes otherwise.

#### 8.3 Sliding TTL

* **How it works:** Each read or write "touches" the TTL, extending it. This keeps frequently accessed keys alive longer.
* **Freshness:** High — frequently used data stays fresh, less-used data expires naturally.
* **Complexity:** Medium — requires updating TTL on each access.
* **Latency Impact:** None — updating TTL is usually a lightweight operation.
* **Example:** User session tokens where activity extends session life, preventing expiry while user is active.

#### 8.4 Manual Invalidation

* **How it works:** Cache entries are invalidated explicitly by the application when data changes, rather than relying on TTL expiration.
* **Freshness:** High — data is updated immediately after a change.
* **Complexity:** High — requires careful tracking and publishing of invalidation events.
* **Latency Impact:** None — cache reads remain fast, invalidation happens asynchronously.
* **Example:** E-commerce cart cache that is invalidated immediately after a user updates cart contents.

#### 8.5 Event-Driven Invalidation

* **How it works:** Changes in one service publish events that notify other services to invalidate or update their caches.
* **Freshness:** High — caches across multiple services stay in sync closely.
* **Complexity:** High — requires event infrastructure (Kafka, Redis Streams), plus idempotent consumers.
* **Latency Impact:** Low — invalidation occurs asynchronously; slight delay before all caches sync.
* **Example:** When inventory changes in the warehouse service, it triggers events to invalidate product availability caches in storefront and search services.

#### 8.6 Hybrid TTL + Event

* **How it works:** Combines TTL-based expiration with event-driven invalidation for critical data. TTL acts as a safety net.
* **Freshness:** Very High — data is updated immediately on events, but TTL ensures stale cache doesn’t linger due to missed events.
* **Complexity:** High — combines complexities of both TTL management and event-driven systems.
* **Latency Impact:** Low — most cache hits are fast, invalidations are asynchronous but reliable.
* **Example:** Pricing data that must be highly accurate; immediate cache invalidation on price changes, plus TTL to prevent stale cache if events are missed.

---

## **Step 9: Summary Table for Quick Reference**

| Strategy                  | Freshness | Complexity | Latency Impact | Best For              |
| ------------------------- | --------- | ---------- | -------------- | --------------------- |
| Static TTL                | Low       | Low        | None           | Rarely-changing data  |
| Dynamic TTL               | Medium    | Medium     | None           | Mixed volatility data |
| Sliding TTL               | High      | Medium     | None           | Session-like data     |
| Manual Invalidation       | High      | High       | None           | Known-change events   |
| Event-Driven Invalidation | High      | High       | Low            | Multi-service sync    |
| Hybrid TTL + Event        | Very High | High       | Low            | Critical data         |

---

## **Step 10: Final Summary**

| Aspect         | Low Example                                                                        | High Example                                                                                |
| -------------- | ---------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| **Freshness**  | Static TTL caching on product descriptions, potentially stale for minutes or hours | Hybrid event + TTL caching for price updates, almost real-time accuracy                     |
| **Complexity** | Simple static TTL in-memory cache                                                  | Distributed event-driven invalidation with outbox pattern and multiple microservices        |
| **Latency**    | Pure TTL caching adds no latency                                                   | Event-driven invalidation adds small delays due to event propagation but keeps caches fresh |

---
