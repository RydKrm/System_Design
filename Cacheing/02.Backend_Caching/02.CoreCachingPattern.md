## **Chapter: Core Caching Patterns**

When you decide *where* to cache, the next question is *how* your application and the cache will talk to each other.
That‚Äôs where caching patterns come in ‚Äî they are the ‚Äúrules of engagement‚Äù between your app and the cache.

---

## **Read-Through Caching**

### **Concept**

Read-through caching is a pattern where your **application never talks to the database directly for reads**.
Instead, all read requests go to the **cache**.
If the cache doesn‚Äôt have the data (cache miss), it **automatically** fetches it from the database, stores it in the cache, and then returns it.

Here, the cache acts as a **middleman** and **data source of truth for reads** ‚Äî the application trusts it completely.

---

### **How It Works (Step-by-Step)**

1. **App requests data** from the cache (e.g., `product:123`).
2. **Cache hit:**

   * Cache finds the data and returns it instantly.
3. **Cache miss:**

   * Cache fetches the data from the database.
   * Cache stores this data with a TTL (time-to-live).
   * Cache returns it to the application.

In this approach, the *cache system* itself knows how to talk to the database ‚Äî your app doesn‚Äôt handle the ‚Äúmiss‚Äù logic.

---

### **Why Use It?**

* **Simplifies code** ‚Äî your app just asks the cache and gets the data.
* **Centralizes fetching logic** ‚Äî the cache layer decides how to retrieve and store missing data.
* **Reduces boilerplate** ‚Äî no need to write manual cache-miss handling in the app.

---

### **Example Scenario**

Let‚Äôs say you‚Äôre building a **news site**:

```plaintext
User requests "Top Headlines"
‚Üì
App calls cache.get("top_headlines")
‚Üì
Cache hit ‚Üí Return instantly from cache
‚Üì
Cache miss ‚Üí Cache fetches from DB or API
‚Üì
Cache stores headlines for 2 minutes
‚Üì
Return headlines to app
```

On subsequent requests within 2 minutes, the app gets the cached headlines without touching the database.

---

### **Pros**

* No manual cache miss handling in the application.
* Easier to integrate caching later without changing much app logic.
* Useful when using caching libraries or systems that natively support read-through (e.g., Hazelcast, Ehcache).

### **Cons**

* Cache must be tightly integrated with the database ‚Äî adds complexity to cache layer.
* Harder to have fine-grained control over *when* data is fetched and stored.

---

üí° **Key Difference from Cache-Aside:**
In Cache-Aside, **your app** handles the ‚Äúif missing, fetch from DB‚Äù logic.
In Read-Through, **the cache system** handles it for you.

---

Here‚Äôs the **deep dive** into **Write-Through Caching** so it pairs with the Read-Through explanation.

---

## **Write-Through Caching**

### **Concept**

Write-through caching ensures that **every write** (create or update) to your database also **updates the cache immediately**.
This means the cache is **always in sync** with the database, and any subsequent reads ‚Äî whether through read-through or direct cache calls ‚Äî will return fresh data.

Think of it like a ‚Äúdual-write‚Äù guarantee: the moment the database changes, the cache changes too.

---

### **How It Works (Step-by-Step)**

1. **Application writes data** ‚Äî for example, updating `user:101` with a new email address.
2. **Write to cache:** The cache layer stores the updated value under `user:101`.
3. **Write to database:** At the same time, the new data is written to the database.
4. **Acknowledgement:** The write operation is considered complete **only when both** cache and DB updates succeed.

---

### **Why Use It?**

* Keeps cache and database perfectly consistent for reads.
* Eliminates the risk of serving stale data from the cache after writes.
* Works well when paired with **read-through caching** so both reads and writes stay consistent without extra app logic.

---

### **Example Scenario**

Imagine a **social media profile update**:

```plaintext
User changes display name ‚Üí "Riyad Karim"
‚Üì
Write-Through flow:
    - Update cache.set("user:101", {name: "Riyad Karim"})
    - Update DB row for user:101
‚Üì
Next time anyone requests user:101, 
the read-through cache instantly returns the updated profile.
```

---

### **Pros**

* No stale reads from cache.
* Works seamlessly with read-through for consistent data flow.
* Easy for developers ‚Äî application doesn‚Äôt need special invalidation logic after writes.

### **Cons**

* Slightly slower writes ‚Äî you‚Äôre writing to two places.
* Cache must always be available during writes (otherwise you risk failing the whole operation).

---

üí° **Key Difference from Write-Behind:**
Write-Through writes to both cache and DB **synchronously** (immediately).
Write-Behind writes to cache first, then **later** flushes changes to DB asynchronously for speed.

---

Here‚Äôs the **deep dive** into **Write-Behind Caching** ‚Äî the ‚Äúfast but tricky‚Äù sibling of Write-Through.

---

## **Write-Behind Caching**

### **Concept**

Write-Behind (also called **Write-Back**) is a caching pattern where **your application writes data to the cache first**, and the cache **writes it to the database later** in the background.
This makes **writes extremely fast**, because you‚Äôre not waiting for the database to finish before responding to the user.

Think of it like dropping a letter into a mailbox: you ‚Äúwrite‚Äù it instantly, but the postman (cache system) delivers it to the recipient (database) later.

---

### **How It Works (Step-by-Step)**

1. **App writes data** (e.g., `order:987` status ‚Üí ‚Äúshipped‚Äù).
2. **Cache updates immediately** with the new value.
3. **App returns success** to the user ‚Äî no DB write yet.
4. **Cache flushes changes to DB asynchronously** after a short delay or in batches.

---

### **Why Use It?**

* Reduces write latency dramatically ‚Äî user sees instant success.
* Reduces database load by batching multiple writes into one transaction.
* Works well in high-write environments where exact real-time DB sync is not critical.

---

### **Example Scenario**

Imagine a **game leaderboard**:

```plaintext
Player scores 500 points ‚Üí App updates cache.set("player:42:score", 500)
‚Üì
App responds instantly to player
‚Üì
Every 60 seconds, cache flushes updated scores in bulk to the database
```

This way, the leaderboard updates instantly for users, but the DB isn‚Äôt bombarded with constant writes.

---

### **Pros**

* Extremely fast writes.
* Great for high-throughput systems (IoT, gaming, analytics).
* DB load is reduced thanks to batching.

### **Cons**

* Risk of **data loss** if the cache fails before flushing to DB.
* DB may be slightly **behind** the cache, which can be a problem for real-time consistency needs.
* More complex to implement reliably (needs failover and retry handling).

---

üí° **Key Difference from Write-Through:**

* **Write-Through:** Writes go to DB and cache **at the same time** (slower but consistent).
* **Write-Behind:** Writes go to cache now, DB later (faster but may cause lag or data loss).

---

## **Cache-Aside (Lazy Loading)**

### **Concept**

Cache-aside is one of the most common caching strategies, often called *lazy loading*.
The ‚Äúlazy‚Äù part means the cache only gets populated **when** the data is requested ‚Äî not before.
In this pattern, **your application code** controls when to read from the database, when to update the cache, and when to bypass it.

---

### **How It Works (Step-by-Step)**

1. **Check cache:**
   Application looks for the data in the cache using a key (e.g., `product:123`).

2. **Cache hit:**
   If found, return the cached value immediately ‚Äî no database involved.

3. **Cache miss:**
   If not found, the application queries the database for the data.

4. **Update cache:**
   Once the database returns the data, the application stores it in the cache for future requests.

5. **Return result:**
   Send the data back to the requester.

---

### **Why Use It?**

* **Full control** over caching logic.
* Ideal when you want to cache only specific queries or results.
* Cache is updated only for items actually requested ‚Äî saving space and memory.

---

### **Example Scenario**

Imagine an e-commerce app showing product details:

```plaintext
User requests Product #123
‚Üì
App checks Redis for "product:123"
‚Üì
Cache miss ‚Üí App queries PostgreSQL for Product #123
‚Üì
App stores result in Redis as "product:123" with TTL=5 minutes
‚Üì
Return product details to the user
```

On the **next request** for Product #123 within 5 minutes, the app gets it from Redis instantly without touching the database.

---

### **Pros**

* Efficient memory use ‚Äî only stores requested data.
* High cache hit rate over time for frequently accessed items.
* Flexible: app decides what and when to cache.

### **Cons**

* First request after cache expiry is slower (must hit DB).
* Manual invalidation needed if underlying data changes.


---

**Quick Summary Table:**

| Pattern       | Reads              | Writes                  | Control        | Best for               |
| ------------- | ------------------ | ----------------------- | -------------- | ---------------------- |
| Read-Through  | Cache handles miss | Manual or Write-Through | Low control    | Mostly-read data       |
| Write-Through | Always syncs DB    | Always syncs cache      | Low control    | Critical consistency   |
| Write-Behind  | From cache         | Async DB writes         | Medium control | High write throughput  |
| Cache-Aside   | App handles miss   | App updates cache       | High control   | Flexible caching needs |

---

If you want, I can now do **"Setting cache keys and structure (naming strategy)"** in the same short, book-style flow so you can read these like connected chapters. That‚Äôs where caching starts to feel like architecture, not just speed hacks.
